{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Wondav/Data-Analysis/blob/main/Model_Improvement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fGvfAAdx5gDo",
    "outputId": "356cf740-7542-40b5-e59d-81d162a884cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Wonder\\anaconda3\\envs\\venv\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold,cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "372XPoK8OMQ2",
    "outputId": "b91d188c-2376-4b88-bc8f-b164bc8771ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "      <th>Loan_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5849.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>LP001002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4583.0</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LP001003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>LP001005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2583.0</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>LP001006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>LP001008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Married  Dependents  Education  Self_Employed  ApplicantIncome  \\\n",
       "0     1.0      0.0         0.0        1.0            0.0           5849.0   \n",
       "1     1.0      1.0         1.0        1.0            0.0           4583.0   \n",
       "2     1.0      1.0         0.0        1.0            1.0           3000.0   \n",
       "3     1.0      1.0         0.0        0.0            0.0           2583.0   \n",
       "4     1.0      0.0         0.0        1.0            0.0           6000.0   \n",
       "\n",
       "   CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
       "0                0.0       148.0             360.0             1.0   \n",
       "1             1508.0       128.0             360.0             1.0   \n",
       "2                0.0        66.0             360.0             1.0   \n",
       "3             2358.0       120.0             360.0             1.0   \n",
       "4                0.0       141.0             360.0             1.0   \n",
       "\n",
       "   Property_Area  Loan_Status   Loan_ID  \n",
       "0            2.0          1.0  LP001002  \n",
       "1            0.0          0.0  LP001003  \n",
       "2            2.0          1.0  LP001005  \n",
       "3            2.0          1.0  LP001006  \n",
       "4            2.0          1.0  LP001008  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"data_cleaned.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPYi4rhWr3UZ"
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TCVsNmyiW7Pc"
   },
   "outputs": [],
   "source": [
    "poly=PolynomialFeatures(degree=2, interaction_only=True,include_bias=False)\n",
    "\n",
    "data['TotalIncome']=data['ApplicantIncome']+data['CoapplicantIncome']\n",
    "data['IncomeByLoan']=data['TotalIncome']/data['LoanAmount']\n",
    "data['ApplicantByLoan']=data['ApplicantIncome']/data['LoanAmount']\n",
    "data['CoapplicantByLoan']=data['CoapplicantIncome']/data['LoanAmount']\n",
    "data['LoanByTerm']=data['LoanAmount']/data['Loan_Amount_Term']\n",
    "\n",
    "\n",
    "poly1=poly.fit_transform(data[['ApplicantIncome','CoapplicantIncome','LoanAmount','TotalIncome','IncomeByLoan','ApplicantByLoan','CoapplicantByLoan','LoanByTerm']])\n",
    "df_poly=pd.DataFrame(poly1, columns=[f'poly_{i}' for i in range(poly1.shape[1])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "a338mUC-YuJF"
   },
   "outputs": [],
   "source": [
    "new_data=pd.concat([data,df_poly],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zuezsooIcGnR"
   },
   "outputs": [],
   "source": [
    "X=new_data.drop(['Loan_ID','Loan_Status'],axis=1)\n",
    "y=new_data['Loan_Status']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGJmU_a6sDz7"
   },
   "source": [
    "## Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GOd0YDLUZWI7",
    "outputId": "01db7c60-108d-4b10-efa7-a96ee6ade7ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, fold_1: 0.7560975609756098\n",
      "Accuracy, fold_2: 0.7804878048780488\n",
      "Accuracy, fold_3: 0.8211382113821138\n",
      "Accuracy, fold_4: 0.8536585365853658\n",
      "Accuracy, fold_5: 0.7377049180327869\n",
      "0.789817406370785\n"
     ]
    }
   ],
   "source": [
    "fold=StratifiedKFold(n_splits=5)\n",
    "\n",
    "F1,i=[],1\n",
    "for train, test in fold.split(X,y):\n",
    "\n",
    "  X_train, X_test = X.iloc[train],X.iloc[test]\n",
    "  y_train, y_test = y.iloc[train],y.iloc[test]\n",
    "\n",
    "  model=XGBClassifier()\n",
    "\n",
    "  model.fit(X_train,y_train)\n",
    "\n",
    "  preds=model.predict(X_test)\n",
    "\n",
    "  print(f'Accuracy, fold_{i}: {accuracy_score(y_test,preds)}')\n",
    "  i+=1\n",
    "  F1.append(accuracy_score(y_test,preds))\n",
    "print(np.mean(F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.007604\n",
      "0:\tlearn: 0.6892715\ttotal: 211ms\tremaining: 3m 31s\n",
      "1:\tlearn: 0.6847908\ttotal: 247ms\tremaining: 2m 3s\n",
      "2:\tlearn: 0.6805808\ttotal: 338ms\tremaining: 1m 52s\n",
      "3:\tlearn: 0.6765870\ttotal: 372ms\tremaining: 1m 32s\n",
      "4:\tlearn: 0.6726992\ttotal: 431ms\tremaining: 1m 25s\n",
      "5:\tlearn: 0.6689722\ttotal: 498ms\tremaining: 1m 22s\n",
      "6:\tlearn: 0.6651798\ttotal: 592ms\tremaining: 1m 23s\n",
      "7:\tlearn: 0.6614290\ttotal: 643ms\tremaining: 1m 19s\n",
      "8:\tlearn: 0.6578818\ttotal: 724ms\tremaining: 1m 19s\n",
      "9:\tlearn: 0.6544678\ttotal: 772ms\tremaining: 1m 16s\n",
      "10:\tlearn: 0.6507841\ttotal: 865ms\tremaining: 1m 17s\n",
      "11:\tlearn: 0.6473771\ttotal: 977ms\tremaining: 1m 20s\n",
      "12:\tlearn: 0.6440397\ttotal: 1.02s\tremaining: 1m 17s\n",
      "13:\tlearn: 0.6406804\ttotal: 1.12s\tremaining: 1m 19s\n",
      "14:\tlearn: 0.6374900\ttotal: 1.25s\tremaining: 1m 21s\n",
      "15:\tlearn: 0.6345721\ttotal: 1.27s\tremaining: 1m 18s\n",
      "16:\tlearn: 0.6314323\ttotal: 1.3s\tremaining: 1m 15s\n",
      "17:\tlearn: 0.6280476\ttotal: 1.33s\tremaining: 1m 12s\n",
      "18:\tlearn: 0.6247442\ttotal: 1.35s\tremaining: 1m 9s\n",
      "19:\tlearn: 0.6220163\ttotal: 1.38s\tremaining: 1m 7s\n",
      "20:\tlearn: 0.6189310\ttotal: 1.5s\tremaining: 1m 9s\n",
      "21:\tlearn: 0.6157250\ttotal: 1.54s\tremaining: 1m 8s\n",
      "22:\tlearn: 0.6128779\ttotal: 1.56s\tremaining: 1m 6s\n",
      "23:\tlearn: 0.6098222\ttotal: 1.58s\tremaining: 1m 4s\n",
      "24:\tlearn: 0.6068192\ttotal: 1.62s\tremaining: 1m 3s\n",
      "25:\tlearn: 0.6035601\ttotal: 1.72s\tremaining: 1m 4s\n",
      "26:\tlearn: 0.6008905\ttotal: 1.76s\tremaining: 1m 3s\n",
      "27:\tlearn: 0.5975483\ttotal: 1.79s\tremaining: 1m 2s\n",
      "28:\tlearn: 0.5947974\ttotal: 2.02s\tremaining: 1m 7s\n",
      "29:\tlearn: 0.5920190\ttotal: 2.1s\tremaining: 1m 7s\n",
      "30:\tlearn: 0.5893429\ttotal: 2.16s\tremaining: 1m 7s\n",
      "31:\tlearn: 0.5866499\ttotal: 2.23s\tremaining: 1m 7s\n",
      "32:\tlearn: 0.5839560\ttotal: 2.29s\tremaining: 1m 7s\n",
      "33:\tlearn: 0.5819782\ttotal: 2.3s\tremaining: 1m 5s\n",
      "34:\tlearn: 0.5791740\ttotal: 2.32s\tremaining: 1m 4s\n",
      "35:\tlearn: 0.5770273\ttotal: 2.36s\tremaining: 1m 3s\n",
      "36:\tlearn: 0.5747130\ttotal: 2.38s\tremaining: 1m 1s\n",
      "37:\tlearn: 0.5726003\ttotal: 2.4s\tremaining: 1m\n",
      "38:\tlearn: 0.5700889\ttotal: 2.44s\tremaining: 1m\n",
      "39:\tlearn: 0.5675851\ttotal: 2.46s\tremaining: 59.2s\n",
      "40:\tlearn: 0.5651805\ttotal: 2.51s\tremaining: 58.7s\n",
      "41:\tlearn: 0.5627971\ttotal: 2.53s\tremaining: 57.7s\n",
      "42:\tlearn: 0.5602869\ttotal: 2.55s\tremaining: 56.8s\n",
      "43:\tlearn: 0.5579983\ttotal: 2.58s\tremaining: 56s\n",
      "44:\tlearn: 0.5557807\ttotal: 2.6s\tremaining: 55.1s\n",
      "45:\tlearn: 0.5537721\ttotal: 2.62s\tremaining: 54.4s\n",
      "46:\tlearn: 0.5514911\ttotal: 2.65s\tremaining: 53.8s\n",
      "47:\tlearn: 0.5494544\ttotal: 2.69s\tremaining: 53.4s\n",
      "48:\tlearn: 0.5475674\ttotal: 2.76s\tremaining: 53.6s\n",
      "49:\tlearn: 0.5454418\ttotal: 2.79s\tremaining: 52.9s\n",
      "50:\tlearn: 0.5435542\ttotal: 2.82s\tremaining: 52.5s\n",
      "51:\tlearn: 0.5414732\ttotal: 2.87s\tremaining: 52.4s\n",
      "52:\tlearn: 0.5396469\ttotal: 2.92s\tremaining: 52.2s\n",
      "53:\tlearn: 0.5374029\ttotal: 3.06s\tremaining: 53.6s\n",
      "54:\tlearn: 0.5352542\ttotal: 3.12s\tremaining: 53.6s\n",
      "55:\tlearn: 0.5332889\ttotal: 3.21s\tremaining: 54.2s\n",
      "56:\tlearn: 0.5317174\ttotal: 3.27s\tremaining: 54.1s\n",
      "57:\tlearn: 0.5299507\ttotal: 3.41s\tremaining: 55.4s\n",
      "58:\tlearn: 0.5280307\ttotal: 3.5s\tremaining: 55.8s\n",
      "59:\tlearn: 0.5261307\ttotal: 3.54s\tremaining: 55.5s\n",
      "60:\tlearn: 0.5244248\ttotal: 3.57s\tremaining: 54.9s\n",
      "61:\tlearn: 0.5226655\ttotal: 3.61s\tremaining: 54.7s\n",
      "62:\tlearn: 0.5206881\ttotal: 3.71s\tremaining: 55.2s\n",
      "63:\tlearn: 0.5188259\ttotal: 3.74s\tremaining: 54.7s\n",
      "64:\tlearn: 0.5172657\ttotal: 3.77s\tremaining: 54.2s\n",
      "65:\tlearn: 0.5157247\ttotal: 3.79s\tremaining: 53.6s\n",
      "66:\tlearn: 0.5142115\ttotal: 3.82s\tremaining: 53.2s\n",
      "67:\tlearn: 0.5125442\ttotal: 3.86s\tremaining: 52.9s\n",
      "68:\tlearn: 0.5109229\ttotal: 3.91s\tremaining: 52.8s\n",
      "69:\tlearn: 0.5091605\ttotal: 3.96s\tremaining: 52.6s\n",
      "70:\tlearn: 0.5073730\ttotal: 3.99s\tremaining: 52.2s\n",
      "71:\tlearn: 0.5060895\ttotal: 4.02s\tremaining: 51.8s\n",
      "72:\tlearn: 0.5047602\ttotal: 4.05s\tremaining: 51.4s\n",
      "73:\tlearn: 0.5032622\ttotal: 4.08s\tremaining: 51s\n",
      "74:\tlearn: 0.5017747\ttotal: 4.09s\tremaining: 50.5s\n",
      "75:\tlearn: 0.5001691\ttotal: 4.12s\tremaining: 50.1s\n",
      "76:\tlearn: 0.4987906\ttotal: 4.18s\tremaining: 50.1s\n",
      "77:\tlearn: 0.4972937\ttotal: 4.2s\tremaining: 49.7s\n",
      "78:\tlearn: 0.4958059\ttotal: 4.22s\tremaining: 49.2s\n",
      "79:\tlearn: 0.4943987\ttotal: 4.24s\tremaining: 48.8s\n",
      "80:\tlearn: 0.4928471\ttotal: 4.26s\tremaining: 48.4s\n",
      "81:\tlearn: 0.4913597\ttotal: 4.28s\tremaining: 48s\n",
      "82:\tlearn: 0.4899109\ttotal: 4.3s\tremaining: 47.6s\n",
      "83:\tlearn: 0.4886618\ttotal: 4.33s\tremaining: 47.2s\n",
      "84:\tlearn: 0.4880177\ttotal: 4.41s\tremaining: 47.5s\n",
      "85:\tlearn: 0.4873297\ttotal: 4.45s\tremaining: 47.3s\n",
      "86:\tlearn: 0.4860012\ttotal: 4.48s\tremaining: 47s\n",
      "87:\tlearn: 0.4846877\ttotal: 4.52s\tremaining: 46.9s\n",
      "88:\tlearn: 0.4831949\ttotal: 4.56s\tremaining: 46.6s\n",
      "89:\tlearn: 0.4820135\ttotal: 4.6s\tremaining: 46.5s\n",
      "90:\tlearn: 0.4807979\ttotal: 4.67s\tremaining: 46.7s\n",
      "91:\tlearn: 0.4797193\ttotal: 4.7s\tremaining: 46.4s\n",
      "92:\tlearn: 0.4786999\ttotal: 4.74s\tremaining: 46.2s\n",
      "93:\tlearn: 0.4775173\ttotal: 4.79s\tremaining: 46.2s\n",
      "94:\tlearn: 0.4768773\ttotal: 4.81s\tremaining: 45.8s\n",
      "95:\tlearn: 0.4758682\ttotal: 4.83s\tremaining: 45.5s\n",
      "96:\tlearn: 0.4746299\ttotal: 4.84s\tremaining: 45.1s\n",
      "97:\tlearn: 0.4734512\ttotal: 4.88s\tremaining: 44.9s\n",
      "98:\tlearn: 0.4726707\ttotal: 4.9s\tremaining: 44.6s\n",
      "99:\tlearn: 0.4715961\ttotal: 4.92s\tremaining: 44.3s\n",
      "100:\tlearn: 0.4707353\ttotal: 4.93s\tremaining: 43.9s\n",
      "101:\tlearn: 0.4697279\ttotal: 4.98s\tremaining: 43.8s\n",
      "102:\tlearn: 0.4687260\ttotal: 5s\tremaining: 43.5s\n",
      "103:\tlearn: 0.4675308\ttotal: 5.02s\tremaining: 43.2s\n",
      "104:\tlearn: 0.4663811\ttotal: 5.03s\tremaining: 42.9s\n",
      "105:\tlearn: 0.4658860\ttotal: 5.06s\tremaining: 42.6s\n",
      "106:\tlearn: 0.4648541\ttotal: 5.08s\tremaining: 42.4s\n",
      "107:\tlearn: 0.4639547\ttotal: 5.14s\tremaining: 42.4s\n",
      "108:\tlearn: 0.4630837\ttotal: 5.18s\tremaining: 42.3s\n",
      "109:\tlearn: 0.4617930\ttotal: 5.24s\tremaining: 42.4s\n",
      "110:\tlearn: 0.4606515\ttotal: 5.27s\tremaining: 42.2s\n",
      "111:\tlearn: 0.4601480\ttotal: 5.29s\tremaining: 42s\n",
      "112:\tlearn: 0.4596229\ttotal: 5.39s\tremaining: 42.4s\n",
      "113:\tlearn: 0.4586910\ttotal: 5.49s\tremaining: 42.7s\n",
      "114:\tlearn: 0.4574657\ttotal: 5.56s\tremaining: 42.8s\n",
      "115:\tlearn: 0.4565589\ttotal: 5.58s\tremaining: 42.6s\n",
      "116:\tlearn: 0.4558952\ttotal: 5.64s\tremaining: 42.6s\n",
      "117:\tlearn: 0.4546779\ttotal: 5.67s\tremaining: 42.4s\n",
      "118:\tlearn: 0.4540030\ttotal: 5.7s\tremaining: 42.2s\n",
      "119:\tlearn: 0.4528679\ttotal: 5.74s\tremaining: 42.1s\n",
      "120:\tlearn: 0.4519901\ttotal: 5.77s\tremaining: 41.9s\n",
      "121:\tlearn: 0.4509565\ttotal: 5.83s\tremaining: 42s\n",
      "122:\tlearn: 0.4501345\ttotal: 5.96s\tremaining: 42.5s\n",
      "123:\tlearn: 0.4494989\ttotal: 6.04s\tremaining: 42.6s\n",
      "124:\tlearn: 0.4485822\ttotal: 6.12s\tremaining: 42.9s\n",
      "125:\tlearn: 0.4478099\ttotal: 6.17s\tremaining: 42.8s\n",
      "126:\tlearn: 0.4470731\ttotal: 6.19s\tremaining: 42.6s\n",
      "127:\tlearn: 0.4461648\ttotal: 6.22s\tremaining: 42.3s\n",
      "128:\tlearn: 0.4454475\ttotal: 6.24s\tremaining: 42.1s\n",
      "129:\tlearn: 0.4443633\ttotal: 6.26s\tremaining: 41.9s\n",
      "130:\tlearn: 0.4435201\ttotal: 6.29s\tremaining: 41.8s\n",
      "131:\tlearn: 0.4428898\ttotal: 6.31s\tremaining: 41.5s\n",
      "132:\tlearn: 0.4421481\ttotal: 6.33s\tremaining: 41.2s\n",
      "133:\tlearn: 0.4411138\ttotal: 6.36s\tremaining: 41.1s\n",
      "134:\tlearn: 0.4402578\ttotal: 6.38s\tremaining: 40.9s\n",
      "135:\tlearn: 0.4393155\ttotal: 6.41s\tremaining: 40.7s\n",
      "136:\tlearn: 0.4386943\ttotal: 6.48s\tremaining: 40.8s\n",
      "137:\tlearn: 0.4381597\ttotal: 6.53s\tremaining: 40.8s\n",
      "138:\tlearn: 0.4376664\ttotal: 6.61s\tremaining: 41s\n",
      "139:\tlearn: 0.4367263\ttotal: 6.68s\tremaining: 41s\n",
      "140:\tlearn: 0.4357824\ttotal: 6.77s\tremaining: 41.2s\n",
      "141:\tlearn: 0.4353527\ttotal: 6.79s\tremaining: 41s\n",
      "142:\tlearn: 0.4347328\ttotal: 6.81s\tremaining: 40.8s\n",
      "143:\tlearn: 0.4341298\ttotal: 6.83s\tremaining: 40.6s\n",
      "144:\tlearn: 0.4334529\ttotal: 6.87s\tremaining: 40.5s\n",
      "145:\tlearn: 0.4330065\ttotal: 6.89s\tremaining: 40.3s\n",
      "146:\tlearn: 0.4324061\ttotal: 6.91s\tremaining: 40.1s\n",
      "147:\tlearn: 0.4318309\ttotal: 6.93s\tremaining: 39.9s\n",
      "148:\tlearn: 0.4309285\ttotal: 6.95s\tremaining: 39.7s\n",
      "149:\tlearn: 0.4303150\ttotal: 6.97s\tremaining: 39.5s\n",
      "150:\tlearn: 0.4295959\ttotal: 7s\tremaining: 39.3s\n",
      "151:\tlearn: 0.4289357\ttotal: 7.02s\tremaining: 39.2s\n",
      "152:\tlearn: 0.4280289\ttotal: 7.04s\tremaining: 39s\n",
      "153:\tlearn: 0.4275905\ttotal: 7.05s\tremaining: 38.7s\n",
      "154:\tlearn: 0.4269210\ttotal: 7.07s\tremaining: 38.5s\n",
      "155:\tlearn: 0.4264201\ttotal: 7.1s\tremaining: 38.4s\n",
      "156:\tlearn: 0.4257143\ttotal: 7.11s\tremaining: 38.2s\n",
      "157:\tlearn: 0.4252244\ttotal: 7.13s\tremaining: 38s\n",
      "158:\tlearn: 0.4245889\ttotal: 7.14s\tremaining: 37.8s\n",
      "159:\tlearn: 0.4238989\ttotal: 7.16s\tremaining: 37.6s\n",
      "160:\tlearn: 0.4233396\ttotal: 7.18s\tremaining: 37.4s\n",
      "161:\tlearn: 0.4226590\ttotal: 7.2s\tremaining: 37.2s\n",
      "162:\tlearn: 0.4220899\ttotal: 7.23s\tremaining: 37.1s\n",
      "163:\tlearn: 0.4212861\ttotal: 7.25s\tremaining: 37s\n",
      "164:\tlearn: 0.4207772\ttotal: 7.27s\tremaining: 36.8s\n",
      "165:\tlearn: 0.4201163\ttotal: 7.29s\tremaining: 36.6s\n",
      "166:\tlearn: 0.4194656\ttotal: 7.31s\tremaining: 36.4s\n",
      "167:\tlearn: 0.4188495\ttotal: 7.32s\tremaining: 36.3s\n",
      "168:\tlearn: 0.4185966\ttotal: 7.35s\tremaining: 36.2s\n",
      "169:\tlearn: 0.4179754\ttotal: 7.37s\tremaining: 36s\n",
      "170:\tlearn: 0.4175560\ttotal: 7.39s\tremaining: 35.8s\n",
      "171:\tlearn: 0.4168523\ttotal: 7.41s\tremaining: 35.7s\n",
      "172:\tlearn: 0.4163325\ttotal: 7.43s\tremaining: 35.5s\n",
      "173:\tlearn: 0.4159466\ttotal: 7.45s\tremaining: 35.4s\n",
      "174:\tlearn: 0.4151745\ttotal: 7.47s\tremaining: 35.2s\n",
      "175:\tlearn: 0.4145700\ttotal: 7.49s\tremaining: 35.1s\n",
      "176:\tlearn: 0.4141381\ttotal: 7.51s\tremaining: 34.9s\n",
      "177:\tlearn: 0.4137863\ttotal: 7.53s\tremaining: 34.8s\n",
      "178:\tlearn: 0.4132256\ttotal: 7.55s\tremaining: 34.7s\n",
      "179:\tlearn: 0.4127127\ttotal: 7.57s\tremaining: 34.5s\n",
      "180:\tlearn: 0.4120534\ttotal: 7.61s\tremaining: 34.4s\n",
      "181:\tlearn: 0.4115152\ttotal: 7.64s\tremaining: 34.3s\n",
      "182:\tlearn: 0.4110677\ttotal: 7.66s\tremaining: 34.2s\n",
      "183:\tlearn: 0.4104740\ttotal: 7.67s\tremaining: 34s\n",
      "184:\tlearn: 0.4100846\ttotal: 7.7s\tremaining: 33.9s\n",
      "185:\tlearn: 0.4096618\ttotal: 7.74s\tremaining: 33.9s\n",
      "186:\tlearn: 0.4093840\ttotal: 7.75s\tremaining: 33.7s\n",
      "187:\tlearn: 0.4088635\ttotal: 7.77s\tremaining: 33.5s\n",
      "188:\tlearn: 0.4082280\ttotal: 7.78s\tremaining: 33.4s\n",
      "189:\tlearn: 0.4077908\ttotal: 7.8s\tremaining: 33.3s\n",
      "190:\tlearn: 0.4071743\ttotal: 7.85s\tremaining: 33.3s\n",
      "191:\tlearn: 0.4066853\ttotal: 7.87s\tremaining: 33.1s\n",
      "192:\tlearn: 0.4061440\ttotal: 7.89s\tremaining: 33s\n",
      "193:\tlearn: 0.4053417\ttotal: 7.91s\tremaining: 32.8s\n",
      "194:\tlearn: 0.4048725\ttotal: 7.92s\tremaining: 32.7s\n",
      "195:\tlearn: 0.4044069\ttotal: 7.94s\tremaining: 32.6s\n",
      "196:\tlearn: 0.4039734\ttotal: 7.95s\tremaining: 32.4s\n",
      "197:\tlearn: 0.4034778\ttotal: 7.97s\tremaining: 32.3s\n",
      "198:\tlearn: 0.4031015\ttotal: 7.98s\tremaining: 32.1s\n",
      "199:\tlearn: 0.4024238\ttotal: 8s\tremaining: 32s\n",
      "200:\tlearn: 0.4018928\ttotal: 8.02s\tremaining: 31.9s\n",
      "201:\tlearn: 0.4012012\ttotal: 8.04s\tremaining: 31.8s\n",
      "202:\tlearn: 0.4007459\ttotal: 8.08s\tremaining: 31.7s\n",
      "203:\tlearn: 0.3998808\ttotal: 8.1s\tremaining: 31.6s\n",
      "204:\tlearn: 0.3992813\ttotal: 8.12s\tremaining: 31.5s\n",
      "205:\tlearn: 0.3987116\ttotal: 8.13s\tremaining: 31.4s\n",
      "206:\tlearn: 0.3982180\ttotal: 8.15s\tremaining: 31.2s\n",
      "207:\tlearn: 0.3979030\ttotal: 8.17s\tremaining: 31.1s\n",
      "208:\tlearn: 0.3974235\ttotal: 8.18s\tremaining: 31s\n",
      "209:\tlearn: 0.3970178\ttotal: 8.21s\tremaining: 30.9s\n",
      "210:\tlearn: 0.3966239\ttotal: 8.24s\tremaining: 30.8s\n",
      "211:\tlearn: 0.3962516\ttotal: 8.26s\tremaining: 30.7s\n",
      "212:\tlearn: 0.3958020\ttotal: 8.28s\tremaining: 30.6s\n",
      "213:\tlearn: 0.3952430\ttotal: 8.29s\tremaining: 30.5s\n",
      "214:\tlearn: 0.3947404\ttotal: 8.32s\tremaining: 30.4s\n",
      "215:\tlearn: 0.3945115\ttotal: 8.34s\tremaining: 30.3s\n",
      "216:\tlearn: 0.3940048\ttotal: 8.36s\tremaining: 30.2s\n",
      "217:\tlearn: 0.3936004\ttotal: 8.37s\tremaining: 30s\n",
      "218:\tlearn: 0.3931866\ttotal: 8.39s\tremaining: 29.9s\n",
      "219:\tlearn: 0.3927949\ttotal: 8.4s\tremaining: 29.8s\n",
      "220:\tlearn: 0.3920132\ttotal: 8.43s\tremaining: 29.7s\n",
      "221:\tlearn: 0.3913588\ttotal: 8.45s\tremaining: 29.6s\n",
      "222:\tlearn: 0.3910129\ttotal: 8.47s\tremaining: 29.5s\n",
      "223:\tlearn: 0.3906928\ttotal: 8.49s\tremaining: 29.4s\n",
      "224:\tlearn: 0.3901421\ttotal: 8.5s\tremaining: 29.3s\n",
      "225:\tlearn: 0.3897078\ttotal: 8.52s\tremaining: 29.2s\n",
      "226:\tlearn: 0.3892111\ttotal: 8.54s\tremaining: 29.1s\n",
      "227:\tlearn: 0.3886342\ttotal: 8.57s\tremaining: 29s\n",
      "228:\tlearn: 0.3883212\ttotal: 8.59s\tremaining: 28.9s\n",
      "229:\tlearn: 0.3877942\ttotal: 8.6s\tremaining: 28.8s\n",
      "230:\tlearn: 0.3873228\ttotal: 8.62s\tremaining: 28.7s\n",
      "231:\tlearn: 0.3869887\ttotal: 8.65s\tremaining: 28.6s\n",
      "232:\tlearn: 0.3865273\ttotal: 8.67s\tremaining: 28.5s\n",
      "233:\tlearn: 0.3861091\ttotal: 8.68s\tremaining: 28.4s\n",
      "234:\tlearn: 0.3857897\ttotal: 8.7s\tremaining: 28.3s\n",
      "235:\tlearn: 0.3854337\ttotal: 8.72s\tremaining: 28.2s\n",
      "236:\tlearn: 0.3851626\ttotal: 8.74s\tremaining: 28.1s\n",
      "237:\tlearn: 0.3850227\ttotal: 8.75s\tremaining: 28s\n",
      "238:\tlearn: 0.3847044\ttotal: 8.78s\tremaining: 27.9s\n",
      "239:\tlearn: 0.3843742\ttotal: 8.83s\tremaining: 28s\n",
      "240:\tlearn: 0.3840145\ttotal: 8.85s\tremaining: 27.9s\n",
      "241:\tlearn: 0.3837501\ttotal: 8.87s\tremaining: 27.8s\n",
      "242:\tlearn: 0.3833950\ttotal: 8.89s\tremaining: 27.7s\n",
      "243:\tlearn: 0.3828366\ttotal: 8.91s\tremaining: 27.6s\n",
      "244:\tlearn: 0.3824574\ttotal: 8.93s\tremaining: 27.5s\n",
      "245:\tlearn: 0.3822419\ttotal: 8.95s\tremaining: 27.4s\n",
      "246:\tlearn: 0.3819790\ttotal: 8.96s\tremaining: 27.3s\n",
      "247:\tlearn: 0.3815878\ttotal: 8.98s\tremaining: 27.2s\n",
      "248:\tlearn: 0.3812037\ttotal: 9s\tremaining: 27.1s\n",
      "249:\tlearn: 0.3808659\ttotal: 9.02s\tremaining: 27.1s\n",
      "250:\tlearn: 0.3801933\ttotal: 9.05s\tremaining: 27s\n",
      "251:\tlearn: 0.3797567\ttotal: 9.07s\tremaining: 26.9s\n",
      "252:\tlearn: 0.3794430\ttotal: 9.09s\tremaining: 26.8s\n",
      "253:\tlearn: 0.3790826\ttotal: 9.1s\tremaining: 26.7s\n",
      "254:\tlearn: 0.3785735\ttotal: 9.12s\tremaining: 26.6s\n",
      "255:\tlearn: 0.3781442\ttotal: 9.13s\tremaining: 26.5s\n",
      "256:\tlearn: 0.3777365\ttotal: 9.15s\tremaining: 26.5s\n",
      "257:\tlearn: 0.3771714\ttotal: 9.17s\tremaining: 26.4s\n",
      "258:\tlearn: 0.3766313\ttotal: 9.19s\tremaining: 26.3s\n",
      "259:\tlearn: 0.3760617\ttotal: 9.21s\tremaining: 26.2s\n",
      "260:\tlearn: 0.3757789\ttotal: 9.23s\tremaining: 26.1s\n",
      "261:\tlearn: 0.3753048\ttotal: 9.25s\tremaining: 26.1s\n",
      "262:\tlearn: 0.3750042\ttotal: 9.27s\tremaining: 26s\n",
      "263:\tlearn: 0.3746981\ttotal: 9.3s\tremaining: 25.9s\n",
      "264:\tlearn: 0.3742882\ttotal: 9.31s\tremaining: 25.8s\n",
      "265:\tlearn: 0.3739162\ttotal: 9.33s\tremaining: 25.8s\n",
      "266:\tlearn: 0.3735215\ttotal: 9.35s\tremaining: 25.7s\n",
      "267:\tlearn: 0.3730728\ttotal: 9.37s\tremaining: 25.6s\n",
      "268:\tlearn: 0.3726110\ttotal: 9.38s\tremaining: 25.5s\n",
      "269:\tlearn: 0.3721300\ttotal: 9.4s\tremaining: 25.4s\n",
      "270:\tlearn: 0.3717887\ttotal: 9.41s\tremaining: 25.3s\n",
      "271:\tlearn: 0.3714962\ttotal: 9.44s\tremaining: 25.3s\n",
      "272:\tlearn: 0.3711697\ttotal: 9.46s\tremaining: 25.2s\n",
      "273:\tlearn: 0.3706893\ttotal: 9.48s\tremaining: 25.1s\n",
      "274:\tlearn: 0.3704400\ttotal: 9.5s\tremaining: 25s\n",
      "275:\tlearn: 0.3699894\ttotal: 9.51s\tremaining: 25s\n",
      "276:\tlearn: 0.3696460\ttotal: 9.53s\tremaining: 24.9s\n",
      "277:\tlearn: 0.3692921\ttotal: 9.55s\tremaining: 24.8s\n",
      "278:\tlearn: 0.3689064\ttotal: 9.58s\tremaining: 24.8s\n",
      "279:\tlearn: 0.3687423\ttotal: 9.61s\tremaining: 24.7s\n",
      "280:\tlearn: 0.3682900\ttotal: 9.62s\tremaining: 24.6s\n",
      "281:\tlearn: 0.3676229\ttotal: 9.66s\tremaining: 24.6s\n",
      "282:\tlearn: 0.3673431\ttotal: 9.69s\tremaining: 24.5s\n",
      "283:\tlearn: 0.3668913\ttotal: 9.71s\tremaining: 24.5s\n",
      "284:\tlearn: 0.3666175\ttotal: 9.72s\tremaining: 24.4s\n",
      "285:\tlearn: 0.3663266\ttotal: 9.74s\tremaining: 24.3s\n",
      "286:\tlearn: 0.3661073\ttotal: 9.76s\tremaining: 24.2s\n",
      "287:\tlearn: 0.3657057\ttotal: 9.77s\tremaining: 24.2s\n",
      "288:\tlearn: 0.3652690\ttotal: 9.82s\tremaining: 24.1s\n",
      "289:\tlearn: 0.3648554\ttotal: 9.9s\tremaining: 24.2s\n",
      "290:\tlearn: 0.3646837\ttotal: 9.91s\tremaining: 24.1s\n",
      "291:\tlearn: 0.3642969\ttotal: 9.93s\tremaining: 24.1s\n",
      "292:\tlearn: 0.3638483\ttotal: 9.95s\tremaining: 24s\n",
      "293:\tlearn: 0.3635307\ttotal: 9.96s\tremaining: 23.9s\n",
      "294:\tlearn: 0.3630394\ttotal: 9.98s\tremaining: 23.8s\n",
      "295:\tlearn: 0.3625776\ttotal: 9.99s\tremaining: 23.8s\n",
      "296:\tlearn: 0.3622084\ttotal: 10s\tremaining: 23.7s\n",
      "297:\tlearn: 0.3619872\ttotal: 10s\tremaining: 23.6s\n",
      "298:\tlearn: 0.3617149\ttotal: 10.1s\tremaining: 23.7s\n",
      "299:\tlearn: 0.3614849\ttotal: 10.2s\tremaining: 23.8s\n",
      "300:\tlearn: 0.3611833\ttotal: 10.2s\tremaining: 23.7s\n",
      "301:\tlearn: 0.3608560\ttotal: 10.3s\tremaining: 23.7s\n",
      "302:\tlearn: 0.3605768\ttotal: 10.3s\tremaining: 23.7s\n",
      "303:\tlearn: 0.3601716\ttotal: 10.3s\tremaining: 23.7s\n",
      "304:\tlearn: 0.3596856\ttotal: 10.4s\tremaining: 23.6s\n",
      "305:\tlearn: 0.3594971\ttotal: 10.4s\tremaining: 23.5s\n",
      "306:\tlearn: 0.3590288\ttotal: 10.4s\tremaining: 23.4s\n",
      "307:\tlearn: 0.3585972\ttotal: 10.4s\tremaining: 23.4s\n",
      "308:\tlearn: 0.3583317\ttotal: 10.4s\tremaining: 23.3s\n",
      "309:\tlearn: 0.3581080\ttotal: 10.4s\tremaining: 23.2s\n",
      "310:\tlearn: 0.3578225\ttotal: 10.4s\tremaining: 23.2s\n",
      "311:\tlearn: 0.3573894\ttotal: 10.5s\tremaining: 23.1s\n",
      "312:\tlearn: 0.3570038\ttotal: 10.5s\tremaining: 23s\n",
      "313:\tlearn: 0.3566953\ttotal: 10.6s\tremaining: 23.1s\n",
      "314:\tlearn: 0.3562861\ttotal: 10.6s\tremaining: 23s\n",
      "315:\tlearn: 0.3559878\ttotal: 10.6s\tremaining: 23s\n",
      "316:\tlearn: 0.3554858\ttotal: 10.6s\tremaining: 22.9s\n",
      "317:\tlearn: 0.3550780\ttotal: 10.6s\tremaining: 22.8s\n",
      "318:\tlearn: 0.3548951\ttotal: 10.7s\tremaining: 22.7s\n",
      "319:\tlearn: 0.3545140\ttotal: 10.7s\tremaining: 22.7s\n",
      "320:\tlearn: 0.3540071\ttotal: 10.7s\tremaining: 22.6s\n",
      "321:\tlearn: 0.3536535\ttotal: 10.7s\tremaining: 22.5s\n",
      "322:\tlearn: 0.3533695\ttotal: 10.7s\tremaining: 22.5s\n",
      "323:\tlearn: 0.3530945\ttotal: 10.8s\tremaining: 22.5s\n",
      "324:\tlearn: 0.3527657\ttotal: 10.8s\tremaining: 22.4s\n",
      "325:\tlearn: 0.3523362\ttotal: 10.8s\tremaining: 22.4s\n",
      "326:\tlearn: 0.3521070\ttotal: 10.8s\tremaining: 22.3s\n",
      "327:\tlearn: 0.3517493\ttotal: 10.9s\tremaining: 22.2s\n",
      "328:\tlearn: 0.3514952\ttotal: 10.9s\tremaining: 22.2s\n",
      "329:\tlearn: 0.3513612\ttotal: 10.9s\tremaining: 22.1s\n",
      "330:\tlearn: 0.3509244\ttotal: 10.9s\tremaining: 22.1s\n",
      "331:\tlearn: 0.3506904\ttotal: 11s\tremaining: 22.1s\n",
      "332:\tlearn: 0.3504105\ttotal: 11s\tremaining: 22s\n",
      "333:\tlearn: 0.3499607\ttotal: 11s\tremaining: 22s\n",
      "334:\tlearn: 0.3497974\ttotal: 11.1s\tremaining: 22s\n",
      "335:\tlearn: 0.3494931\ttotal: 11.1s\tremaining: 21.9s\n",
      "336:\tlearn: 0.3492846\ttotal: 11.1s\tremaining: 21.8s\n",
      "337:\tlearn: 0.3490671\ttotal: 11.1s\tremaining: 21.8s\n",
      "338:\tlearn: 0.3488359\ttotal: 11.2s\tremaining: 21.7s\n",
      "339:\tlearn: 0.3486427\ttotal: 11.2s\tremaining: 21.7s\n",
      "340:\tlearn: 0.3481790\ttotal: 11.2s\tremaining: 21.6s\n",
      "341:\tlearn: 0.3479692\ttotal: 11.2s\tremaining: 21.6s\n",
      "342:\tlearn: 0.3476618\ttotal: 11.2s\tremaining: 21.5s\n",
      "343:\tlearn: 0.3472665\ttotal: 11.2s\tremaining: 21.4s\n",
      "344:\tlearn: 0.3467956\ttotal: 11.3s\tremaining: 21.4s\n",
      "345:\tlearn: 0.3463673\ttotal: 11.3s\tremaining: 21.3s\n",
      "346:\tlearn: 0.3461328\ttotal: 11.3s\tremaining: 21.3s\n",
      "347:\tlearn: 0.3457698\ttotal: 11.3s\tremaining: 21.2s\n",
      "348:\tlearn: 0.3454776\ttotal: 11.3s\tremaining: 21.2s\n",
      "349:\tlearn: 0.3451125\ttotal: 11.4s\tremaining: 21.1s\n",
      "350:\tlearn: 0.3449182\ttotal: 11.4s\tremaining: 21.1s\n",
      "351:\tlearn: 0.3448126\ttotal: 11.4s\tremaining: 21s\n",
      "352:\tlearn: 0.3443549\ttotal: 11.4s\tremaining: 20.9s\n",
      "353:\tlearn: 0.3441616\ttotal: 11.4s\tremaining: 20.9s\n",
      "354:\tlearn: 0.3438158\ttotal: 11.5s\tremaining: 20.8s\n",
      "355:\tlearn: 0.3435256\ttotal: 11.5s\tremaining: 20.8s\n",
      "356:\tlearn: 0.3431856\ttotal: 11.5s\tremaining: 20.7s\n",
      "357:\tlearn: 0.3428569\ttotal: 11.5s\tremaining: 20.7s\n",
      "358:\tlearn: 0.3424477\ttotal: 11.6s\tremaining: 20.6s\n",
      "359:\tlearn: 0.3420905\ttotal: 11.6s\tremaining: 20.6s\n",
      "360:\tlearn: 0.3417717\ttotal: 11.6s\tremaining: 20.5s\n",
      "361:\tlearn: 0.3413909\ttotal: 11.6s\tremaining: 20.5s\n",
      "362:\tlearn: 0.3412117\ttotal: 11.6s\tremaining: 20.4s\n",
      "363:\tlearn: 0.3409330\ttotal: 11.6s\tremaining: 20.3s\n",
      "364:\tlearn: 0.3406951\ttotal: 11.7s\tremaining: 20.3s\n",
      "365:\tlearn: 0.3404659\ttotal: 11.7s\tremaining: 20.2s\n",
      "366:\tlearn: 0.3402441\ttotal: 11.7s\tremaining: 20.2s\n",
      "367:\tlearn: 0.3400068\ttotal: 11.7s\tremaining: 20.1s\n",
      "368:\tlearn: 0.3396571\ttotal: 11.7s\tremaining: 20.1s\n",
      "369:\tlearn: 0.3392403\ttotal: 11.8s\tremaining: 20.1s\n",
      "370:\tlearn: 0.3389074\ttotal: 11.8s\tremaining: 20s\n",
      "371:\tlearn: 0.3386792\ttotal: 11.8s\tremaining: 20s\n",
      "372:\tlearn: 0.3383516\ttotal: 11.8s\tremaining: 19.9s\n",
      "373:\tlearn: 0.3381434\ttotal: 11.9s\tremaining: 19.8s\n",
      "374:\tlearn: 0.3376575\ttotal: 11.9s\tremaining: 19.8s\n",
      "375:\tlearn: 0.3372780\ttotal: 11.9s\tremaining: 19.7s\n",
      "376:\tlearn: 0.3369591\ttotal: 11.9s\tremaining: 19.7s\n",
      "377:\tlearn: 0.3366507\ttotal: 11.9s\tremaining: 19.6s\n",
      "378:\tlearn: 0.3364149\ttotal: 12s\tremaining: 19.6s\n",
      "379:\tlearn: 0.3361009\ttotal: 12s\tremaining: 19.6s\n",
      "380:\tlearn: 0.3358545\ttotal: 12s\tremaining: 19.6s\n",
      "381:\tlearn: 0.3357155\ttotal: 12.1s\tremaining: 19.5s\n",
      "382:\tlearn: 0.3352959\ttotal: 12.1s\tremaining: 19.4s\n",
      "383:\tlearn: 0.3350949\ttotal: 12.1s\tremaining: 19.4s\n",
      "384:\tlearn: 0.3348338\ttotal: 12.1s\tremaining: 19.3s\n",
      "385:\tlearn: 0.3345636\ttotal: 12.1s\tremaining: 19.3s\n",
      "386:\tlearn: 0.3343398\ttotal: 12.2s\tremaining: 19.3s\n",
      "387:\tlearn: 0.3339616\ttotal: 12.2s\tremaining: 19.2s\n",
      "388:\tlearn: 0.3335679\ttotal: 12.2s\tremaining: 19.1s\n",
      "389:\tlearn: 0.3331976\ttotal: 12.2s\tremaining: 19.1s\n",
      "390:\tlearn: 0.3329614\ttotal: 12.2s\tremaining: 19s\n",
      "391:\tlearn: 0.3327360\ttotal: 12.2s\tremaining: 19s\n",
      "392:\tlearn: 0.3323255\ttotal: 12.3s\tremaining: 18.9s\n",
      "393:\tlearn: 0.3319200\ttotal: 12.3s\tremaining: 18.9s\n",
      "394:\tlearn: 0.3314902\ttotal: 12.3s\tremaining: 18.9s\n",
      "395:\tlearn: 0.3310382\ttotal: 12.3s\tremaining: 18.8s\n",
      "396:\tlearn: 0.3307767\ttotal: 12.4s\tremaining: 18.8s\n",
      "397:\tlearn: 0.3306124\ttotal: 12.4s\tremaining: 18.7s\n",
      "398:\tlearn: 0.3303488\ttotal: 12.4s\tremaining: 18.7s\n",
      "399:\tlearn: 0.3300678\ttotal: 12.4s\tremaining: 18.6s\n",
      "400:\tlearn: 0.3297249\ttotal: 12.4s\tremaining: 18.6s\n",
      "401:\tlearn: 0.3293706\ttotal: 12.4s\tremaining: 18.5s\n",
      "402:\tlearn: 0.3290483\ttotal: 12.5s\tremaining: 18.5s\n",
      "403:\tlearn: 0.3286316\ttotal: 12.5s\tremaining: 18.4s\n",
      "404:\tlearn: 0.3283196\ttotal: 12.5s\tremaining: 18.4s\n",
      "405:\tlearn: 0.3280631\ttotal: 12.6s\tremaining: 18.4s\n",
      "406:\tlearn: 0.3277277\ttotal: 12.6s\tremaining: 18.3s\n",
      "407:\tlearn: 0.3273421\ttotal: 12.6s\tremaining: 18.3s\n",
      "408:\tlearn: 0.3270461\ttotal: 12.6s\tremaining: 18.2s\n",
      "409:\tlearn: 0.3266387\ttotal: 12.6s\tremaining: 18.2s\n",
      "410:\tlearn: 0.3264459\ttotal: 12.6s\tremaining: 18.1s\n",
      "411:\tlearn: 0.3261257\ttotal: 12.7s\tremaining: 18.1s\n",
      "412:\tlearn: 0.3258920\ttotal: 12.7s\tremaining: 18s\n",
      "413:\tlearn: 0.3256565\ttotal: 12.7s\tremaining: 18s\n",
      "414:\tlearn: 0.3251683\ttotal: 12.7s\tremaining: 17.9s\n",
      "415:\tlearn: 0.3250859\ttotal: 12.7s\tremaining: 17.9s\n",
      "416:\tlearn: 0.3248469\ttotal: 12.8s\tremaining: 17.9s\n",
      "417:\tlearn: 0.3243495\ttotal: 12.8s\tremaining: 17.8s\n",
      "418:\tlearn: 0.3242213\ttotal: 12.8s\tremaining: 17.8s\n",
      "419:\tlearn: 0.3239267\ttotal: 12.8s\tremaining: 17.7s\n",
      "420:\tlearn: 0.3234931\ttotal: 12.9s\tremaining: 17.7s\n",
      "421:\tlearn: 0.3233853\ttotal: 12.9s\tremaining: 17.6s\n",
      "422:\tlearn: 0.3231578\ttotal: 12.9s\tremaining: 17.6s\n",
      "423:\tlearn: 0.3229283\ttotal: 12.9s\tremaining: 17.6s\n",
      "424:\tlearn: 0.3226074\ttotal: 12.9s\tremaining: 17.5s\n",
      "425:\tlearn: 0.3224019\ttotal: 13s\tremaining: 17.5s\n",
      "426:\tlearn: 0.3220773\ttotal: 13s\tremaining: 17.4s\n",
      "427:\tlearn: 0.3217349\ttotal: 13s\tremaining: 17.4s\n",
      "428:\tlearn: 0.3213342\ttotal: 13s\tremaining: 17.3s\n",
      "429:\tlearn: 0.3209989\ttotal: 13.1s\tremaining: 17.3s\n",
      "430:\tlearn: 0.3208452\ttotal: 13.1s\tremaining: 17.3s\n",
      "431:\tlearn: 0.3206531\ttotal: 13.1s\tremaining: 17.3s\n",
      "432:\tlearn: 0.3201209\ttotal: 13.1s\tremaining: 17.2s\n",
      "433:\tlearn: 0.3199418\ttotal: 13.2s\tremaining: 17.2s\n",
      "434:\tlearn: 0.3195348\ttotal: 13.2s\tremaining: 17.1s\n",
      "435:\tlearn: 0.3193405\ttotal: 13.2s\tremaining: 17.1s\n",
      "436:\tlearn: 0.3191119\ttotal: 13.2s\tremaining: 17s\n",
      "437:\tlearn: 0.3188660\ttotal: 13.2s\tremaining: 17s\n",
      "438:\tlearn: 0.3187109\ttotal: 13.3s\tremaining: 16.9s\n",
      "439:\tlearn: 0.3183641\ttotal: 13.3s\tremaining: 16.9s\n",
      "440:\tlearn: 0.3180608\ttotal: 13.3s\tremaining: 16.8s\n",
      "441:\tlearn: 0.3176241\ttotal: 13.3s\tremaining: 16.8s\n",
      "442:\tlearn: 0.3171382\ttotal: 13.3s\tremaining: 16.8s\n",
      "443:\tlearn: 0.3167100\ttotal: 13.4s\tremaining: 16.7s\n",
      "444:\tlearn: 0.3165056\ttotal: 13.4s\tremaining: 16.7s\n",
      "445:\tlearn: 0.3162499\ttotal: 13.4s\tremaining: 16.6s\n",
      "446:\tlearn: 0.3160392\ttotal: 13.4s\tremaining: 16.6s\n",
      "447:\tlearn: 0.3157088\ttotal: 13.4s\tremaining: 16.6s\n",
      "448:\tlearn: 0.3153727\ttotal: 13.5s\tremaining: 16.5s\n",
      "449:\tlearn: 0.3150995\ttotal: 13.5s\tremaining: 16.5s\n",
      "450:\tlearn: 0.3148428\ttotal: 13.5s\tremaining: 16.4s\n",
      "451:\tlearn: 0.3145612\ttotal: 13.5s\tremaining: 16.4s\n",
      "452:\tlearn: 0.3142666\ttotal: 13.5s\tremaining: 16.3s\n",
      "453:\tlearn: 0.3139695\ttotal: 13.6s\tremaining: 16.3s\n",
      "454:\tlearn: 0.3137802\ttotal: 13.6s\tremaining: 16.3s\n",
      "455:\tlearn: 0.3136093\ttotal: 13.6s\tremaining: 16.2s\n",
      "456:\tlearn: 0.3134103\ttotal: 13.6s\tremaining: 16.2s\n",
      "457:\tlearn: 0.3130728\ttotal: 13.6s\tremaining: 16.1s\n",
      "458:\tlearn: 0.3127985\ttotal: 13.6s\tremaining: 16.1s\n",
      "459:\tlearn: 0.3126893\ttotal: 13.7s\tremaining: 16s\n",
      "460:\tlearn: 0.3124038\ttotal: 13.7s\tremaining: 16s\n",
      "461:\tlearn: 0.3121895\ttotal: 13.7s\tremaining: 16s\n",
      "462:\tlearn: 0.3120152\ttotal: 13.7s\tremaining: 15.9s\n",
      "463:\tlearn: 0.3117693\ttotal: 13.8s\tremaining: 15.9s\n",
      "464:\tlearn: 0.3115934\ttotal: 13.8s\tremaining: 15.9s\n",
      "465:\tlearn: 0.3113583\ttotal: 13.8s\tremaining: 15.8s\n",
      "466:\tlearn: 0.3110725\ttotal: 13.8s\tremaining: 15.8s\n",
      "467:\tlearn: 0.3107112\ttotal: 13.8s\tremaining: 15.7s\n",
      "468:\tlearn: 0.3104666\ttotal: 13.9s\tremaining: 15.7s\n",
      "469:\tlearn: 0.3101467\ttotal: 13.9s\tremaining: 15.6s\n",
      "470:\tlearn: 0.3097840\ttotal: 13.9s\tremaining: 15.6s\n",
      "471:\tlearn: 0.3095782\ttotal: 13.9s\tremaining: 15.6s\n",
      "472:\tlearn: 0.3091241\ttotal: 13.9s\tremaining: 15.5s\n",
      "473:\tlearn: 0.3089456\ttotal: 13.9s\tremaining: 15.5s\n",
      "474:\tlearn: 0.3088106\ttotal: 14s\tremaining: 15.4s\n",
      "475:\tlearn: 0.3086071\ttotal: 14s\tremaining: 15.4s\n",
      "476:\tlearn: 0.3083787\ttotal: 14s\tremaining: 15.4s\n",
      "477:\tlearn: 0.3080986\ttotal: 14s\tremaining: 15.3s\n",
      "478:\tlearn: 0.3077526\ttotal: 14.1s\tremaining: 15.3s\n",
      "479:\tlearn: 0.3075510\ttotal: 14.1s\tremaining: 15.2s\n",
      "480:\tlearn: 0.3074177\ttotal: 14.1s\tremaining: 15.2s\n",
      "481:\tlearn: 0.3072206\ttotal: 14.1s\tremaining: 15.2s\n",
      "482:\tlearn: 0.3069225\ttotal: 14.2s\tremaining: 15.2s\n",
      "483:\tlearn: 0.3067479\ttotal: 14.2s\tremaining: 15.1s\n",
      "484:\tlearn: 0.3065232\ttotal: 14.2s\tremaining: 15.1s\n",
      "485:\tlearn: 0.3063256\ttotal: 14.2s\tremaining: 15.1s\n",
      "486:\tlearn: 0.3060092\ttotal: 14.3s\tremaining: 15s\n",
      "487:\tlearn: 0.3058111\ttotal: 14.3s\tremaining: 15s\n",
      "488:\tlearn: 0.3056186\ttotal: 14.3s\tremaining: 14.9s\n",
      "489:\tlearn: 0.3053910\ttotal: 14.3s\tremaining: 14.9s\n",
      "490:\tlearn: 0.3052141\ttotal: 14.3s\tremaining: 14.8s\n",
      "491:\tlearn: 0.3050804\ttotal: 14.3s\tremaining: 14.8s\n",
      "492:\tlearn: 0.3047800\ttotal: 14.4s\tremaining: 14.8s\n",
      "493:\tlearn: 0.3045253\ttotal: 14.4s\tremaining: 14.7s\n",
      "494:\tlearn: 0.3043601\ttotal: 14.4s\tremaining: 14.7s\n",
      "495:\tlearn: 0.3041543\ttotal: 14.4s\tremaining: 14.7s\n",
      "496:\tlearn: 0.3038911\ttotal: 14.5s\tremaining: 14.6s\n",
      "497:\tlearn: 0.3037185\ttotal: 14.5s\tremaining: 14.6s\n",
      "498:\tlearn: 0.3036057\ttotal: 14.5s\tremaining: 14.5s\n",
      "499:\tlearn: 0.3034212\ttotal: 14.5s\tremaining: 14.5s\n",
      "500:\tlearn: 0.3031525\ttotal: 14.5s\tremaining: 14.5s\n",
      "501:\tlearn: 0.3027820\ttotal: 14.5s\tremaining: 14.4s\n",
      "502:\tlearn: 0.3025944\ttotal: 14.6s\tremaining: 14.4s\n",
      "503:\tlearn: 0.3023574\ttotal: 14.6s\tremaining: 14.3s\n",
      "504:\tlearn: 0.3021569\ttotal: 14.6s\tremaining: 14.3s\n",
      "505:\tlearn: 0.3018696\ttotal: 14.6s\tremaining: 14.3s\n",
      "506:\tlearn: 0.3016368\ttotal: 14.6s\tremaining: 14.2s\n",
      "507:\tlearn: 0.3014096\ttotal: 14.7s\tremaining: 14.2s\n",
      "508:\tlearn: 0.3011251\ttotal: 14.7s\tremaining: 14.2s\n",
      "509:\tlearn: 0.3009494\ttotal: 14.7s\tremaining: 14.1s\n",
      "510:\tlearn: 0.3006368\ttotal: 14.7s\tremaining: 14.1s\n",
      "511:\tlearn: 0.3004250\ttotal: 14.7s\tremaining: 14s\n",
      "512:\tlearn: 0.3000168\ttotal: 14.8s\tremaining: 14s\n",
      "513:\tlearn: 0.2996755\ttotal: 14.8s\tremaining: 14s\n",
      "514:\tlearn: 0.2993754\ttotal: 14.8s\tremaining: 13.9s\n",
      "515:\tlearn: 0.2992780\ttotal: 14.8s\tremaining: 13.9s\n",
      "516:\tlearn: 0.2988006\ttotal: 14.8s\tremaining: 13.9s\n",
      "517:\tlearn: 0.2984689\ttotal: 14.9s\tremaining: 13.8s\n",
      "518:\tlearn: 0.2983238\ttotal: 14.9s\tremaining: 13.8s\n",
      "519:\tlearn: 0.2981716\ttotal: 14.9s\tremaining: 13.7s\n",
      "520:\tlearn: 0.2980029\ttotal: 14.9s\tremaining: 13.7s\n",
      "521:\tlearn: 0.2978910\ttotal: 14.9s\tremaining: 13.7s\n",
      "522:\tlearn: 0.2976257\ttotal: 14.9s\tremaining: 13.6s\n",
      "523:\tlearn: 0.2975612\ttotal: 15s\tremaining: 13.6s\n",
      "524:\tlearn: 0.2972812\ttotal: 15s\tremaining: 13.6s\n",
      "525:\tlearn: 0.2970582\ttotal: 15s\tremaining: 13.5s\n",
      "526:\tlearn: 0.2968191\ttotal: 15s\tremaining: 13.5s\n",
      "527:\tlearn: 0.2966318\ttotal: 15.1s\tremaining: 13.5s\n",
      "528:\tlearn: 0.2963679\ttotal: 15.1s\tremaining: 13.4s\n",
      "529:\tlearn: 0.2961163\ttotal: 15.1s\tremaining: 13.4s\n",
      "530:\tlearn: 0.2959121\ttotal: 15.1s\tremaining: 13.3s\n",
      "531:\tlearn: 0.2956874\ttotal: 15.1s\tremaining: 13.3s\n",
      "532:\tlearn: 0.2953319\ttotal: 15.2s\tremaining: 13.3s\n",
      "533:\tlearn: 0.2950668\ttotal: 15.2s\tremaining: 13.3s\n",
      "534:\tlearn: 0.2949139\ttotal: 15.3s\tremaining: 13.3s\n",
      "535:\tlearn: 0.2946822\ttotal: 15.3s\tremaining: 13.2s\n",
      "536:\tlearn: 0.2945407\ttotal: 15.3s\tremaining: 13.2s\n",
      "537:\tlearn: 0.2943684\ttotal: 15.3s\tremaining: 13.1s\n",
      "538:\tlearn: 0.2940502\ttotal: 15.3s\tremaining: 13.1s\n",
      "539:\tlearn: 0.2939092\ttotal: 15.3s\tremaining: 13.1s\n",
      "540:\tlearn: 0.2936791\ttotal: 15.4s\tremaining: 13s\n",
      "541:\tlearn: 0.2934131\ttotal: 15.4s\tremaining: 13s\n",
      "542:\tlearn: 0.2931281\ttotal: 15.4s\tremaining: 13s\n",
      "543:\tlearn: 0.2929167\ttotal: 15.5s\tremaining: 13s\n",
      "544:\tlearn: 0.2926559\ttotal: 15.5s\tremaining: 12.9s\n",
      "545:\tlearn: 0.2923329\ttotal: 15.5s\tremaining: 12.9s\n",
      "546:\tlearn: 0.2921346\ttotal: 15.5s\tremaining: 12.9s\n",
      "547:\tlearn: 0.2920504\ttotal: 15.5s\tremaining: 12.8s\n",
      "548:\tlearn: 0.2917325\ttotal: 15.6s\tremaining: 12.8s\n",
      "549:\tlearn: 0.2914848\ttotal: 15.6s\tremaining: 12.7s\n",
      "550:\tlearn: 0.2912398\ttotal: 15.6s\tremaining: 12.7s\n",
      "551:\tlearn: 0.2910217\ttotal: 15.6s\tremaining: 12.7s\n",
      "552:\tlearn: 0.2908209\ttotal: 15.6s\tremaining: 12.6s\n",
      "553:\tlearn: 0.2906042\ttotal: 15.7s\tremaining: 12.6s\n",
      "554:\tlearn: 0.2903774\ttotal: 15.7s\tremaining: 12.6s\n",
      "555:\tlearn: 0.2900241\ttotal: 15.7s\tremaining: 12.5s\n",
      "556:\tlearn: 0.2897884\ttotal: 15.7s\tremaining: 12.5s\n",
      "557:\tlearn: 0.2894393\ttotal: 15.7s\tremaining: 12.5s\n",
      "558:\tlearn: 0.2890395\ttotal: 15.8s\tremaining: 12.4s\n",
      "559:\tlearn: 0.2887059\ttotal: 15.8s\tremaining: 12.4s\n",
      "560:\tlearn: 0.2883657\ttotal: 15.8s\tremaining: 12.4s\n",
      "561:\tlearn: 0.2879848\ttotal: 15.8s\tremaining: 12.3s\n",
      "562:\tlearn: 0.2877604\ttotal: 15.8s\tremaining: 12.3s\n",
      "563:\tlearn: 0.2875637\ttotal: 15.9s\tremaining: 12.3s\n",
      "564:\tlearn: 0.2873761\ttotal: 15.9s\tremaining: 12.2s\n",
      "565:\tlearn: 0.2871952\ttotal: 15.9s\tremaining: 12.2s\n",
      "566:\tlearn: 0.2870314\ttotal: 15.9s\tremaining: 12.2s\n",
      "567:\tlearn: 0.2869046\ttotal: 16s\tremaining: 12.1s\n",
      "568:\tlearn: 0.2865497\ttotal: 16s\tremaining: 12.1s\n",
      "569:\tlearn: 0.2864210\ttotal: 16s\tremaining: 12.1s\n",
      "570:\tlearn: 0.2862081\ttotal: 16s\tremaining: 12s\n",
      "571:\tlearn: 0.2858178\ttotal: 16s\tremaining: 12s\n",
      "572:\tlearn: 0.2857094\ttotal: 16s\tremaining: 12s\n",
      "573:\tlearn: 0.2854483\ttotal: 16.1s\tremaining: 11.9s\n",
      "574:\tlearn: 0.2852457\ttotal: 16.1s\tremaining: 11.9s\n",
      "575:\tlearn: 0.2850539\ttotal: 16.1s\tremaining: 11.8s\n",
      "576:\tlearn: 0.2847834\ttotal: 16.1s\tremaining: 11.8s\n",
      "577:\tlearn: 0.2846067\ttotal: 16.2s\tremaining: 11.8s\n",
      "578:\tlearn: 0.2843750\ttotal: 16.2s\tremaining: 11.8s\n",
      "579:\tlearn: 0.2841529\ttotal: 16.2s\tremaining: 11.8s\n",
      "580:\tlearn: 0.2839622\ttotal: 16.3s\tremaining: 11.7s\n",
      "581:\tlearn: 0.2836530\ttotal: 16.3s\tremaining: 11.7s\n",
      "582:\tlearn: 0.2832973\ttotal: 16.3s\tremaining: 11.7s\n",
      "583:\tlearn: 0.2829849\ttotal: 16.3s\tremaining: 11.6s\n",
      "584:\tlearn: 0.2828261\ttotal: 16.3s\tremaining: 11.6s\n",
      "585:\tlearn: 0.2826134\ttotal: 16.4s\tremaining: 11.6s\n",
      "586:\tlearn: 0.2824035\ttotal: 16.4s\tremaining: 11.5s\n",
      "587:\tlearn: 0.2821539\ttotal: 16.4s\tremaining: 11.5s\n",
      "588:\tlearn: 0.2818262\ttotal: 16.4s\tremaining: 11.5s\n",
      "589:\tlearn: 0.2816863\ttotal: 16.5s\tremaining: 11.4s\n",
      "590:\tlearn: 0.2813312\ttotal: 16.5s\tremaining: 11.4s\n",
      "591:\tlearn: 0.2810332\ttotal: 16.5s\tremaining: 11.4s\n",
      "592:\tlearn: 0.2807966\ttotal: 16.5s\tremaining: 11.3s\n",
      "593:\tlearn: 0.2806060\ttotal: 16.5s\tremaining: 11.3s\n",
      "594:\tlearn: 0.2803164\ttotal: 16.5s\tremaining: 11.3s\n",
      "595:\tlearn: 0.2798905\ttotal: 16.6s\tremaining: 11.2s\n",
      "596:\tlearn: 0.2797023\ttotal: 16.6s\tremaining: 11.2s\n",
      "597:\tlearn: 0.2795990\ttotal: 16.6s\tremaining: 11.2s\n",
      "598:\tlearn: 0.2792619\ttotal: 16.6s\tremaining: 11.1s\n",
      "599:\tlearn: 0.2789924\ttotal: 16.7s\tremaining: 11.1s\n",
      "600:\tlearn: 0.2785858\ttotal: 16.7s\tremaining: 11.1s\n",
      "601:\tlearn: 0.2783933\ttotal: 16.7s\tremaining: 11s\n",
      "602:\tlearn: 0.2782278\ttotal: 16.7s\tremaining: 11s\n",
      "603:\tlearn: 0.2780515\ttotal: 16.7s\tremaining: 11s\n",
      "604:\tlearn: 0.2779229\ttotal: 16.8s\tremaining: 10.9s\n",
      "605:\tlearn: 0.2777030\ttotal: 16.8s\tremaining: 10.9s\n",
      "606:\tlearn: 0.2775138\ttotal: 16.8s\tremaining: 10.9s\n",
      "607:\tlearn: 0.2772993\ttotal: 16.8s\tremaining: 10.8s\n",
      "608:\tlearn: 0.2771272\ttotal: 16.8s\tremaining: 10.8s\n",
      "609:\tlearn: 0.2769355\ttotal: 16.9s\tremaining: 10.8s\n",
      "610:\tlearn: 0.2767727\ttotal: 16.9s\tremaining: 10.8s\n",
      "611:\tlearn: 0.2766304\ttotal: 16.9s\tremaining: 10.7s\n",
      "612:\tlearn: 0.2765499\ttotal: 16.9s\tremaining: 10.7s\n",
      "613:\tlearn: 0.2763532\ttotal: 16.9s\tremaining: 10.6s\n",
      "614:\tlearn: 0.2760769\ttotal: 16.9s\tremaining: 10.6s\n",
      "615:\tlearn: 0.2758124\ttotal: 17s\tremaining: 10.6s\n",
      "616:\tlearn: 0.2755503\ttotal: 17s\tremaining: 10.6s\n",
      "617:\tlearn: 0.2753409\ttotal: 17s\tremaining: 10.5s\n",
      "618:\tlearn: 0.2752111\ttotal: 17.1s\tremaining: 10.5s\n",
      "619:\tlearn: 0.2747976\ttotal: 17.1s\tremaining: 10.5s\n",
      "620:\tlearn: 0.2746268\ttotal: 17.1s\tremaining: 10.4s\n",
      "621:\tlearn: 0.2743878\ttotal: 17.1s\tremaining: 10.4s\n",
      "622:\tlearn: 0.2740505\ttotal: 17.2s\tremaining: 10.4s\n",
      "623:\tlearn: 0.2738885\ttotal: 17.2s\tremaining: 10.4s\n",
      "624:\tlearn: 0.2737538\ttotal: 17.2s\tremaining: 10.3s\n",
      "625:\tlearn: 0.2735429\ttotal: 17.2s\tremaining: 10.3s\n",
      "626:\tlearn: 0.2733148\ttotal: 17.3s\tremaining: 10.3s\n",
      "627:\tlearn: 0.2730185\ttotal: 17.3s\tremaining: 10.2s\n",
      "628:\tlearn: 0.2728423\ttotal: 17.3s\tremaining: 10.2s\n",
      "629:\tlearn: 0.2726590\ttotal: 17.4s\tremaining: 10.2s\n",
      "630:\tlearn: 0.2724550\ttotal: 17.4s\tremaining: 10.2s\n",
      "631:\tlearn: 0.2722963\ttotal: 17.4s\tremaining: 10.1s\n",
      "632:\tlearn: 0.2721947\ttotal: 17.4s\tremaining: 10.1s\n",
      "633:\tlearn: 0.2720214\ttotal: 17.4s\tremaining: 10.1s\n",
      "634:\tlearn: 0.2719253\ttotal: 17.4s\tremaining: 10s\n",
      "635:\tlearn: 0.2715677\ttotal: 17.4s\tremaining: 9.99s\n",
      "636:\tlearn: 0.2713710\ttotal: 17.5s\tremaining: 9.95s\n",
      "637:\tlearn: 0.2710714\ttotal: 17.5s\tremaining: 9.92s\n",
      "638:\tlearn: 0.2708377\ttotal: 17.5s\tremaining: 9.89s\n",
      "639:\tlearn: 0.2706258\ttotal: 17.6s\tremaining: 9.88s\n",
      "640:\tlearn: 0.2705020\ttotal: 17.6s\tremaining: 9.85s\n",
      "641:\tlearn: 0.2702873\ttotal: 17.6s\tremaining: 9.82s\n",
      "642:\tlearn: 0.2700979\ttotal: 17.6s\tremaining: 9.79s\n",
      "643:\tlearn: 0.2698422\ttotal: 17.6s\tremaining: 9.76s\n",
      "644:\tlearn: 0.2696212\ttotal: 17.7s\tremaining: 9.72s\n",
      "645:\tlearn: 0.2692997\ttotal: 17.7s\tremaining: 9.69s\n",
      "646:\tlearn: 0.2690520\ttotal: 17.7s\tremaining: 9.65s\n",
      "647:\tlearn: 0.2688909\ttotal: 17.7s\tremaining: 9.62s\n",
      "648:\tlearn: 0.2686046\ttotal: 17.7s\tremaining: 9.59s\n",
      "649:\tlearn: 0.2681395\ttotal: 17.7s\tremaining: 9.55s\n",
      "650:\tlearn: 0.2680031\ttotal: 17.8s\tremaining: 9.52s\n",
      "651:\tlearn: 0.2678085\ttotal: 17.8s\tremaining: 9.49s\n",
      "652:\tlearn: 0.2675934\ttotal: 17.8s\tremaining: 9.48s\n",
      "653:\tlearn: 0.2674588\ttotal: 17.9s\tremaining: 9.45s\n",
      "654:\tlearn: 0.2672969\ttotal: 17.9s\tremaining: 9.41s\n",
      "655:\tlearn: 0.2670873\ttotal: 17.9s\tremaining: 9.38s\n",
      "656:\tlearn: 0.2669485\ttotal: 17.9s\tremaining: 9.35s\n",
      "657:\tlearn: 0.2666773\ttotal: 17.9s\tremaining: 9.31s\n",
      "658:\tlearn: 0.2664499\ttotal: 17.9s\tremaining: 9.28s\n",
      "659:\tlearn: 0.2662122\ttotal: 18s\tremaining: 9.25s\n",
      "660:\tlearn: 0.2660864\ttotal: 18s\tremaining: 9.22s\n",
      "661:\tlearn: 0.2658907\ttotal: 18s\tremaining: 9.18s\n",
      "662:\tlearn: 0.2656732\ttotal: 18s\tremaining: 9.15s\n",
      "663:\tlearn: 0.2654586\ttotal: 18s\tremaining: 9.12s\n",
      "664:\tlearn: 0.2650404\ttotal: 18.1s\tremaining: 9.11s\n",
      "665:\tlearn: 0.2649486\ttotal: 18.1s\tremaining: 9.07s\n",
      "666:\tlearn: 0.2647580\ttotal: 18.1s\tremaining: 9.04s\n",
      "667:\tlearn: 0.2645186\ttotal: 18.1s\tremaining: 9.01s\n",
      "668:\tlearn: 0.2643358\ttotal: 18.1s\tremaining: 8.98s\n",
      "669:\tlearn: 0.2642449\ttotal: 18.2s\tremaining: 8.95s\n",
      "670:\tlearn: 0.2640185\ttotal: 18.2s\tremaining: 8.92s\n",
      "671:\tlearn: 0.2638633\ttotal: 18.2s\tremaining: 8.89s\n",
      "672:\tlearn: 0.2634731\ttotal: 18.2s\tremaining: 8.86s\n",
      "673:\tlearn: 0.2633119\ttotal: 18.3s\tremaining: 8.84s\n",
      "674:\tlearn: 0.2631465\ttotal: 18.3s\tremaining: 8.82s\n",
      "675:\tlearn: 0.2628612\ttotal: 18.3s\tremaining: 8.79s\n",
      "676:\tlearn: 0.2627174\ttotal: 18.4s\tremaining: 8.76s\n",
      "677:\tlearn: 0.2625984\ttotal: 18.4s\tremaining: 8.73s\n",
      "678:\tlearn: 0.2623035\ttotal: 18.4s\tremaining: 8.69s\n",
      "679:\tlearn: 0.2620067\ttotal: 18.4s\tremaining: 8.66s\n",
      "680:\tlearn: 0.2618782\ttotal: 18.4s\tremaining: 8.63s\n",
      "681:\tlearn: 0.2617496\ttotal: 18.4s\tremaining: 8.6s\n",
      "682:\tlearn: 0.2614307\ttotal: 18.5s\tremaining: 8.57s\n",
      "683:\tlearn: 0.2613066\ttotal: 18.5s\tremaining: 8.54s\n",
      "684:\tlearn: 0.2611634\ttotal: 18.5s\tremaining: 8.51s\n",
      "685:\tlearn: 0.2608687\ttotal: 18.5s\tremaining: 8.48s\n",
      "686:\tlearn: 0.2607198\ttotal: 18.6s\tremaining: 8.46s\n",
      "687:\tlearn: 0.2605557\ttotal: 18.6s\tremaining: 8.43s\n",
      "688:\tlearn: 0.2602708\ttotal: 18.6s\tremaining: 8.39s\n",
      "689:\tlearn: 0.2600255\ttotal: 18.6s\tremaining: 8.36s\n",
      "690:\tlearn: 0.2598841\ttotal: 18.6s\tremaining: 8.33s\n",
      "691:\tlearn: 0.2596601\ttotal: 18.6s\tremaining: 8.3s\n",
      "692:\tlearn: 0.2594239\ttotal: 18.7s\tremaining: 8.27s\n",
      "693:\tlearn: 0.2591955\ttotal: 18.7s\tremaining: 8.23s\n",
      "694:\tlearn: 0.2590913\ttotal: 18.7s\tremaining: 8.2s\n",
      "695:\tlearn: 0.2589153\ttotal: 18.7s\tremaining: 8.18s\n",
      "696:\tlearn: 0.2587985\ttotal: 18.7s\tremaining: 8.15s\n",
      "697:\tlearn: 0.2586234\ttotal: 18.8s\tremaining: 8.12s\n",
      "698:\tlearn: 0.2584456\ttotal: 18.8s\tremaining: 8.09s\n",
      "699:\tlearn: 0.2582748\ttotal: 18.8s\tremaining: 8.06s\n",
      "700:\tlearn: 0.2580748\ttotal: 18.8s\tremaining: 8.03s\n",
      "701:\tlearn: 0.2577542\ttotal: 18.8s\tremaining: 8s\n",
      "702:\tlearn: 0.2576079\ttotal: 18.9s\tremaining: 7.97s\n",
      "703:\tlearn: 0.2574143\ttotal: 18.9s\tremaining: 7.94s\n",
      "704:\tlearn: 0.2571973\ttotal: 18.9s\tremaining: 7.91s\n",
      "705:\tlearn: 0.2570879\ttotal: 18.9s\tremaining: 7.87s\n",
      "706:\tlearn: 0.2569098\ttotal: 18.9s\tremaining: 7.84s\n",
      "707:\tlearn: 0.2566713\ttotal: 18.9s\tremaining: 7.81s\n",
      "708:\tlearn: 0.2565722\ttotal: 19s\tremaining: 7.79s\n",
      "709:\tlearn: 0.2564163\ttotal: 19s\tremaining: 7.76s\n",
      "710:\tlearn: 0.2562445\ttotal: 19s\tremaining: 7.73s\n",
      "711:\tlearn: 0.2561149\ttotal: 19s\tremaining: 7.7s\n",
      "712:\tlearn: 0.2558895\ttotal: 19.1s\tremaining: 7.67s\n",
      "713:\tlearn: 0.2556554\ttotal: 19.1s\tremaining: 7.64s\n",
      "714:\tlearn: 0.2553875\ttotal: 19.1s\tremaining: 7.61s\n",
      "715:\tlearn: 0.2552172\ttotal: 19.1s\tremaining: 7.58s\n",
      "716:\tlearn: 0.2550390\ttotal: 19.1s\tremaining: 7.54s\n",
      "717:\tlearn: 0.2549186\ttotal: 19.1s\tremaining: 7.51s\n",
      "718:\tlearn: 0.2548027\ttotal: 19.2s\tremaining: 7.49s\n",
      "719:\tlearn: 0.2545619\ttotal: 19.2s\tremaining: 7.45s\n",
      "720:\tlearn: 0.2544375\ttotal: 19.2s\tremaining: 7.43s\n",
      "721:\tlearn: 0.2542229\ttotal: 19.2s\tremaining: 7.41s\n",
      "722:\tlearn: 0.2541274\ttotal: 19.3s\tremaining: 7.38s\n",
      "723:\tlearn: 0.2539925\ttotal: 19.3s\tremaining: 7.36s\n",
      "724:\tlearn: 0.2536440\ttotal: 19.3s\tremaining: 7.33s\n",
      "725:\tlearn: 0.2533142\ttotal: 19.3s\tremaining: 7.3s\n",
      "726:\tlearn: 0.2532223\ttotal: 19.4s\tremaining: 7.27s\n",
      "727:\tlearn: 0.2530430\ttotal: 19.4s\tremaining: 7.24s\n",
      "728:\tlearn: 0.2529147\ttotal: 19.4s\tremaining: 7.21s\n",
      "729:\tlearn: 0.2527086\ttotal: 19.4s\tremaining: 7.18s\n",
      "730:\tlearn: 0.2524851\ttotal: 19.4s\tremaining: 7.16s\n",
      "731:\tlearn: 0.2523576\ttotal: 19.5s\tremaining: 7.13s\n",
      "732:\tlearn: 0.2522834\ttotal: 19.5s\tremaining: 7.1s\n",
      "733:\tlearn: 0.2522211\ttotal: 19.5s\tremaining: 7.07s\n",
      "734:\tlearn: 0.2520799\ttotal: 19.5s\tremaining: 7.04s\n",
      "735:\tlearn: 0.2517613\ttotal: 19.6s\tremaining: 7.03s\n",
      "736:\tlearn: 0.2515979\ttotal: 19.6s\tremaining: 7s\n",
      "737:\tlearn: 0.2514600\ttotal: 19.6s\tremaining: 6.97s\n",
      "738:\tlearn: 0.2511246\ttotal: 19.6s\tremaining: 6.94s\n",
      "739:\tlearn: 0.2510133\ttotal: 19.7s\tremaining: 6.91s\n",
      "740:\tlearn: 0.2508034\ttotal: 19.7s\tremaining: 6.88s\n",
      "741:\tlearn: 0.2505977\ttotal: 19.7s\tremaining: 6.86s\n",
      "742:\tlearn: 0.2502945\ttotal: 19.7s\tremaining: 6.83s\n",
      "743:\tlearn: 0.2499488\ttotal: 19.8s\tremaining: 6.8s\n",
      "744:\tlearn: 0.2498219\ttotal: 19.8s\tremaining: 6.77s\n",
      "745:\tlearn: 0.2497382\ttotal: 19.8s\tremaining: 6.74s\n",
      "746:\tlearn: 0.2494939\ttotal: 19.8s\tremaining: 6.71s\n",
      "747:\tlearn: 0.2491969\ttotal: 19.8s\tremaining: 6.68s\n",
      "748:\tlearn: 0.2490658\ttotal: 19.9s\tremaining: 6.65s\n",
      "749:\tlearn: 0.2488134\ttotal: 19.9s\tremaining: 6.62s\n",
      "750:\tlearn: 0.2486314\ttotal: 19.9s\tremaining: 6.59s\n",
      "751:\tlearn: 0.2482950\ttotal: 19.9s\tremaining: 6.56s\n",
      "752:\tlearn: 0.2479686\ttotal: 19.9s\tremaining: 6.54s\n",
      "753:\tlearn: 0.2478616\ttotal: 20s\tremaining: 6.51s\n",
      "754:\tlearn: 0.2476351\ttotal: 20s\tremaining: 6.49s\n",
      "755:\tlearn: 0.2474545\ttotal: 20s\tremaining: 6.46s\n",
      "756:\tlearn: 0.2472769\ttotal: 20s\tremaining: 6.43s\n",
      "757:\tlearn: 0.2472018\ttotal: 20.1s\tremaining: 6.41s\n",
      "758:\tlearn: 0.2470528\ttotal: 20.1s\tremaining: 6.38s\n",
      "759:\tlearn: 0.2468623\ttotal: 20.1s\tremaining: 6.35s\n",
      "760:\tlearn: 0.2465884\ttotal: 20.1s\tremaining: 6.32s\n",
      "761:\tlearn: 0.2462898\ttotal: 20.1s\tremaining: 6.29s\n",
      "762:\tlearn: 0.2461529\ttotal: 20.1s\tremaining: 6.26s\n",
      "763:\tlearn: 0.2460287\ttotal: 20.2s\tremaining: 6.24s\n",
      "764:\tlearn: 0.2458190\ttotal: 20.2s\tremaining: 6.22s\n",
      "765:\tlearn: 0.2455750\ttotal: 20.3s\tremaining: 6.19s\n",
      "766:\tlearn: 0.2453599\ttotal: 20.3s\tremaining: 6.16s\n",
      "767:\tlearn: 0.2452113\ttotal: 20.3s\tremaining: 6.13s\n",
      "768:\tlearn: 0.2451168\ttotal: 20.3s\tremaining: 6.11s\n",
      "769:\tlearn: 0.2448224\ttotal: 20.4s\tremaining: 6.08s\n",
      "770:\tlearn: 0.2446854\ttotal: 20.4s\tremaining: 6.05s\n",
      "771:\tlearn: 0.2445280\ttotal: 20.4s\tremaining: 6.02s\n",
      "772:\tlearn: 0.2443740\ttotal: 20.4s\tremaining: 6s\n",
      "773:\tlearn: 0.2441406\ttotal: 20.5s\tremaining: 5.97s\n",
      "774:\tlearn: 0.2439130\ttotal: 20.5s\tremaining: 5.94s\n",
      "775:\tlearn: 0.2436291\ttotal: 20.5s\tremaining: 5.91s\n",
      "776:\tlearn: 0.2433699\ttotal: 20.5s\tremaining: 5.88s\n",
      "777:\tlearn: 0.2431409\ttotal: 20.5s\tremaining: 5.85s\n",
      "778:\tlearn: 0.2428541\ttotal: 20.5s\tremaining: 5.83s\n",
      "779:\tlearn: 0.2426630\ttotal: 20.6s\tremaining: 5.8s\n",
      "780:\tlearn: 0.2424823\ttotal: 20.6s\tremaining: 5.77s\n",
      "781:\tlearn: 0.2421586\ttotal: 20.6s\tremaining: 5.74s\n",
      "782:\tlearn: 0.2418168\ttotal: 20.6s\tremaining: 5.72s\n",
      "783:\tlearn: 0.2416844\ttotal: 20.6s\tremaining: 5.69s\n",
      "784:\tlearn: 0.2413485\ttotal: 20.7s\tremaining: 5.66s\n",
      "785:\tlearn: 0.2412347\ttotal: 20.7s\tremaining: 5.64s\n",
      "786:\tlearn: 0.2410820\ttotal: 20.7s\tremaining: 5.61s\n",
      "787:\tlearn: 0.2408579\ttotal: 20.7s\tremaining: 5.58s\n",
      "788:\tlearn: 0.2406076\ttotal: 20.8s\tremaining: 5.55s\n",
      "789:\tlearn: 0.2404943\ttotal: 20.8s\tremaining: 5.52s\n",
      "790:\tlearn: 0.2403064\ttotal: 20.8s\tremaining: 5.49s\n",
      "791:\tlearn: 0.2401476\ttotal: 20.8s\tremaining: 5.47s\n",
      "792:\tlearn: 0.2398722\ttotal: 20.8s\tremaining: 5.44s\n",
      "793:\tlearn: 0.2397387\ttotal: 20.8s\tremaining: 5.41s\n",
      "794:\tlearn: 0.2395777\ttotal: 20.9s\tremaining: 5.38s\n",
      "795:\tlearn: 0.2394367\ttotal: 20.9s\tremaining: 5.35s\n",
      "796:\tlearn: 0.2393034\ttotal: 20.9s\tremaining: 5.33s\n",
      "797:\tlearn: 0.2391335\ttotal: 20.9s\tremaining: 5.3s\n",
      "798:\tlearn: 0.2390372\ttotal: 20.9s\tremaining: 5.27s\n",
      "799:\tlearn: 0.2388884\ttotal: 21s\tremaining: 5.24s\n",
      "800:\tlearn: 0.2386773\ttotal: 21s\tremaining: 5.21s\n",
      "801:\tlearn: 0.2384957\ttotal: 21s\tremaining: 5.19s\n",
      "802:\tlearn: 0.2383024\ttotal: 21s\tremaining: 5.16s\n",
      "803:\tlearn: 0.2381832\ttotal: 21s\tremaining: 5.13s\n",
      "804:\tlearn: 0.2380698\ttotal: 21.1s\tremaining: 5.1s\n",
      "805:\tlearn: 0.2377579\ttotal: 21.1s\tremaining: 5.07s\n",
      "806:\tlearn: 0.2375716\ttotal: 21.1s\tremaining: 5.04s\n",
      "807:\tlearn: 0.2373055\ttotal: 21.1s\tremaining: 5.02s\n",
      "808:\tlearn: 0.2370162\ttotal: 21.1s\tremaining: 4.99s\n",
      "809:\tlearn: 0.2367769\ttotal: 21.1s\tremaining: 4.96s\n",
      "810:\tlearn: 0.2365220\ttotal: 21.2s\tremaining: 4.94s\n",
      "811:\tlearn: 0.2362566\ttotal: 21.2s\tremaining: 4.91s\n",
      "812:\tlearn: 0.2359286\ttotal: 21.2s\tremaining: 4.88s\n",
      "813:\tlearn: 0.2357336\ttotal: 21.3s\tremaining: 4.86s\n",
      "814:\tlearn: 0.2355627\ttotal: 21.3s\tremaining: 4.83s\n",
      "815:\tlearn: 0.2353569\ttotal: 21.3s\tremaining: 4.8s\n",
      "816:\tlearn: 0.2352118\ttotal: 21.3s\tremaining: 4.77s\n",
      "817:\tlearn: 0.2351182\ttotal: 21.3s\tremaining: 4.74s\n",
      "818:\tlearn: 0.2348522\ttotal: 21.3s\tremaining: 4.71s\n",
      "819:\tlearn: 0.2346307\ttotal: 21.4s\tremaining: 4.69s\n",
      "820:\tlearn: 0.2344713\ttotal: 21.4s\tremaining: 4.67s\n",
      "821:\tlearn: 0.2341884\ttotal: 21.4s\tremaining: 4.64s\n",
      "822:\tlearn: 0.2339358\ttotal: 21.5s\tremaining: 4.62s\n",
      "823:\tlearn: 0.2337815\ttotal: 21.5s\tremaining: 4.59s\n",
      "824:\tlearn: 0.2335029\ttotal: 21.5s\tremaining: 4.56s\n",
      "825:\tlearn: 0.2333314\ttotal: 21.5s\tremaining: 4.54s\n",
      "826:\tlearn: 0.2331548\ttotal: 21.5s\tremaining: 4.51s\n",
      "827:\tlearn: 0.2330141\ttotal: 21.6s\tremaining: 4.48s\n",
      "828:\tlearn: 0.2327827\ttotal: 21.6s\tremaining: 4.45s\n",
      "829:\tlearn: 0.2327005\ttotal: 21.6s\tremaining: 4.42s\n",
      "830:\tlearn: 0.2325083\ttotal: 21.6s\tremaining: 4.4s\n",
      "831:\tlearn: 0.2322377\ttotal: 21.7s\tremaining: 4.37s\n",
      "832:\tlearn: 0.2320544\ttotal: 21.7s\tremaining: 4.34s\n",
      "833:\tlearn: 0.2317252\ttotal: 21.7s\tremaining: 4.32s\n",
      "834:\tlearn: 0.2315271\ttotal: 21.7s\tremaining: 4.29s\n",
      "835:\tlearn: 0.2312555\ttotal: 21.7s\tremaining: 4.26s\n",
      "836:\tlearn: 0.2310290\ttotal: 21.7s\tremaining: 4.23s\n",
      "837:\tlearn: 0.2308516\ttotal: 21.7s\tremaining: 4.2s\n",
      "838:\tlearn: 0.2306427\ttotal: 21.8s\tremaining: 4.18s\n",
      "839:\tlearn: 0.2303439\ttotal: 21.8s\tremaining: 4.15s\n",
      "840:\tlearn: 0.2301429\ttotal: 21.8s\tremaining: 4.12s\n",
      "841:\tlearn: 0.2297406\ttotal: 21.8s\tremaining: 4.1s\n",
      "842:\tlearn: 0.2295671\ttotal: 21.8s\tremaining: 4.07s\n",
      "843:\tlearn: 0.2292939\ttotal: 21.9s\tremaining: 4.04s\n",
      "844:\tlearn: 0.2290757\ttotal: 21.9s\tremaining: 4.01s\n",
      "845:\tlearn: 0.2288152\ttotal: 21.9s\tremaining: 3.99s\n",
      "846:\tlearn: 0.2285583\ttotal: 21.9s\tremaining: 3.96s\n",
      "847:\tlearn: 0.2283868\ttotal: 21.9s\tremaining: 3.93s\n",
      "848:\tlearn: 0.2282217\ttotal: 22s\tremaining: 3.9s\n",
      "849:\tlearn: 0.2278873\ttotal: 22s\tremaining: 3.88s\n",
      "850:\tlearn: 0.2276970\ttotal: 22s\tremaining: 3.85s\n",
      "851:\tlearn: 0.2275029\ttotal: 22s\tremaining: 3.83s\n",
      "852:\tlearn: 0.2272734\ttotal: 22s\tremaining: 3.8s\n",
      "853:\tlearn: 0.2271639\ttotal: 22.1s\tremaining: 3.77s\n",
      "854:\tlearn: 0.2270169\ttotal: 22.1s\tremaining: 3.74s\n",
      "855:\tlearn: 0.2268057\ttotal: 22.1s\tremaining: 3.71s\n",
      "856:\tlearn: 0.2267164\ttotal: 22.1s\tremaining: 3.69s\n",
      "857:\tlearn: 0.2265588\ttotal: 22.1s\tremaining: 3.67s\n",
      "858:\tlearn: 0.2263828\ttotal: 22.2s\tremaining: 3.64s\n",
      "859:\tlearn: 0.2261692\ttotal: 22.2s\tremaining: 3.61s\n",
      "860:\tlearn: 0.2258905\ttotal: 22.2s\tremaining: 3.59s\n",
      "861:\tlearn: 0.2256248\ttotal: 22.2s\tremaining: 3.56s\n",
      "862:\tlearn: 0.2255468\ttotal: 22.3s\tremaining: 3.54s\n",
      "863:\tlearn: 0.2253092\ttotal: 22.3s\tremaining: 3.51s\n",
      "864:\tlearn: 0.2251273\ttotal: 22.3s\tremaining: 3.49s\n",
      "865:\tlearn: 0.2249330\ttotal: 22.4s\tremaining: 3.46s\n",
      "866:\tlearn: 0.2246679\ttotal: 22.4s\tremaining: 3.43s\n",
      "867:\tlearn: 0.2245340\ttotal: 22.4s\tremaining: 3.4s\n",
      "868:\tlearn: 0.2243870\ttotal: 22.4s\tremaining: 3.38s\n",
      "869:\tlearn: 0.2242469\ttotal: 22.4s\tremaining: 3.35s\n",
      "870:\tlearn: 0.2240865\ttotal: 22.4s\tremaining: 3.32s\n",
      "871:\tlearn: 0.2239476\ttotal: 22.5s\tremaining: 3.3s\n",
      "872:\tlearn: 0.2237017\ttotal: 22.5s\tremaining: 3.27s\n",
      "873:\tlearn: 0.2236106\ttotal: 22.5s\tremaining: 3.25s\n",
      "874:\tlearn: 0.2233899\ttotal: 22.6s\tremaining: 3.22s\n",
      "875:\tlearn: 0.2232446\ttotal: 22.6s\tremaining: 3.2s\n",
      "876:\tlearn: 0.2229979\ttotal: 22.6s\tremaining: 3.17s\n",
      "877:\tlearn: 0.2227808\ttotal: 22.6s\tremaining: 3.14s\n",
      "878:\tlearn: 0.2225168\ttotal: 22.6s\tremaining: 3.12s\n",
      "879:\tlearn: 0.2222556\ttotal: 22.7s\tremaining: 3.09s\n",
      "880:\tlearn: 0.2220915\ttotal: 22.7s\tremaining: 3.06s\n",
      "881:\tlearn: 0.2218770\ttotal: 22.7s\tremaining: 3.04s\n",
      "882:\tlearn: 0.2217739\ttotal: 22.7s\tremaining: 3.01s\n",
      "883:\tlearn: 0.2215291\ttotal: 22.8s\tremaining: 2.99s\n",
      "884:\tlearn: 0.2212885\ttotal: 22.8s\tremaining: 2.96s\n",
      "885:\tlearn: 0.2211557\ttotal: 22.8s\tremaining: 2.93s\n",
      "886:\tlearn: 0.2210481\ttotal: 22.8s\tremaining: 2.91s\n",
      "887:\tlearn: 0.2209243\ttotal: 22.8s\tremaining: 2.88s\n",
      "888:\tlearn: 0.2207666\ttotal: 22.9s\tremaining: 2.85s\n",
      "889:\tlearn: 0.2205236\ttotal: 22.9s\tremaining: 2.83s\n",
      "890:\tlearn: 0.2201928\ttotal: 22.9s\tremaining: 2.8s\n",
      "891:\tlearn: 0.2199523\ttotal: 22.9s\tremaining: 2.77s\n",
      "892:\tlearn: 0.2197570\ttotal: 22.9s\tremaining: 2.75s\n",
      "893:\tlearn: 0.2196101\ttotal: 22.9s\tremaining: 2.72s\n",
      "894:\tlearn: 0.2195107\ttotal: 23s\tremaining: 2.7s\n",
      "895:\tlearn: 0.2193821\ttotal: 23s\tremaining: 2.67s\n",
      "896:\tlearn: 0.2191691\ttotal: 23s\tremaining: 2.64s\n",
      "897:\tlearn: 0.2190059\ttotal: 23s\tremaining: 2.62s\n",
      "898:\tlearn: 0.2187658\ttotal: 23s\tremaining: 2.59s\n",
      "899:\tlearn: 0.2185822\ttotal: 23.1s\tremaining: 2.56s\n",
      "900:\tlearn: 0.2183850\ttotal: 23.1s\tremaining: 2.54s\n",
      "901:\tlearn: 0.2182549\ttotal: 23.1s\tremaining: 2.51s\n",
      "902:\tlearn: 0.2181571\ttotal: 23.1s\tremaining: 2.48s\n",
      "903:\tlearn: 0.2179736\ttotal: 23.1s\tremaining: 2.46s\n",
      "904:\tlearn: 0.2177631\ttotal: 23.1s\tremaining: 2.43s\n",
      "905:\tlearn: 0.2175590\ttotal: 23.2s\tremaining: 2.4s\n",
      "906:\tlearn: 0.2172732\ttotal: 23.2s\tremaining: 2.38s\n",
      "907:\tlearn: 0.2171481\ttotal: 23.2s\tremaining: 2.35s\n",
      "908:\tlearn: 0.2169569\ttotal: 23.3s\tremaining: 2.33s\n",
      "909:\tlearn: 0.2168450\ttotal: 23.3s\tremaining: 2.3s\n",
      "910:\tlearn: 0.2166308\ttotal: 23.3s\tremaining: 2.27s\n",
      "911:\tlearn: 0.2164805\ttotal: 23.3s\tremaining: 2.25s\n",
      "912:\tlearn: 0.2161993\ttotal: 23.3s\tremaining: 2.22s\n",
      "913:\tlearn: 0.2160422\ttotal: 23.4s\tremaining: 2.2s\n",
      "914:\tlearn: 0.2159595\ttotal: 23.4s\tremaining: 2.17s\n",
      "915:\tlearn: 0.2157471\ttotal: 23.4s\tremaining: 2.15s\n",
      "916:\tlearn: 0.2156016\ttotal: 23.5s\tremaining: 2.12s\n",
      "917:\tlearn: 0.2154777\ttotal: 23.5s\tremaining: 2.1s\n",
      "918:\tlearn: 0.2153255\ttotal: 23.5s\tremaining: 2.07s\n",
      "919:\tlearn: 0.2151873\ttotal: 23.5s\tremaining: 2.04s\n",
      "920:\tlearn: 0.2150433\ttotal: 23.5s\tremaining: 2.02s\n",
      "921:\tlearn: 0.2148430\ttotal: 23.6s\tremaining: 1.99s\n",
      "922:\tlearn: 0.2145790\ttotal: 23.6s\tremaining: 1.97s\n",
      "923:\tlearn: 0.2142871\ttotal: 23.6s\tremaining: 1.94s\n",
      "924:\tlearn: 0.2141556\ttotal: 23.6s\tremaining: 1.91s\n",
      "925:\tlearn: 0.2139014\ttotal: 23.6s\tremaining: 1.89s\n",
      "926:\tlearn: 0.2138249\ttotal: 23.6s\tremaining: 1.86s\n",
      "927:\tlearn: 0.2135371\ttotal: 23.7s\tremaining: 1.84s\n",
      "928:\tlearn: 0.2133421\ttotal: 23.7s\tremaining: 1.81s\n",
      "929:\tlearn: 0.2132143\ttotal: 23.7s\tremaining: 1.78s\n",
      "930:\tlearn: 0.2130318\ttotal: 23.7s\tremaining: 1.76s\n",
      "931:\tlearn: 0.2127377\ttotal: 23.8s\tremaining: 1.73s\n",
      "932:\tlearn: 0.2125247\ttotal: 23.8s\tremaining: 1.71s\n",
      "933:\tlearn: 0.2123193\ttotal: 23.8s\tremaining: 1.68s\n",
      "934:\tlearn: 0.2122101\ttotal: 23.8s\tremaining: 1.65s\n",
      "935:\tlearn: 0.2119168\ttotal: 23.8s\tremaining: 1.63s\n",
      "936:\tlearn: 0.2117213\ttotal: 23.8s\tremaining: 1.6s\n",
      "937:\tlearn: 0.2116125\ttotal: 23.8s\tremaining: 1.58s\n",
      "938:\tlearn: 0.2114289\ttotal: 23.9s\tremaining: 1.55s\n",
      "939:\tlearn: 0.2112596\ttotal: 23.9s\tremaining: 1.52s\n",
      "940:\tlearn: 0.2110871\ttotal: 23.9s\tremaining: 1.5s\n",
      "941:\tlearn: 0.2108868\ttotal: 23.9s\tremaining: 1.47s\n",
      "942:\tlearn: 0.2106978\ttotal: 24s\tremaining: 1.45s\n",
      "943:\tlearn: 0.2104394\ttotal: 24s\tremaining: 1.42s\n",
      "944:\tlearn: 0.2102695\ttotal: 24s\tremaining: 1.4s\n",
      "945:\tlearn: 0.2100855\ttotal: 24s\tremaining: 1.37s\n",
      "946:\tlearn: 0.2099459\ttotal: 24.1s\tremaining: 1.35s\n",
      "947:\tlearn: 0.2098016\ttotal: 24.1s\tremaining: 1.32s\n",
      "948:\tlearn: 0.2094958\ttotal: 24.1s\tremaining: 1.29s\n",
      "949:\tlearn: 0.2091883\ttotal: 24.1s\tremaining: 1.27s\n",
      "950:\tlearn: 0.2090508\ttotal: 24.1s\tremaining: 1.24s\n",
      "951:\tlearn: 0.2087332\ttotal: 24.2s\tremaining: 1.22s\n",
      "952:\tlearn: 0.2085931\ttotal: 24.2s\tremaining: 1.19s\n",
      "953:\tlearn: 0.2082782\ttotal: 24.2s\tremaining: 1.17s\n",
      "954:\tlearn: 0.2081313\ttotal: 24.2s\tremaining: 1.14s\n",
      "955:\tlearn: 0.2080111\ttotal: 24.3s\tremaining: 1.12s\n",
      "956:\tlearn: 0.2079009\ttotal: 24.3s\tremaining: 1.09s\n",
      "957:\tlearn: 0.2078037\ttotal: 24.3s\tremaining: 1.06s\n",
      "958:\tlearn: 0.2075183\ttotal: 24.3s\tremaining: 1.04s\n",
      "959:\tlearn: 0.2073485\ttotal: 24.3s\tremaining: 1.01s\n",
      "960:\tlearn: 0.2070291\ttotal: 24.3s\tremaining: 988ms\n",
      "961:\tlearn: 0.2068027\ttotal: 24.4s\tremaining: 964ms\n",
      "962:\tlearn: 0.2066233\ttotal: 24.4s\tremaining: 939ms\n",
      "963:\tlearn: 0.2064604\ttotal: 24.5s\tremaining: 913ms\n",
      "964:\tlearn: 0.2062672\ttotal: 24.5s\tremaining: 888ms\n",
      "965:\tlearn: 0.2059871\ttotal: 24.5s\tremaining: 862ms\n",
      "966:\tlearn: 0.2058294\ttotal: 24.5s\tremaining: 836ms\n",
      "967:\tlearn: 0.2057204\ttotal: 24.5s\tremaining: 810ms\n",
      "968:\tlearn: 0.2055063\ttotal: 24.5s\tremaining: 785ms\n",
      "969:\tlearn: 0.2053941\ttotal: 24.5s\tremaining: 759ms\n",
      "970:\tlearn: 0.2053037\ttotal: 24.6s\tremaining: 734ms\n",
      "971:\tlearn: 0.2051266\ttotal: 24.6s\tremaining: 708ms\n",
      "972:\tlearn: 0.2049671\ttotal: 24.6s\tremaining: 683ms\n",
      "973:\tlearn: 0.2047794\ttotal: 24.6s\tremaining: 658ms\n",
      "974:\tlearn: 0.2046112\ttotal: 24.7s\tremaining: 633ms\n",
      "975:\tlearn: 0.2044792\ttotal: 24.7s\tremaining: 607ms\n",
      "976:\tlearn: 0.2043209\ttotal: 24.7s\tremaining: 582ms\n",
      "977:\tlearn: 0.2042446\ttotal: 24.7s\tremaining: 556ms\n",
      "978:\tlearn: 0.2039515\ttotal: 24.7s\tremaining: 531ms\n",
      "979:\tlearn: 0.2038280\ttotal: 24.8s\tremaining: 506ms\n",
      "980:\tlearn: 0.2035881\ttotal: 24.8s\tremaining: 481ms\n",
      "981:\tlearn: 0.2034764\ttotal: 24.8s\tremaining: 455ms\n",
      "982:\tlearn: 0.2033914\ttotal: 24.8s\tremaining: 430ms\n",
      "983:\tlearn: 0.2030876\ttotal: 24.9s\tremaining: 404ms\n",
      "984:\tlearn: 0.2028828\ttotal: 24.9s\tremaining: 379ms\n",
      "985:\tlearn: 0.2027058\ttotal: 24.9s\tremaining: 354ms\n",
      "986:\tlearn: 0.2025616\ttotal: 24.9s\tremaining: 328ms\n",
      "987:\tlearn: 0.2023848\ttotal: 24.9s\tremaining: 303ms\n",
      "988:\tlearn: 0.2021858\ttotal: 25s\tremaining: 278ms\n",
      "989:\tlearn: 0.2019444\ttotal: 25s\tremaining: 252ms\n",
      "990:\tlearn: 0.2017271\ttotal: 25s\tremaining: 227ms\n",
      "991:\tlearn: 0.2014729\ttotal: 25s\tremaining: 202ms\n",
      "992:\tlearn: 0.2013336\ttotal: 25s\tremaining: 177ms\n",
      "993:\tlearn: 0.2011435\ttotal: 25.1s\tremaining: 151ms\n",
      "994:\tlearn: 0.2010428\ttotal: 25.1s\tremaining: 126ms\n",
      "995:\tlearn: 0.2008880\ttotal: 25.1s\tremaining: 101ms\n",
      "996:\tlearn: 0.2006816\ttotal: 25.1s\tremaining: 75.6ms\n",
      "997:\tlearn: 0.2004119\ttotal: 25.1s\tremaining: 50.4ms\n",
      "998:\tlearn: 0.2001546\ttotal: 25.2s\tremaining: 25.2ms\n",
      "999:\tlearn: 0.2000277\ttotal: 25.2s\tremaining: 0us\n",
      "Accuracy, fold_1: 0.8130081300813008\n",
      "Learning rate set to 0.007604\n",
      "0:\tlearn: 0.6884705\ttotal: 20.1ms\tremaining: 20.1s\n",
      "1:\tlearn: 0.6839647\ttotal: 35.9ms\tremaining: 17.9s\n",
      "2:\tlearn: 0.6798054\ttotal: 57.9ms\tremaining: 19.2s\n",
      "3:\tlearn: 0.6758363\ttotal: 78.4ms\tremaining: 19.5s\n",
      "4:\tlearn: 0.6716509\ttotal: 99.5ms\tremaining: 19.8s\n",
      "5:\tlearn: 0.6672817\ttotal: 116ms\tremaining: 19.3s\n",
      "6:\tlearn: 0.6633780\ttotal: 133ms\tremaining: 18.9s\n",
      "7:\tlearn: 0.6592721\ttotal: 153ms\tremaining: 19s\n",
      "8:\tlearn: 0.6555305\ttotal: 179ms\tremaining: 19.7s\n",
      "9:\tlearn: 0.6518458\ttotal: 197ms\tremaining: 19.5s\n",
      "10:\tlearn: 0.6481362\ttotal: 215ms\tremaining: 19.3s\n",
      "11:\tlearn: 0.6447008\ttotal: 229ms\tremaining: 18.9s\n",
      "12:\tlearn: 0.6413936\ttotal: 246ms\tremaining: 18.7s\n",
      "13:\tlearn: 0.6379386\ttotal: 262ms\tremaining: 18.4s\n",
      "14:\tlearn: 0.6347044\ttotal: 277ms\tremaining: 18.2s\n",
      "15:\tlearn: 0.6316234\ttotal: 293ms\tremaining: 18s\n",
      "16:\tlearn: 0.6284290\ttotal: 322ms\tremaining: 18.6s\n",
      "17:\tlearn: 0.6249387\ttotal: 347ms\tremaining: 18.9s\n",
      "18:\tlearn: 0.6214677\ttotal: 369ms\tremaining: 19s\n",
      "19:\tlearn: 0.6185066\ttotal: 397ms\tremaining: 19.5s\n",
      "20:\tlearn: 0.6152429\ttotal: 416ms\tremaining: 19.4s\n",
      "21:\tlearn: 0.6122024\ttotal: 432ms\tremaining: 19.2s\n",
      "22:\tlearn: 0.6092046\ttotal: 447ms\tremaining: 19s\n",
      "23:\tlearn: 0.6058491\ttotal: 465ms\tremaining: 18.9s\n",
      "24:\tlearn: 0.6029303\ttotal: 478ms\tremaining: 18.7s\n",
      "25:\tlearn: 0.5996582\ttotal: 494ms\tremaining: 18.5s\n",
      "26:\tlearn: 0.5969724\ttotal: 512ms\tremaining: 18.4s\n",
      "27:\tlearn: 0.5940562\ttotal: 532ms\tremaining: 18.5s\n",
      "28:\tlearn: 0.5910611\ttotal: 567ms\tremaining: 19s\n",
      "29:\tlearn: 0.5883533\ttotal: 588ms\tremaining: 19s\n",
      "30:\tlearn: 0.5855745\ttotal: 620ms\tremaining: 19.4s\n",
      "31:\tlearn: 0.5828011\ttotal: 639ms\tremaining: 19.3s\n",
      "32:\tlearn: 0.5802793\ttotal: 660ms\tremaining: 19.3s\n",
      "33:\tlearn: 0.5781466\ttotal: 664ms\tremaining: 18.9s\n",
      "34:\tlearn: 0.5757023\ttotal: 686ms\tremaining: 18.9s\n",
      "35:\tlearn: 0.5733384\ttotal: 707ms\tremaining: 18.9s\n",
      "36:\tlearn: 0.5707449\ttotal: 732ms\tremaining: 19.1s\n",
      "37:\tlearn: 0.5682196\ttotal: 753ms\tremaining: 19.1s\n",
      "38:\tlearn: 0.5657709\ttotal: 779ms\tremaining: 19.2s\n",
      "39:\tlearn: 0.5629929\ttotal: 814ms\tremaining: 19.5s\n",
      "40:\tlearn: 0.5606112\ttotal: 861ms\tremaining: 20.1s\n",
      "41:\tlearn: 0.5584367\ttotal: 882ms\tremaining: 20.1s\n",
      "42:\tlearn: 0.5561789\ttotal: 903ms\tremaining: 20.1s\n",
      "43:\tlearn: 0.5539415\ttotal: 943ms\tremaining: 20.5s\n",
      "44:\tlearn: 0.5519458\ttotal: 970ms\tremaining: 20.6s\n",
      "45:\tlearn: 0.5492433\ttotal: 990ms\tremaining: 20.5s\n",
      "46:\tlearn: 0.5468859\ttotal: 1.01s\tremaining: 20.4s\n",
      "47:\tlearn: 0.5447461\ttotal: 1.03s\tremaining: 20.4s\n",
      "48:\tlearn: 0.5429632\ttotal: 1.07s\tremaining: 20.9s\n",
      "49:\tlearn: 0.5407929\ttotal: 1.09s\tremaining: 20.7s\n",
      "50:\tlearn: 0.5387359\ttotal: 1.11s\tremaining: 20.6s\n",
      "51:\tlearn: 0.5367682\ttotal: 1.12s\tremaining: 20.4s\n",
      "52:\tlearn: 0.5345221\ttotal: 1.14s\tremaining: 20.4s\n",
      "53:\tlearn: 0.5324958\ttotal: 1.16s\tremaining: 20.2s\n",
      "54:\tlearn: 0.5306450\ttotal: 1.17s\tremaining: 20.1s\n",
      "55:\tlearn: 0.5290003\ttotal: 1.19s\tremaining: 20s\n",
      "56:\tlearn: 0.5273979\ttotal: 1.24s\tremaining: 20.5s\n",
      "57:\tlearn: 0.5254507\ttotal: 1.26s\tremaining: 20.5s\n",
      "58:\tlearn: 0.5238771\ttotal: 1.28s\tremaining: 20.4s\n",
      "59:\tlearn: 0.5221731\ttotal: 1.3s\tremaining: 20.4s\n",
      "60:\tlearn: 0.5201148\ttotal: 1.32s\tremaining: 20.3s\n",
      "61:\tlearn: 0.5185581\ttotal: 1.34s\tremaining: 20.2s\n",
      "62:\tlearn: 0.5168440\ttotal: 1.35s\tremaining: 20.2s\n",
      "63:\tlearn: 0.5149673\ttotal: 1.37s\tremaining: 20s\n",
      "64:\tlearn: 0.5132346\ttotal: 1.39s\tremaining: 20s\n",
      "65:\tlearn: 0.5117090\ttotal: 1.41s\tremaining: 20s\n",
      "66:\tlearn: 0.5102292\ttotal: 1.44s\tremaining: 20s\n",
      "67:\tlearn: 0.5085727\ttotal: 1.45s\tremaining: 19.9s\n",
      "68:\tlearn: 0.5066377\ttotal: 1.47s\tremaining: 19.9s\n",
      "69:\tlearn: 0.5048853\ttotal: 1.49s\tremaining: 19.8s\n",
      "70:\tlearn: 0.5032561\ttotal: 1.51s\tremaining: 19.7s\n",
      "71:\tlearn: 0.5018969\ttotal: 1.55s\tremaining: 20s\n",
      "72:\tlearn: 0.5004192\ttotal: 1.57s\tremaining: 19.9s\n",
      "73:\tlearn: 0.4990973\ttotal: 1.58s\tremaining: 19.8s\n",
      "74:\tlearn: 0.4975841\ttotal: 1.6s\tremaining: 19.8s\n",
      "75:\tlearn: 0.4968257\ttotal: 1.62s\tremaining: 19.7s\n",
      "76:\tlearn: 0.4953147\ttotal: 1.65s\tremaining: 19.8s\n",
      "77:\tlearn: 0.4939337\ttotal: 1.67s\tremaining: 19.7s\n",
      "78:\tlearn: 0.4925773\ttotal: 1.69s\tremaining: 19.7s\n",
      "79:\tlearn: 0.4911724\ttotal: 1.7s\tremaining: 19.6s\n",
      "80:\tlearn: 0.4898454\ttotal: 1.72s\tremaining: 19.5s\n",
      "81:\tlearn: 0.4887088\ttotal: 1.73s\tremaining: 19.4s\n",
      "82:\tlearn: 0.4873507\ttotal: 1.75s\tremaining: 19.3s\n",
      "83:\tlearn: 0.4856682\ttotal: 1.76s\tremaining: 19.3s\n",
      "84:\tlearn: 0.4842765\ttotal: 1.79s\tremaining: 19.3s\n",
      "85:\tlearn: 0.4829681\ttotal: 1.81s\tremaining: 19.2s\n",
      "86:\tlearn: 0.4815612\ttotal: 1.83s\tremaining: 19.2s\n",
      "87:\tlearn: 0.4802323\ttotal: 1.85s\tremaining: 19.2s\n",
      "88:\tlearn: 0.4788636\ttotal: 1.87s\tremaining: 19.2s\n",
      "89:\tlearn: 0.4776976\ttotal: 1.89s\tremaining: 19.1s\n",
      "90:\tlearn: 0.4771233\ttotal: 1.9s\tremaining: 19s\n",
      "91:\tlearn: 0.4759475\ttotal: 1.92s\tremaining: 19s\n",
      "92:\tlearn: 0.4747126\ttotal: 1.93s\tremaining: 18.9s\n",
      "93:\tlearn: 0.4736995\ttotal: 1.95s\tremaining: 18.8s\n",
      "94:\tlearn: 0.4724624\ttotal: 1.99s\tremaining: 19s\n",
      "95:\tlearn: 0.4715670\ttotal: 2.04s\tremaining: 19.2s\n",
      "96:\tlearn: 0.4702603\ttotal: 2.07s\tremaining: 19.2s\n",
      "97:\tlearn: 0.4691690\ttotal: 2.09s\tremaining: 19.3s\n",
      "98:\tlearn: 0.4679841\ttotal: 2.11s\tremaining: 19.2s\n",
      "99:\tlearn: 0.4667620\ttotal: 2.13s\tremaining: 19.1s\n",
      "100:\tlearn: 0.4656132\ttotal: 2.14s\tremaining: 19s\n",
      "101:\tlearn: 0.4646644\ttotal: 2.16s\tremaining: 19s\n",
      "102:\tlearn: 0.4635597\ttotal: 2.17s\tremaining: 18.9s\n",
      "103:\tlearn: 0.4626913\ttotal: 2.19s\tremaining: 18.9s\n",
      "104:\tlearn: 0.4618353\ttotal: 2.21s\tremaining: 18.8s\n",
      "105:\tlearn: 0.4607275\ttotal: 2.22s\tremaining: 18.8s\n",
      "106:\tlearn: 0.4593719\ttotal: 2.24s\tremaining: 18.7s\n",
      "107:\tlearn: 0.4587818\ttotal: 2.26s\tremaining: 18.7s\n",
      "108:\tlearn: 0.4577175\ttotal: 2.31s\tremaining: 18.9s\n",
      "109:\tlearn: 0.4568741\ttotal: 2.33s\tremaining: 18.8s\n",
      "110:\tlearn: 0.4559299\ttotal: 2.34s\tremaining: 18.8s\n",
      "111:\tlearn: 0.4551761\ttotal: 2.36s\tremaining: 18.7s\n",
      "112:\tlearn: 0.4542346\ttotal: 2.37s\tremaining: 18.6s\n",
      "113:\tlearn: 0.4532045\ttotal: 2.39s\tremaining: 18.6s\n",
      "114:\tlearn: 0.4525344\ttotal: 2.41s\tremaining: 18.5s\n",
      "115:\tlearn: 0.4515321\ttotal: 2.42s\tremaining: 18.5s\n",
      "116:\tlearn: 0.4509140\ttotal: 2.44s\tremaining: 18.4s\n",
      "117:\tlearn: 0.4497629\ttotal: 2.46s\tremaining: 18.4s\n",
      "118:\tlearn: 0.4490096\ttotal: 2.48s\tremaining: 18.4s\n",
      "119:\tlearn: 0.4480518\ttotal: 2.51s\tremaining: 18.4s\n",
      "120:\tlearn: 0.4474447\ttotal: 2.54s\tremaining: 18.5s\n",
      "121:\tlearn: 0.4465700\ttotal: 2.56s\tremaining: 18.4s\n",
      "122:\tlearn: 0.4454875\ttotal: 2.58s\tremaining: 18.4s\n",
      "123:\tlearn: 0.4444854\ttotal: 2.59s\tremaining: 18.3s\n",
      "124:\tlearn: 0.4436255\ttotal: 2.61s\tremaining: 18.3s\n",
      "125:\tlearn: 0.4425565\ttotal: 2.62s\tremaining: 18.2s\n",
      "126:\tlearn: 0.4418082\ttotal: 2.64s\tremaining: 18.2s\n",
      "127:\tlearn: 0.4411569\ttotal: 2.66s\tremaining: 18.1s\n",
      "128:\tlearn: 0.4403278\ttotal: 2.69s\tremaining: 18.1s\n",
      "129:\tlearn: 0.4399337\ttotal: 2.72s\tremaining: 18.2s\n",
      "130:\tlearn: 0.4394400\ttotal: 2.73s\tremaining: 18.1s\n",
      "131:\tlearn: 0.4385654\ttotal: 2.75s\tremaining: 18.1s\n",
      "132:\tlearn: 0.4378642\ttotal: 2.77s\tremaining: 18.1s\n",
      "133:\tlearn: 0.4370796\ttotal: 2.79s\tremaining: 18.1s\n",
      "134:\tlearn: 0.4364067\ttotal: 2.81s\tremaining: 18s\n",
      "135:\tlearn: 0.4355670\ttotal: 2.83s\tremaining: 18s\n",
      "136:\tlearn: 0.4348019\ttotal: 2.85s\tremaining: 17.9s\n",
      "137:\tlearn: 0.4341429\ttotal: 2.86s\tremaining: 17.9s\n",
      "138:\tlearn: 0.4334731\ttotal: 2.88s\tremaining: 17.9s\n",
      "139:\tlearn: 0.4324162\ttotal: 2.91s\tremaining: 17.9s\n",
      "140:\tlearn: 0.4317208\ttotal: 2.93s\tremaining: 17.9s\n",
      "141:\tlearn: 0.4310784\ttotal: 2.94s\tremaining: 17.8s\n",
      "142:\tlearn: 0.4306380\ttotal: 2.96s\tremaining: 17.8s\n",
      "143:\tlearn: 0.4298040\ttotal: 2.98s\tremaining: 17.7s\n",
      "144:\tlearn: 0.4290986\ttotal: 3s\tremaining: 17.7s\n",
      "145:\tlearn: 0.4287191\ttotal: 3.02s\tremaining: 17.7s\n",
      "146:\tlearn: 0.4278841\ttotal: 3.06s\tremaining: 17.8s\n",
      "147:\tlearn: 0.4271206\ttotal: 3.11s\tremaining: 17.9s\n",
      "148:\tlearn: 0.4263682\ttotal: 3.13s\tremaining: 17.9s\n",
      "149:\tlearn: 0.4257857\ttotal: 3.15s\tremaining: 17.8s\n",
      "150:\tlearn: 0.4250640\ttotal: 3.16s\tremaining: 17.8s\n",
      "151:\tlearn: 0.4244100\ttotal: 3.18s\tremaining: 17.7s\n",
      "152:\tlearn: 0.4237022\ttotal: 3.19s\tremaining: 17.7s\n",
      "153:\tlearn: 0.4232048\ttotal: 3.21s\tremaining: 17.6s\n",
      "154:\tlearn: 0.4227059\ttotal: 3.23s\tremaining: 17.6s\n",
      "155:\tlearn: 0.4219774\ttotal: 3.24s\tremaining: 17.5s\n",
      "156:\tlearn: 0.4215257\ttotal: 3.27s\tremaining: 17.5s\n",
      "157:\tlearn: 0.4210932\ttotal: 3.29s\tremaining: 17.5s\n",
      "158:\tlearn: 0.4204072\ttotal: 3.32s\tremaining: 17.6s\n",
      "159:\tlearn: 0.4200080\ttotal: 3.34s\tremaining: 17.5s\n",
      "160:\tlearn: 0.4196822\ttotal: 3.35s\tremaining: 17.4s\n",
      "161:\tlearn: 0.4191592\ttotal: 3.36s\tremaining: 17.4s\n",
      "162:\tlearn: 0.4186261\ttotal: 3.38s\tremaining: 17.3s\n",
      "163:\tlearn: 0.4182295\ttotal: 3.39s\tremaining: 17.3s\n",
      "164:\tlearn: 0.4177639\ttotal: 3.41s\tremaining: 17.2s\n",
      "165:\tlearn: 0.4172872\ttotal: 3.42s\tremaining: 17.2s\n",
      "166:\tlearn: 0.4166800\ttotal: 3.44s\tremaining: 17.2s\n",
      "167:\tlearn: 0.4162536\ttotal: 3.46s\tremaining: 17.1s\n",
      "168:\tlearn: 0.4157901\ttotal: 3.47s\tremaining: 17.1s\n",
      "169:\tlearn: 0.4151731\ttotal: 3.49s\tremaining: 17.1s\n",
      "170:\tlearn: 0.4148587\ttotal: 3.55s\tremaining: 17.2s\n",
      "171:\tlearn: 0.4143883\ttotal: 3.57s\tremaining: 17.2s\n",
      "172:\tlearn: 0.4137867\ttotal: 3.58s\tremaining: 17.1s\n",
      "173:\tlearn: 0.4131399\ttotal: 3.6s\tremaining: 17.1s\n",
      "174:\tlearn: 0.4126736\ttotal: 3.61s\tremaining: 17s\n",
      "175:\tlearn: 0.4120025\ttotal: 3.71s\tremaining: 17.4s\n",
      "176:\tlearn: 0.4116783\ttotal: 3.76s\tremaining: 17.5s\n",
      "177:\tlearn: 0.4113094\ttotal: 3.8s\tremaining: 17.5s\n",
      "178:\tlearn: 0.4107926\ttotal: 3.81s\tremaining: 17.5s\n",
      "179:\tlearn: 0.4104089\ttotal: 3.83s\tremaining: 17.4s\n",
      "180:\tlearn: 0.4098724\ttotal: 3.85s\tremaining: 17.4s\n",
      "181:\tlearn: 0.4094178\ttotal: 3.86s\tremaining: 17.4s\n",
      "182:\tlearn: 0.4088402\ttotal: 3.88s\tremaining: 17.3s\n",
      "183:\tlearn: 0.4081905\ttotal: 3.89s\tremaining: 17.3s\n",
      "184:\tlearn: 0.4077578\ttotal: 3.91s\tremaining: 17.2s\n",
      "185:\tlearn: 0.4073006\ttotal: 3.93s\tremaining: 17.2s\n",
      "186:\tlearn: 0.4068266\ttotal: 3.96s\tremaining: 17.2s\n",
      "187:\tlearn: 0.4062534\ttotal: 3.98s\tremaining: 17.2s\n",
      "188:\tlearn: 0.4058459\ttotal: 4.02s\tremaining: 17.2s\n",
      "189:\tlearn: 0.4052258\ttotal: 4.03s\tremaining: 17.2s\n",
      "190:\tlearn: 0.4046396\ttotal: 4.05s\tremaining: 17.2s\n",
      "191:\tlearn: 0.4042458\ttotal: 4.07s\tremaining: 17.1s\n",
      "192:\tlearn: 0.4037529\ttotal: 4.08s\tremaining: 17.1s\n",
      "193:\tlearn: 0.4033977\ttotal: 4.11s\tremaining: 17.1s\n",
      "194:\tlearn: 0.4031025\ttotal: 4.15s\tremaining: 17.1s\n",
      "195:\tlearn: 0.4027613\ttotal: 4.17s\tremaining: 17.1s\n",
      "196:\tlearn: 0.4020411\ttotal: 4.2s\tremaining: 17.1s\n",
      "197:\tlearn: 0.4016722\ttotal: 4.22s\tremaining: 17.1s\n",
      "198:\tlearn: 0.4010533\ttotal: 4.24s\tremaining: 17.1s\n",
      "199:\tlearn: 0.4002854\ttotal: 4.26s\tremaining: 17.1s\n",
      "200:\tlearn: 0.3995517\ttotal: 4.28s\tremaining: 17s\n",
      "201:\tlearn: 0.3992205\ttotal: 4.29s\tremaining: 17s\n",
      "202:\tlearn: 0.3986724\ttotal: 4.31s\tremaining: 16.9s\n",
      "203:\tlearn: 0.3981980\ttotal: 4.33s\tremaining: 16.9s\n",
      "204:\tlearn: 0.3977900\ttotal: 4.34s\tremaining: 16.9s\n",
      "205:\tlearn: 0.3973417\ttotal: 4.36s\tremaining: 16.8s\n",
      "206:\tlearn: 0.3969551\ttotal: 4.38s\tremaining: 16.8s\n",
      "207:\tlearn: 0.3963150\ttotal: 4.42s\tremaining: 16.8s\n",
      "208:\tlearn: 0.3956104\ttotal: 4.43s\tremaining: 16.8s\n",
      "209:\tlearn: 0.3950841\ttotal: 4.45s\tremaining: 16.7s\n",
      "210:\tlearn: 0.3943569\ttotal: 4.47s\tremaining: 16.7s\n",
      "211:\tlearn: 0.3938957\ttotal: 4.49s\tremaining: 16.7s\n",
      "212:\tlearn: 0.3934052\ttotal: 4.52s\tremaining: 16.7s\n",
      "213:\tlearn: 0.3930360\ttotal: 4.54s\tremaining: 16.7s\n",
      "214:\tlearn: 0.3927795\ttotal: 4.55s\tremaining: 16.6s\n",
      "215:\tlearn: 0.3923584\ttotal: 4.57s\tremaining: 16.6s\n",
      "216:\tlearn: 0.3919687\ttotal: 4.59s\tremaining: 16.6s\n",
      "217:\tlearn: 0.3916230\ttotal: 4.62s\tremaining: 16.6s\n",
      "218:\tlearn: 0.3912909\ttotal: 4.64s\tremaining: 16.5s\n",
      "219:\tlearn: 0.3908346\ttotal: 4.66s\tremaining: 16.5s\n",
      "220:\tlearn: 0.3905096\ttotal: 4.67s\tremaining: 16.5s\n",
      "221:\tlearn: 0.3902254\ttotal: 4.69s\tremaining: 16.4s\n",
      "222:\tlearn: 0.3898158\ttotal: 4.71s\tremaining: 16.4s\n",
      "223:\tlearn: 0.3894706\ttotal: 4.74s\tremaining: 16.4s\n",
      "224:\tlearn: 0.3889512\ttotal: 4.75s\tremaining: 16.4s\n",
      "225:\tlearn: 0.3883898\ttotal: 4.77s\tremaining: 16.3s\n",
      "226:\tlearn: 0.3878198\ttotal: 4.79s\tremaining: 16.3s\n",
      "227:\tlearn: 0.3872379\ttotal: 4.82s\tremaining: 16.3s\n",
      "228:\tlearn: 0.3868294\ttotal: 4.84s\tremaining: 16.3s\n",
      "229:\tlearn: 0.3864679\ttotal: 4.86s\tremaining: 16.3s\n",
      "230:\tlearn: 0.3860169\ttotal: 4.87s\tremaining: 16.2s\n",
      "231:\tlearn: 0.3856461\ttotal: 4.89s\tremaining: 16.2s\n",
      "232:\tlearn: 0.3853898\ttotal: 4.91s\tremaining: 16.1s\n",
      "233:\tlearn: 0.3850365\ttotal: 4.92s\tremaining: 16.1s\n",
      "234:\tlearn: 0.3846921\ttotal: 4.94s\tremaining: 16.1s\n",
      "235:\tlearn: 0.3840644\ttotal: 4.96s\tremaining: 16.1s\n",
      "236:\tlearn: 0.3836761\ttotal: 5s\tremaining: 16.1s\n",
      "237:\tlearn: 0.3832942\ttotal: 5.02s\tremaining: 16.1s\n",
      "238:\tlearn: 0.3828843\ttotal: 5.04s\tremaining: 16.1s\n",
      "239:\tlearn: 0.3823507\ttotal: 5.06s\tremaining: 16s\n",
      "240:\tlearn: 0.3818147\ttotal: 5.08s\tremaining: 16s\n",
      "241:\tlearn: 0.3815177\ttotal: 5.09s\tremaining: 16s\n",
      "242:\tlearn: 0.3810964\ttotal: 5.11s\tremaining: 15.9s\n",
      "243:\tlearn: 0.3807811\ttotal: 5.13s\tremaining: 15.9s\n",
      "244:\tlearn: 0.3803175\ttotal: 5.16s\tremaining: 15.9s\n",
      "245:\tlearn: 0.3799362\ttotal: 5.2s\tremaining: 15.9s\n",
      "246:\tlearn: 0.3795522\ttotal: 5.24s\tremaining: 16s\n",
      "247:\tlearn: 0.3791115\ttotal: 5.26s\tremaining: 15.9s\n",
      "248:\tlearn: 0.3786073\ttotal: 5.28s\tremaining: 15.9s\n",
      "249:\tlearn: 0.3783763\ttotal: 5.29s\tremaining: 15.9s\n",
      "250:\tlearn: 0.3780663\ttotal: 5.31s\tremaining: 15.8s\n",
      "251:\tlearn: 0.3777467\ttotal: 5.33s\tremaining: 15.8s\n",
      "252:\tlearn: 0.3772938\ttotal: 5.34s\tremaining: 15.8s\n",
      "253:\tlearn: 0.3769689\ttotal: 5.36s\tremaining: 15.7s\n",
      "254:\tlearn: 0.3766929\ttotal: 5.38s\tremaining: 15.7s\n",
      "255:\tlearn: 0.3761767\ttotal: 5.41s\tremaining: 15.7s\n",
      "256:\tlearn: 0.3759518\ttotal: 5.43s\tremaining: 15.7s\n",
      "257:\tlearn: 0.3754860\ttotal: 5.45s\tremaining: 15.7s\n",
      "258:\tlearn: 0.3752846\ttotal: 5.49s\tremaining: 15.7s\n",
      "259:\tlearn: 0.3748170\ttotal: 5.51s\tremaining: 15.7s\n",
      "260:\tlearn: 0.3743579\ttotal: 5.53s\tremaining: 15.6s\n",
      "261:\tlearn: 0.3740369\ttotal: 5.54s\tremaining: 15.6s\n",
      "262:\tlearn: 0.3736286\ttotal: 5.56s\tremaining: 15.6s\n",
      "263:\tlearn: 0.3732500\ttotal: 5.58s\tremaining: 15.6s\n",
      "264:\tlearn: 0.3727579\ttotal: 5.61s\tremaining: 15.6s\n",
      "265:\tlearn: 0.3723255\ttotal: 5.63s\tremaining: 15.5s\n",
      "266:\tlearn: 0.3719919\ttotal: 5.65s\tremaining: 15.5s\n",
      "267:\tlearn: 0.3714916\ttotal: 5.66s\tremaining: 15.5s\n",
      "268:\tlearn: 0.3711008\ttotal: 5.68s\tremaining: 15.4s\n",
      "269:\tlearn: 0.3708333\ttotal: 5.69s\tremaining: 15.4s\n",
      "270:\tlearn: 0.3705700\ttotal: 5.73s\tremaining: 15.4s\n",
      "271:\tlearn: 0.3700153\ttotal: 5.74s\tremaining: 15.4s\n",
      "272:\tlearn: 0.3695148\ttotal: 5.76s\tremaining: 15.3s\n",
      "273:\tlearn: 0.3692329\ttotal: 5.78s\tremaining: 15.3s\n",
      "274:\tlearn: 0.3688104\ttotal: 5.8s\tremaining: 15.3s\n",
      "275:\tlearn: 0.3683971\ttotal: 5.82s\tremaining: 15.3s\n",
      "276:\tlearn: 0.3678369\ttotal: 5.84s\tremaining: 15.2s\n",
      "277:\tlearn: 0.3674708\ttotal: 5.85s\tremaining: 15.2s\n",
      "278:\tlearn: 0.3672062\ttotal: 5.87s\tremaining: 15.2s\n",
      "279:\tlearn: 0.3667813\ttotal: 5.88s\tremaining: 15.1s\n",
      "280:\tlearn: 0.3661658\ttotal: 5.9s\tremaining: 15.1s\n",
      "281:\tlearn: 0.3658689\ttotal: 5.91s\tremaining: 15.1s\n",
      "282:\tlearn: 0.3657214\ttotal: 5.93s\tremaining: 15s\n",
      "283:\tlearn: 0.3654901\ttotal: 5.95s\tremaining: 15s\n",
      "284:\tlearn: 0.3651330\ttotal: 5.99s\tremaining: 15s\n",
      "285:\tlearn: 0.3647877\ttotal: 6.01s\tremaining: 15s\n",
      "286:\tlearn: 0.3645542\ttotal: 6.04s\tremaining: 15s\n",
      "287:\tlearn: 0.3642654\ttotal: 6.06s\tremaining: 15s\n",
      "288:\tlearn: 0.3638528\ttotal: 6.08s\tremaining: 14.9s\n",
      "289:\tlearn: 0.3636219\ttotal: 6.09s\tremaining: 14.9s\n",
      "290:\tlearn: 0.3633172\ttotal: 6.11s\tremaining: 14.9s\n",
      "291:\tlearn: 0.3630494\ttotal: 6.13s\tremaining: 14.9s\n",
      "292:\tlearn: 0.3627103\ttotal: 6.15s\tremaining: 14.8s\n",
      "293:\tlearn: 0.3622422\ttotal: 6.16s\tremaining: 14.8s\n",
      "294:\tlearn: 0.3618700\ttotal: 6.18s\tremaining: 14.8s\n",
      "295:\tlearn: 0.3615844\ttotal: 6.23s\tremaining: 14.8s\n",
      "296:\tlearn: 0.3613362\ttotal: 6.27s\tremaining: 14.9s\n",
      "297:\tlearn: 0.3607544\ttotal: 6.29s\tremaining: 14.8s\n",
      "298:\tlearn: 0.3604924\ttotal: 6.31s\tremaining: 14.8s\n",
      "299:\tlearn: 0.3601174\ttotal: 6.33s\tremaining: 14.8s\n",
      "300:\tlearn: 0.3597855\ttotal: 6.35s\tremaining: 14.7s\n",
      "301:\tlearn: 0.3592845\ttotal: 6.36s\tremaining: 14.7s\n",
      "302:\tlearn: 0.3589905\ttotal: 6.39s\tremaining: 14.7s\n",
      "303:\tlearn: 0.3587232\ttotal: 6.41s\tremaining: 14.7s\n",
      "304:\tlearn: 0.3583630\ttotal: 6.43s\tremaining: 14.7s\n",
      "305:\tlearn: 0.3580195\ttotal: 6.46s\tremaining: 14.7s\n",
      "306:\tlearn: 0.3577609\ttotal: 6.48s\tremaining: 14.6s\n",
      "307:\tlearn: 0.3575019\ttotal: 6.5s\tremaining: 14.6s\n",
      "308:\tlearn: 0.3570914\ttotal: 6.51s\tremaining: 14.6s\n",
      "309:\tlearn: 0.3567139\ttotal: 6.53s\tremaining: 14.5s\n",
      "310:\tlearn: 0.3565180\ttotal: 6.55s\tremaining: 14.5s\n",
      "311:\tlearn: 0.3562396\ttotal: 6.56s\tremaining: 14.5s\n",
      "312:\tlearn: 0.3558386\ttotal: 6.59s\tremaining: 14.5s\n",
      "313:\tlearn: 0.3555133\ttotal: 6.61s\tremaining: 14.4s\n",
      "314:\tlearn: 0.3551968\ttotal: 6.63s\tremaining: 14.4s\n",
      "315:\tlearn: 0.3548688\ttotal: 6.65s\tremaining: 14.4s\n",
      "316:\tlearn: 0.3544683\ttotal: 6.67s\tremaining: 14.4s\n",
      "317:\tlearn: 0.3542193\ttotal: 6.68s\tremaining: 14.3s\n",
      "318:\tlearn: 0.3540023\ttotal: 6.71s\tremaining: 14.3s\n",
      "319:\tlearn: 0.3537122\ttotal: 6.73s\tremaining: 14.3s\n",
      "320:\tlearn: 0.3531452\ttotal: 6.75s\tremaining: 14.3s\n",
      "321:\tlearn: 0.3528056\ttotal: 6.76s\tremaining: 14.2s\n",
      "322:\tlearn: 0.3524104\ttotal: 6.78s\tremaining: 14.2s\n",
      "323:\tlearn: 0.3521043\ttotal: 6.84s\tremaining: 14.3s\n",
      "324:\tlearn: 0.3518867\ttotal: 6.85s\tremaining: 14.2s\n",
      "325:\tlearn: 0.3516973\ttotal: 6.87s\tremaining: 14.2s\n",
      "326:\tlearn: 0.3514518\ttotal: 6.88s\tremaining: 14.2s\n",
      "327:\tlearn: 0.3509369\ttotal: 6.9s\tremaining: 14.1s\n",
      "328:\tlearn: 0.3505221\ttotal: 6.91s\tremaining: 14.1s\n",
      "329:\tlearn: 0.3500892\ttotal: 6.93s\tremaining: 14.1s\n",
      "330:\tlearn: 0.3497054\ttotal: 6.97s\tremaining: 14.1s\n",
      "331:\tlearn: 0.3494025\ttotal: 7s\tremaining: 14.1s\n",
      "332:\tlearn: 0.3490739\ttotal: 7.02s\tremaining: 14.1s\n",
      "333:\tlearn: 0.3488727\ttotal: 7.03s\tremaining: 14s\n",
      "334:\tlearn: 0.3484367\ttotal: 7.05s\tremaining: 14s\n",
      "335:\tlearn: 0.3481371\ttotal: 7.07s\tremaining: 14s\n",
      "336:\tlearn: 0.3478317\ttotal: 7.08s\tremaining: 13.9s\n",
      "337:\tlearn: 0.3475125\ttotal: 7.1s\tremaining: 13.9s\n",
      "338:\tlearn: 0.3474224\ttotal: 7.1s\tremaining: 13.9s\n",
      "339:\tlearn: 0.3470350\ttotal: 7.12s\tremaining: 13.8s\n",
      "340:\tlearn: 0.3465762\ttotal: 7.13s\tremaining: 13.8s\n",
      "341:\tlearn: 0.3461158\ttotal: 7.15s\tremaining: 13.8s\n",
      "342:\tlearn: 0.3458314\ttotal: 7.17s\tremaining: 13.7s\n",
      "343:\tlearn: 0.3456277\ttotal: 7.2s\tremaining: 13.7s\n",
      "344:\tlearn: 0.3453988\ttotal: 7.23s\tremaining: 13.7s\n",
      "345:\tlearn: 0.3452019\ttotal: 7.26s\tremaining: 13.7s\n",
      "346:\tlearn: 0.3450041\ttotal: 7.28s\tremaining: 13.7s\n",
      "347:\tlearn: 0.3447418\ttotal: 7.29s\tremaining: 13.7s\n",
      "348:\tlearn: 0.3444809\ttotal: 7.31s\tremaining: 13.6s\n",
      "349:\tlearn: 0.3441416\ttotal: 7.33s\tremaining: 13.6s\n",
      "350:\tlearn: 0.3437184\ttotal: 7.34s\tremaining: 13.6s\n",
      "351:\tlearn: 0.3435004\ttotal: 7.36s\tremaining: 13.5s\n",
      "352:\tlearn: 0.3430871\ttotal: 7.37s\tremaining: 13.5s\n",
      "353:\tlearn: 0.3425485\ttotal: 7.39s\tremaining: 13.5s\n",
      "354:\tlearn: 0.3423451\ttotal: 7.41s\tremaining: 13.5s\n",
      "355:\tlearn: 0.3420514\ttotal: 7.48s\tremaining: 13.5s\n",
      "356:\tlearn: 0.3418701\ttotal: 7.53s\tremaining: 13.6s\n",
      "357:\tlearn: 0.3415878\ttotal: 7.55s\tremaining: 13.5s\n",
      "358:\tlearn: 0.3411571\ttotal: 7.58s\tremaining: 13.5s\n",
      "359:\tlearn: 0.3408055\ttotal: 7.6s\tremaining: 13.5s\n",
      "360:\tlearn: 0.3406849\ttotal: 7.63s\tremaining: 13.5s\n",
      "361:\tlearn: 0.3404461\ttotal: 7.65s\tremaining: 13.5s\n",
      "362:\tlearn: 0.3402429\ttotal: 7.7s\tremaining: 13.5s\n",
      "363:\tlearn: 0.3399166\ttotal: 7.75s\tremaining: 13.5s\n",
      "364:\tlearn: 0.3396171\ttotal: 7.77s\tremaining: 13.5s\n",
      "365:\tlearn: 0.3394119\ttotal: 7.79s\tremaining: 13.5s\n",
      "366:\tlearn: 0.3392402\ttotal: 7.81s\tremaining: 13.5s\n",
      "367:\tlearn: 0.3388980\ttotal: 7.83s\tremaining: 13.4s\n",
      "368:\tlearn: 0.3386141\ttotal: 7.84s\tremaining: 13.4s\n",
      "369:\tlearn: 0.3383201\ttotal: 7.86s\tremaining: 13.4s\n",
      "370:\tlearn: 0.3381590\ttotal: 7.88s\tremaining: 13.4s\n",
      "371:\tlearn: 0.3379304\ttotal: 7.89s\tremaining: 13.3s\n",
      "372:\tlearn: 0.3377018\ttotal: 7.91s\tremaining: 13.3s\n",
      "373:\tlearn: 0.3374422\ttotal: 7.94s\tremaining: 13.3s\n",
      "374:\tlearn: 0.3372130\ttotal: 7.97s\tremaining: 13.3s\n",
      "375:\tlearn: 0.3370569\ttotal: 8.03s\tremaining: 13.3s\n",
      "376:\tlearn: 0.3368028\ttotal: 8.08s\tremaining: 13.4s\n",
      "377:\tlearn: 0.3365168\ttotal: 8.15s\tremaining: 13.4s\n",
      "378:\tlearn: 0.3360981\ttotal: 8.24s\tremaining: 13.5s\n",
      "379:\tlearn: 0.3359356\ttotal: 8.27s\tremaining: 13.5s\n",
      "380:\tlearn: 0.3356730\ttotal: 8.29s\tremaining: 13.5s\n",
      "381:\tlearn: 0.3354055\ttotal: 8.31s\tremaining: 13.4s\n",
      "382:\tlearn: 0.3350945\ttotal: 8.33s\tremaining: 13.4s\n",
      "383:\tlearn: 0.3348456\ttotal: 8.35s\tremaining: 13.4s\n",
      "384:\tlearn: 0.3346341\ttotal: 8.36s\tremaining: 13.4s\n",
      "385:\tlearn: 0.3344603\ttotal: 8.39s\tremaining: 13.3s\n",
      "386:\tlearn: 0.3343638\ttotal: 8.41s\tremaining: 13.3s\n",
      "387:\tlearn: 0.3339695\ttotal: 8.44s\tremaining: 13.3s\n",
      "388:\tlearn: 0.3338112\ttotal: 8.45s\tremaining: 13.3s\n",
      "389:\tlearn: 0.3335440\ttotal: 8.47s\tremaining: 13.2s\n",
      "390:\tlearn: 0.3331932\ttotal: 8.5s\tremaining: 13.2s\n",
      "391:\tlearn: 0.3329223\ttotal: 8.51s\tremaining: 13.2s\n",
      "392:\tlearn: 0.3326437\ttotal: 8.53s\tremaining: 13.2s\n",
      "393:\tlearn: 0.3322962\ttotal: 8.55s\tremaining: 13.1s\n",
      "394:\tlearn: 0.3320507\ttotal: 8.56s\tremaining: 13.1s\n",
      "395:\tlearn: 0.3317309\ttotal: 8.58s\tremaining: 13.1s\n",
      "396:\tlearn: 0.3314229\ttotal: 8.62s\tremaining: 13.1s\n",
      "397:\tlearn: 0.3311811\ttotal: 8.63s\tremaining: 13.1s\n",
      "398:\tlearn: 0.3309487\ttotal: 8.65s\tremaining: 13s\n",
      "399:\tlearn: 0.3307320\ttotal: 8.67s\tremaining: 13s\n",
      "400:\tlearn: 0.3304455\ttotal: 8.7s\tremaining: 13s\n",
      "401:\tlearn: 0.3300755\ttotal: 8.71s\tremaining: 13s\n",
      "402:\tlearn: 0.3298045\ttotal: 8.73s\tremaining: 12.9s\n",
      "403:\tlearn: 0.3294184\ttotal: 8.74s\tremaining: 12.9s\n",
      "404:\tlearn: 0.3292129\ttotal: 8.76s\tremaining: 12.9s\n",
      "405:\tlearn: 0.3288875\ttotal: 8.78s\tremaining: 12.8s\n",
      "406:\tlearn: 0.3283217\ttotal: 8.81s\tremaining: 12.8s\n",
      "407:\tlearn: 0.3280184\ttotal: 8.83s\tremaining: 12.8s\n",
      "408:\tlearn: 0.3278195\ttotal: 8.85s\tremaining: 12.8s\n",
      "409:\tlearn: 0.3275530\ttotal: 8.86s\tremaining: 12.8s\n",
      "410:\tlearn: 0.3273751\ttotal: 8.88s\tremaining: 12.7s\n",
      "411:\tlearn: 0.3271017\ttotal: 8.89s\tremaining: 12.7s\n",
      "412:\tlearn: 0.3269070\ttotal: 8.91s\tremaining: 12.7s\n",
      "413:\tlearn: 0.3266214\ttotal: 8.94s\tremaining: 12.7s\n",
      "414:\tlearn: 0.3263150\ttotal: 8.96s\tremaining: 12.6s\n",
      "415:\tlearn: 0.3260034\ttotal: 8.98s\tremaining: 12.6s\n",
      "416:\tlearn: 0.3258842\ttotal: 9s\tremaining: 12.6s\n",
      "417:\tlearn: 0.3257193\ttotal: 9.02s\tremaining: 12.6s\n",
      "418:\tlearn: 0.3255019\ttotal: 9.04s\tremaining: 12.5s\n",
      "419:\tlearn: 0.3252441\ttotal: 9.05s\tremaining: 12.5s\n",
      "420:\tlearn: 0.3250757\ttotal: 9.07s\tremaining: 12.5s\n",
      "421:\tlearn: 0.3246786\ttotal: 9.09s\tremaining: 12.4s\n",
      "422:\tlearn: 0.3244449\ttotal: 9.1s\tremaining: 12.4s\n",
      "423:\tlearn: 0.3241066\ttotal: 9.12s\tremaining: 12.4s\n",
      "424:\tlearn: 0.3239232\ttotal: 9.14s\tremaining: 12.4s\n",
      "425:\tlearn: 0.3237645\ttotal: 9.18s\tremaining: 12.4s\n",
      "426:\tlearn: 0.3235561\ttotal: 9.23s\tremaining: 12.4s\n",
      "427:\tlearn: 0.3231348\ttotal: 9.26s\tremaining: 12.4s\n",
      "428:\tlearn: 0.3229045\ttotal: 9.29s\tremaining: 12.4s\n",
      "429:\tlearn: 0.3227396\ttotal: 9.3s\tremaining: 12.3s\n",
      "430:\tlearn: 0.3224312\ttotal: 9.32s\tremaining: 12.3s\n",
      "431:\tlearn: 0.3222393\ttotal: 9.33s\tremaining: 12.3s\n",
      "432:\tlearn: 0.3219666\ttotal: 9.35s\tremaining: 12.2s\n",
      "433:\tlearn: 0.3217536\ttotal: 9.37s\tremaining: 12.2s\n",
      "434:\tlearn: 0.3215964\ttotal: 9.38s\tremaining: 12.2s\n",
      "435:\tlearn: 0.3213866\ttotal: 9.4s\tremaining: 12.2s\n",
      "436:\tlearn: 0.3209907\ttotal: 9.44s\tremaining: 12.2s\n",
      "437:\tlearn: 0.3206556\ttotal: 9.47s\tremaining: 12.1s\n",
      "438:\tlearn: 0.3204739\ttotal: 9.48s\tremaining: 12.1s\n",
      "439:\tlearn: 0.3201743\ttotal: 9.5s\tremaining: 12.1s\n",
      "440:\tlearn: 0.3200017\ttotal: 9.51s\tremaining: 12.1s\n",
      "441:\tlearn: 0.3198493\ttotal: 9.53s\tremaining: 12s\n",
      "442:\tlearn: 0.3196392\ttotal: 9.54s\tremaining: 12s\n",
      "443:\tlearn: 0.3194452\ttotal: 9.56s\tremaining: 12s\n",
      "444:\tlearn: 0.3190950\ttotal: 9.58s\tremaining: 11.9s\n",
      "445:\tlearn: 0.3189222\ttotal: 9.59s\tremaining: 11.9s\n",
      "446:\tlearn: 0.3187205\ttotal: 9.61s\tremaining: 11.9s\n",
      "447:\tlearn: 0.3185220\ttotal: 9.63s\tremaining: 11.9s\n",
      "448:\tlearn: 0.3183219\ttotal: 9.68s\tremaining: 11.9s\n",
      "449:\tlearn: 0.3181064\ttotal: 9.7s\tremaining: 11.9s\n",
      "450:\tlearn: 0.3179353\ttotal: 9.71s\tremaining: 11.8s\n",
      "451:\tlearn: 0.3175646\ttotal: 9.73s\tremaining: 11.8s\n",
      "452:\tlearn: 0.3173749\ttotal: 9.77s\tremaining: 11.8s\n",
      "453:\tlearn: 0.3171946\ttotal: 9.79s\tremaining: 11.8s\n",
      "454:\tlearn: 0.3168618\ttotal: 9.84s\tremaining: 11.8s\n",
      "455:\tlearn: 0.3166799\ttotal: 9.87s\tremaining: 11.8s\n",
      "456:\tlearn: 0.3164660\ttotal: 9.89s\tremaining: 11.8s\n",
      "457:\tlearn: 0.3162555\ttotal: 9.91s\tremaining: 11.7s\n",
      "458:\tlearn: 0.3160020\ttotal: 9.94s\tremaining: 11.7s\n",
      "459:\tlearn: 0.3157901\ttotal: 9.99s\tremaining: 11.7s\n",
      "460:\tlearn: 0.3156200\ttotal: 10.1s\tremaining: 11.8s\n",
      "461:\tlearn: 0.3153472\ttotal: 10.1s\tremaining: 11.8s\n",
      "462:\tlearn: 0.3150407\ttotal: 10.1s\tremaining: 11.7s\n",
      "463:\tlearn: 0.3146502\ttotal: 10.1s\tremaining: 11.7s\n",
      "464:\tlearn: 0.3144638\ttotal: 10.2s\tremaining: 11.7s\n",
      "465:\tlearn: 0.3143039\ttotal: 10.2s\tremaining: 11.7s\n",
      "466:\tlearn: 0.3140696\ttotal: 10.2s\tremaining: 11.7s\n",
      "467:\tlearn: 0.3138698\ttotal: 10.3s\tremaining: 11.7s\n",
      "468:\tlearn: 0.3136675\ttotal: 10.3s\tremaining: 11.6s\n",
      "469:\tlearn: 0.3133229\ttotal: 10.3s\tremaining: 11.6s\n",
      "470:\tlearn: 0.3130747\ttotal: 10.3s\tremaining: 11.6s\n",
      "471:\tlearn: 0.3129657\ttotal: 10.4s\tremaining: 11.6s\n",
      "472:\tlearn: 0.3127549\ttotal: 10.4s\tremaining: 11.6s\n",
      "473:\tlearn: 0.3125065\ttotal: 10.4s\tremaining: 11.5s\n",
      "474:\tlearn: 0.3121868\ttotal: 10.4s\tremaining: 11.5s\n",
      "475:\tlearn: 0.3119141\ttotal: 10.4s\tremaining: 11.5s\n",
      "476:\tlearn: 0.3117399\ttotal: 10.5s\tremaining: 11.5s\n",
      "477:\tlearn: 0.3115345\ttotal: 10.5s\tremaining: 11.4s\n",
      "478:\tlearn: 0.3113657\ttotal: 10.5s\tremaining: 11.4s\n",
      "479:\tlearn: 0.3112060\ttotal: 10.5s\tremaining: 11.4s\n",
      "480:\tlearn: 0.3110410\ttotal: 10.5s\tremaining: 11.4s\n",
      "481:\tlearn: 0.3108467\ttotal: 10.5s\tremaining: 11.3s\n",
      "482:\tlearn: 0.3106398\ttotal: 10.6s\tremaining: 11.3s\n",
      "483:\tlearn: 0.3104544\ttotal: 10.6s\tremaining: 11.3s\n",
      "484:\tlearn: 0.3102489\ttotal: 10.6s\tremaining: 11.3s\n",
      "485:\tlearn: 0.3099718\ttotal: 10.6s\tremaining: 11.3s\n",
      "486:\tlearn: 0.3098579\ttotal: 10.7s\tremaining: 11.2s\n",
      "487:\tlearn: 0.3096633\ttotal: 10.7s\tremaining: 11.2s\n",
      "488:\tlearn: 0.3094060\ttotal: 10.7s\tremaining: 11.2s\n",
      "489:\tlearn: 0.3092161\ttotal: 10.7s\tremaining: 11.1s\n",
      "490:\tlearn: 0.3089963\ttotal: 10.7s\tremaining: 11.1s\n",
      "491:\tlearn: 0.3087384\ttotal: 10.7s\tremaining: 11.1s\n",
      "492:\tlearn: 0.3084615\ttotal: 10.8s\tremaining: 11.1s\n",
      "493:\tlearn: 0.3082633\ttotal: 10.8s\tremaining: 11s\n",
      "494:\tlearn: 0.3080590\ttotal: 10.8s\tremaining: 11s\n",
      "495:\tlearn: 0.3078015\ttotal: 10.8s\tremaining: 11s\n",
      "496:\tlearn: 0.3075035\ttotal: 10.9s\tremaining: 11s\n",
      "497:\tlearn: 0.3072608\ttotal: 10.9s\tremaining: 11s\n",
      "498:\tlearn: 0.3069933\ttotal: 10.9s\tremaining: 10.9s\n",
      "499:\tlearn: 0.3067781\ttotal: 10.9s\tremaining: 10.9s\n",
      "500:\tlearn: 0.3063885\ttotal: 10.9s\tremaining: 10.9s\n",
      "501:\tlearn: 0.3062190\ttotal: 11s\tremaining: 10.9s\n",
      "502:\tlearn: 0.3061212\ttotal: 11s\tremaining: 10.9s\n",
      "503:\tlearn: 0.3058877\ttotal: 11s\tremaining: 10.8s\n",
      "504:\tlearn: 0.3057077\ttotal: 11s\tremaining: 10.8s\n",
      "505:\tlearn: 0.3052214\ttotal: 11.1s\tremaining: 10.8s\n",
      "506:\tlearn: 0.3050053\ttotal: 11.1s\tremaining: 10.8s\n",
      "507:\tlearn: 0.3047636\ttotal: 11.1s\tremaining: 10.8s\n",
      "508:\tlearn: 0.3044944\ttotal: 11.1s\tremaining: 10.8s\n",
      "509:\tlearn: 0.3043466\ttotal: 11.2s\tremaining: 10.7s\n",
      "510:\tlearn: 0.3040373\ttotal: 11.2s\tremaining: 10.7s\n",
      "511:\tlearn: 0.3037486\ttotal: 11.3s\tremaining: 10.7s\n",
      "512:\tlearn: 0.3035475\ttotal: 11.3s\tremaining: 10.7s\n",
      "513:\tlearn: 0.3032838\ttotal: 11.3s\tremaining: 10.7s\n",
      "514:\tlearn: 0.3029976\ttotal: 11.3s\tremaining: 10.7s\n",
      "515:\tlearn: 0.3028907\ttotal: 11.4s\tremaining: 10.7s\n",
      "516:\tlearn: 0.3026603\ttotal: 11.4s\tremaining: 10.6s\n",
      "517:\tlearn: 0.3024564\ttotal: 11.4s\tremaining: 10.6s\n",
      "518:\tlearn: 0.3023319\ttotal: 11.5s\tremaining: 10.6s\n",
      "519:\tlearn: 0.3021314\ttotal: 11.5s\tremaining: 10.6s\n",
      "520:\tlearn: 0.3019715\ttotal: 11.6s\tremaining: 10.6s\n",
      "521:\tlearn: 0.3018421\ttotal: 11.6s\tremaining: 10.6s\n",
      "522:\tlearn: 0.3016250\ttotal: 11.6s\tremaining: 10.6s\n",
      "523:\tlearn: 0.3015098\ttotal: 11.7s\tremaining: 10.6s\n",
      "524:\tlearn: 0.3011702\ttotal: 11.7s\tremaining: 10.6s\n",
      "525:\tlearn: 0.3009383\ttotal: 11.7s\tremaining: 10.5s\n",
      "526:\tlearn: 0.3005822\ttotal: 11.7s\tremaining: 10.5s\n",
      "527:\tlearn: 0.3003970\ttotal: 11.7s\tremaining: 10.5s\n",
      "528:\tlearn: 0.2999280\ttotal: 11.7s\tremaining: 10.5s\n",
      "529:\tlearn: 0.2997046\ttotal: 11.8s\tremaining: 10.4s\n",
      "530:\tlearn: 0.2995085\ttotal: 11.8s\tremaining: 10.5s\n",
      "531:\tlearn: 0.2992513\ttotal: 11.9s\tremaining: 10.4s\n",
      "532:\tlearn: 0.2989969\ttotal: 11.9s\tremaining: 10.4s\n",
      "533:\tlearn: 0.2986922\ttotal: 11.9s\tremaining: 10.4s\n",
      "534:\tlearn: 0.2985401\ttotal: 11.9s\tremaining: 10.4s\n",
      "535:\tlearn: 0.2983735\ttotal: 11.9s\tremaining: 10.3s\n",
      "536:\tlearn: 0.2982204\ttotal: 12s\tremaining: 10.3s\n",
      "537:\tlearn: 0.2979290\ttotal: 12s\tremaining: 10.3s\n",
      "538:\tlearn: 0.2977350\ttotal: 12s\tremaining: 10.3s\n",
      "539:\tlearn: 0.2975724\ttotal: 12s\tremaining: 10.3s\n",
      "540:\tlearn: 0.2973332\ttotal: 12.1s\tremaining: 10.2s\n",
      "541:\tlearn: 0.2971218\ttotal: 12.1s\tremaining: 10.2s\n",
      "542:\tlearn: 0.2969206\ttotal: 12.1s\tremaining: 10.2s\n",
      "543:\tlearn: 0.2966586\ttotal: 12.1s\tremaining: 10.1s\n",
      "544:\tlearn: 0.2964748\ttotal: 12.1s\tremaining: 10.1s\n",
      "545:\tlearn: 0.2963013\ttotal: 12.1s\tremaining: 10.1s\n",
      "546:\tlearn: 0.2961256\ttotal: 12.2s\tremaining: 10.1s\n",
      "547:\tlearn: 0.2958726\ttotal: 12.2s\tremaining: 10s\n",
      "548:\tlearn: 0.2955578\ttotal: 12.2s\tremaining: 10s\n",
      "549:\tlearn: 0.2953048\ttotal: 12.2s\tremaining: 10s\n",
      "550:\tlearn: 0.2951256\ttotal: 12.2s\tremaining: 9.98s\n",
      "551:\tlearn: 0.2947279\ttotal: 12.3s\tremaining: 9.96s\n",
      "552:\tlearn: 0.2945588\ttotal: 12.3s\tremaining: 9.95s\n",
      "553:\tlearn: 0.2944093\ttotal: 12.3s\tremaining: 9.92s\n",
      "554:\tlearn: 0.2941252\ttotal: 12.4s\tremaining: 9.91s\n",
      "555:\tlearn: 0.2937065\ttotal: 12.4s\tremaining: 9.89s\n",
      "556:\tlearn: 0.2935604\ttotal: 12.4s\tremaining: 9.86s\n",
      "557:\tlearn: 0.2933237\ttotal: 12.4s\tremaining: 9.84s\n",
      "558:\tlearn: 0.2929447\ttotal: 12.4s\tremaining: 9.81s\n",
      "559:\tlearn: 0.2928048\ttotal: 12.4s\tremaining: 9.78s\n",
      "560:\tlearn: 0.2926117\ttotal: 12.5s\tremaining: 9.77s\n",
      "561:\tlearn: 0.2925025\ttotal: 12.5s\tremaining: 9.74s\n",
      "562:\tlearn: 0.2923357\ttotal: 12.5s\tremaining: 9.71s\n",
      "563:\tlearn: 0.2920909\ttotal: 12.5s\tremaining: 9.69s\n",
      "564:\tlearn: 0.2918589\ttotal: 12.5s\tremaining: 9.66s\n",
      "565:\tlearn: 0.2915620\ttotal: 12.6s\tremaining: 9.63s\n",
      "566:\tlearn: 0.2913311\ttotal: 12.6s\tremaining: 9.62s\n",
      "567:\tlearn: 0.2911982\ttotal: 12.6s\tremaining: 9.59s\n",
      "568:\tlearn: 0.2909516\ttotal: 12.6s\tremaining: 9.56s\n",
      "569:\tlearn: 0.2908311\ttotal: 12.6s\tremaining: 9.54s\n",
      "570:\tlearn: 0.2906932\ttotal: 12.7s\tremaining: 9.51s\n",
      "571:\tlearn: 0.2904915\ttotal: 12.7s\tremaining: 9.48s\n",
      "572:\tlearn: 0.2903306\ttotal: 12.7s\tremaining: 9.45s\n",
      "573:\tlearn: 0.2900519\ttotal: 12.7s\tremaining: 9.43s\n",
      "574:\tlearn: 0.2897354\ttotal: 12.7s\tremaining: 9.42s\n",
      "575:\tlearn: 0.2893606\ttotal: 12.8s\tremaining: 9.39s\n",
      "576:\tlearn: 0.2891533\ttotal: 12.8s\tremaining: 9.37s\n",
      "577:\tlearn: 0.2888673\ttotal: 12.8s\tremaining: 9.35s\n",
      "578:\tlearn: 0.2885583\ttotal: 12.8s\tremaining: 9.32s\n",
      "579:\tlearn: 0.2883289\ttotal: 12.8s\tremaining: 9.3s\n",
      "580:\tlearn: 0.2881398\ttotal: 12.9s\tremaining: 9.27s\n",
      "581:\tlearn: 0.2878419\ttotal: 12.9s\tremaining: 9.24s\n",
      "582:\tlearn: 0.2876404\ttotal: 12.9s\tremaining: 9.22s\n",
      "583:\tlearn: 0.2874055\ttotal: 12.9s\tremaining: 9.19s\n",
      "584:\tlearn: 0.2872121\ttotal: 12.9s\tremaining: 9.16s\n",
      "585:\tlearn: 0.2870848\ttotal: 12.9s\tremaining: 9.14s\n",
      "586:\tlearn: 0.2868684\ttotal: 13s\tremaining: 9.12s\n",
      "587:\tlearn: 0.2867289\ttotal: 13s\tremaining: 9.1s\n",
      "588:\tlearn: 0.2863582\ttotal: 13s\tremaining: 9.08s\n",
      "589:\tlearn: 0.2861588\ttotal: 13s\tremaining: 9.06s\n",
      "590:\tlearn: 0.2859724\ttotal: 13.1s\tremaining: 9.03s\n",
      "591:\tlearn: 0.2857409\ttotal: 13.1s\tremaining: 9.01s\n",
      "592:\tlearn: 0.2854533\ttotal: 13.1s\tremaining: 8.98s\n",
      "593:\tlearn: 0.2851084\ttotal: 13.1s\tremaining: 8.95s\n",
      "594:\tlearn: 0.2849450\ttotal: 13.1s\tremaining: 8.93s\n",
      "595:\tlearn: 0.2844880\ttotal: 13.1s\tremaining: 8.9s\n",
      "596:\tlearn: 0.2842531\ttotal: 13.1s\tremaining: 8.88s\n",
      "597:\tlearn: 0.2840911\ttotal: 13.2s\tremaining: 8.85s\n",
      "598:\tlearn: 0.2839605\ttotal: 13.2s\tremaining: 8.82s\n",
      "599:\tlearn: 0.2837656\ttotal: 13.2s\tremaining: 8.8s\n",
      "600:\tlearn: 0.2836183\ttotal: 13.2s\tremaining: 8.79s\n",
      "601:\tlearn: 0.2834263\ttotal: 13.3s\tremaining: 8.77s\n",
      "602:\tlearn: 0.2832444\ttotal: 13.3s\tremaining: 8.74s\n",
      "603:\tlearn: 0.2830663\ttotal: 13.3s\tremaining: 8.72s\n",
      "604:\tlearn: 0.2829287\ttotal: 13.3s\tremaining: 8.7s\n",
      "605:\tlearn: 0.2827729\ttotal: 13.4s\tremaining: 8.69s\n",
      "606:\tlearn: 0.2822991\ttotal: 13.4s\tremaining: 8.67s\n",
      "607:\tlearn: 0.2821283\ttotal: 13.4s\tremaining: 8.64s\n",
      "608:\tlearn: 0.2819970\ttotal: 13.4s\tremaining: 8.63s\n",
      "609:\tlearn: 0.2818246\ttotal: 13.5s\tremaining: 8.62s\n",
      "610:\tlearn: 0.2815812\ttotal: 13.5s\tremaining: 8.59s\n",
      "611:\tlearn: 0.2813801\ttotal: 13.5s\tremaining: 8.57s\n",
      "612:\tlearn: 0.2812761\ttotal: 13.5s\tremaining: 8.54s\n",
      "613:\tlearn: 0.2810697\ttotal: 13.6s\tremaining: 8.52s\n",
      "614:\tlearn: 0.2809172\ttotal: 13.6s\tremaining: 8.5s\n",
      "615:\tlearn: 0.2806065\ttotal: 13.6s\tremaining: 8.49s\n",
      "616:\tlearn: 0.2804389\ttotal: 13.6s\tremaining: 8.47s\n",
      "617:\tlearn: 0.2801117\ttotal: 13.7s\tremaining: 8.46s\n",
      "618:\tlearn: 0.2799975\ttotal: 13.7s\tremaining: 8.43s\n",
      "619:\tlearn: 0.2798395\ttotal: 13.7s\tremaining: 8.41s\n",
      "620:\tlearn: 0.2794555\ttotal: 13.7s\tremaining: 8.38s\n",
      "621:\tlearn: 0.2793019\ttotal: 13.8s\tremaining: 8.36s\n",
      "622:\tlearn: 0.2789793\ttotal: 13.8s\tremaining: 8.33s\n",
      "623:\tlearn: 0.2788027\ttotal: 13.8s\tremaining: 8.31s\n",
      "624:\tlearn: 0.2785425\ttotal: 13.8s\tremaining: 8.29s\n",
      "625:\tlearn: 0.2783195\ttotal: 13.8s\tremaining: 8.27s\n",
      "626:\tlearn: 0.2781841\ttotal: 13.9s\tremaining: 8.25s\n",
      "627:\tlearn: 0.2778119\ttotal: 13.9s\tremaining: 8.23s\n",
      "628:\tlearn: 0.2776564\ttotal: 13.9s\tremaining: 8.22s\n",
      "629:\tlearn: 0.2774825\ttotal: 14s\tremaining: 8.19s\n",
      "630:\tlearn: 0.2773077\ttotal: 14s\tremaining: 8.17s\n",
      "631:\tlearn: 0.2771287\ttotal: 14s\tremaining: 8.15s\n",
      "632:\tlearn: 0.2767538\ttotal: 14s\tremaining: 8.12s\n",
      "633:\tlearn: 0.2764832\ttotal: 14s\tremaining: 8.1s\n",
      "634:\tlearn: 0.2763413\ttotal: 14.1s\tremaining: 8.08s\n",
      "635:\tlearn: 0.2760146\ttotal: 14.1s\tremaining: 8.06s\n",
      "636:\tlearn: 0.2758001\ttotal: 14.1s\tremaining: 8.04s\n",
      "637:\tlearn: 0.2756147\ttotal: 14.1s\tremaining: 8.01s\n",
      "638:\tlearn: 0.2754588\ttotal: 14.1s\tremaining: 7.99s\n",
      "639:\tlearn: 0.2753367\ttotal: 14.2s\tremaining: 7.97s\n",
      "640:\tlearn: 0.2751931\ttotal: 14.2s\tremaining: 7.95s\n",
      "641:\tlearn: 0.2749707\ttotal: 14.2s\tremaining: 7.93s\n",
      "642:\tlearn: 0.2747442\ttotal: 14.2s\tremaining: 7.9s\n",
      "643:\tlearn: 0.2744670\ttotal: 14.3s\tremaining: 7.88s\n",
      "644:\tlearn: 0.2742551\ttotal: 14.3s\tremaining: 7.86s\n",
      "645:\tlearn: 0.2740063\ttotal: 14.3s\tremaining: 7.84s\n",
      "646:\tlearn: 0.2738254\ttotal: 14.3s\tremaining: 7.81s\n",
      "647:\tlearn: 0.2736263\ttotal: 14.3s\tremaining: 7.79s\n",
      "648:\tlearn: 0.2734814\ttotal: 14.4s\tremaining: 7.78s\n",
      "649:\tlearn: 0.2730792\ttotal: 14.4s\tremaining: 7.76s\n",
      "650:\tlearn: 0.2727633\ttotal: 14.4s\tremaining: 7.74s\n",
      "651:\tlearn: 0.2726112\ttotal: 14.5s\tremaining: 7.71s\n",
      "652:\tlearn: 0.2723505\ttotal: 14.5s\tremaining: 7.69s\n",
      "653:\tlearn: 0.2720129\ttotal: 14.5s\tremaining: 7.67s\n",
      "654:\tlearn: 0.2718132\ttotal: 14.5s\tremaining: 7.65s\n",
      "655:\tlearn: 0.2716237\ttotal: 14.5s\tremaining: 7.62s\n",
      "656:\tlearn: 0.2714988\ttotal: 14.6s\tremaining: 7.6s\n",
      "657:\tlearn: 0.2713347\ttotal: 14.6s\tremaining: 7.57s\n",
      "658:\tlearn: 0.2710667\ttotal: 14.6s\tremaining: 7.55s\n",
      "659:\tlearn: 0.2708156\ttotal: 14.6s\tremaining: 7.52s\n",
      "660:\tlearn: 0.2706310\ttotal: 14.6s\tremaining: 7.5s\n",
      "661:\tlearn: 0.2704882\ttotal: 14.6s\tremaining: 7.47s\n",
      "662:\tlearn: 0.2702017\ttotal: 14.7s\tremaining: 7.46s\n",
      "663:\tlearn: 0.2699622\ttotal: 14.7s\tremaining: 7.43s\n",
      "664:\tlearn: 0.2697611\ttotal: 14.7s\tremaining: 7.41s\n",
      "665:\tlearn: 0.2696102\ttotal: 14.7s\tremaining: 7.39s\n",
      "666:\tlearn: 0.2694934\ttotal: 14.7s\tremaining: 7.36s\n",
      "667:\tlearn: 0.2692143\ttotal: 14.8s\tremaining: 7.34s\n",
      "668:\tlearn: 0.2689910\ttotal: 14.8s\tremaining: 7.31s\n",
      "669:\tlearn: 0.2688839\ttotal: 14.8s\tremaining: 7.29s\n",
      "670:\tlearn: 0.2686607\ttotal: 14.8s\tremaining: 7.26s\n",
      "671:\tlearn: 0.2684855\ttotal: 14.8s\tremaining: 7.24s\n",
      "672:\tlearn: 0.2682867\ttotal: 14.8s\tremaining: 7.21s\n",
      "673:\tlearn: 0.2679541\ttotal: 14.9s\tremaining: 7.19s\n",
      "674:\tlearn: 0.2678658\ttotal: 14.9s\tremaining: 7.16s\n",
      "675:\tlearn: 0.2676059\ttotal: 14.9s\tremaining: 7.15s\n",
      "676:\tlearn: 0.2674539\ttotal: 15s\tremaining: 7.14s\n",
      "677:\tlearn: 0.2673502\ttotal: 15s\tremaining: 7.12s\n",
      "678:\tlearn: 0.2672250\ttotal: 15s\tremaining: 7.1s\n",
      "679:\tlearn: 0.2669348\ttotal: 15s\tremaining: 7.07s\n",
      "680:\tlearn: 0.2667480\ttotal: 15s\tremaining: 7.05s\n",
      "681:\tlearn: 0.2664177\ttotal: 15.1s\tremaining: 7.02s\n",
      "682:\tlearn: 0.2662657\ttotal: 15.1s\tremaining: 7s\n",
      "683:\tlearn: 0.2659528\ttotal: 15.1s\tremaining: 6.97s\n",
      "684:\tlearn: 0.2657295\ttotal: 15.1s\tremaining: 6.95s\n",
      "685:\tlearn: 0.2655726\ttotal: 15.1s\tremaining: 6.92s\n",
      "686:\tlearn: 0.2654627\ttotal: 15.2s\tremaining: 6.91s\n",
      "687:\tlearn: 0.2653143\ttotal: 15.2s\tremaining: 6.89s\n",
      "688:\tlearn: 0.2649805\ttotal: 15.2s\tremaining: 6.86s\n",
      "689:\tlearn: 0.2646930\ttotal: 15.2s\tremaining: 6.84s\n",
      "690:\tlearn: 0.2644427\ttotal: 15.2s\tremaining: 6.81s\n",
      "691:\tlearn: 0.2641480\ttotal: 15.3s\tremaining: 6.79s\n",
      "692:\tlearn: 0.2639512\ttotal: 15.3s\tremaining: 6.77s\n",
      "693:\tlearn: 0.2636966\ttotal: 15.3s\tremaining: 6.74s\n",
      "694:\tlearn: 0.2634811\ttotal: 15.3s\tremaining: 6.72s\n",
      "695:\tlearn: 0.2634282\ttotal: 15.3s\tremaining: 6.7s\n",
      "696:\tlearn: 0.2632787\ttotal: 15.4s\tremaining: 6.67s\n",
      "697:\tlearn: 0.2631311\ttotal: 15.4s\tremaining: 6.65s\n",
      "698:\tlearn: 0.2628645\ttotal: 15.4s\tremaining: 6.62s\n",
      "699:\tlearn: 0.2627509\ttotal: 15.4s\tremaining: 6.61s\n",
      "700:\tlearn: 0.2624447\ttotal: 15.5s\tremaining: 6.59s\n",
      "701:\tlearn: 0.2622373\ttotal: 15.5s\tremaining: 6.57s\n",
      "702:\tlearn: 0.2620158\ttotal: 15.5s\tremaining: 6.55s\n",
      "703:\tlearn: 0.2616405\ttotal: 15.5s\tremaining: 6.53s\n",
      "704:\tlearn: 0.2614978\ttotal: 15.5s\tremaining: 6.5s\n",
      "705:\tlearn: 0.2612629\ttotal: 15.6s\tremaining: 6.48s\n",
      "706:\tlearn: 0.2610645\ttotal: 15.6s\tremaining: 6.46s\n",
      "707:\tlearn: 0.2609076\ttotal: 15.6s\tremaining: 6.43s\n",
      "708:\tlearn: 0.2606288\ttotal: 15.6s\tremaining: 6.41s\n",
      "709:\tlearn: 0.2605346\ttotal: 15.6s\tremaining: 6.38s\n",
      "710:\tlearn: 0.2602391\ttotal: 15.7s\tremaining: 6.37s\n",
      "711:\tlearn: 0.2601032\ttotal: 15.7s\tremaining: 6.34s\n",
      "712:\tlearn: 0.2599784\ttotal: 15.7s\tremaining: 6.32s\n",
      "713:\tlearn: 0.2598658\ttotal: 15.7s\tremaining: 6.3s\n",
      "714:\tlearn: 0.2596446\ttotal: 15.7s\tremaining: 6.28s\n",
      "715:\tlearn: 0.2594782\ttotal: 15.8s\tremaining: 6.25s\n",
      "716:\tlearn: 0.2592590\ttotal: 15.8s\tremaining: 6.23s\n",
      "717:\tlearn: 0.2591324\ttotal: 15.8s\tremaining: 6.2s\n",
      "718:\tlearn: 0.2590394\ttotal: 15.8s\tremaining: 6.18s\n",
      "719:\tlearn: 0.2587126\ttotal: 15.8s\tremaining: 6.15s\n",
      "720:\tlearn: 0.2585327\ttotal: 15.8s\tremaining: 6.13s\n",
      "721:\tlearn: 0.2583924\ttotal: 15.9s\tremaining: 6.11s\n",
      "722:\tlearn: 0.2582890\ttotal: 15.9s\tremaining: 6.08s\n",
      "723:\tlearn: 0.2580178\ttotal: 15.9s\tremaining: 6.07s\n",
      "724:\tlearn: 0.2575490\ttotal: 15.9s\tremaining: 6.05s\n",
      "725:\tlearn: 0.2573308\ttotal: 16s\tremaining: 6.02s\n",
      "726:\tlearn: 0.2571759\ttotal: 16s\tremaining: 6s\n",
      "727:\tlearn: 0.2570454\ttotal: 16s\tremaining: 5.98s\n",
      "728:\tlearn: 0.2568441\ttotal: 16s\tremaining: 5.95s\n",
      "729:\tlearn: 0.2566759\ttotal: 16s\tremaining: 5.93s\n",
      "730:\tlearn: 0.2565721\ttotal: 16.1s\tremaining: 5.91s\n",
      "731:\tlearn: 0.2565182\ttotal: 16.1s\tremaining: 5.88s\n",
      "732:\tlearn: 0.2563814\ttotal: 16.1s\tremaining: 5.86s\n",
      "733:\tlearn: 0.2562418\ttotal: 16.1s\tremaining: 5.83s\n",
      "734:\tlearn: 0.2561124\ttotal: 16.1s\tremaining: 5.82s\n",
      "735:\tlearn: 0.2559888\ttotal: 16.2s\tremaining: 5.8s\n",
      "736:\tlearn: 0.2556836\ttotal: 16.2s\tremaining: 5.78s\n",
      "737:\tlearn: 0.2555731\ttotal: 16.2s\tremaining: 5.75s\n",
      "738:\tlearn: 0.2555015\ttotal: 16.2s\tremaining: 5.73s\n",
      "739:\tlearn: 0.2552669\ttotal: 16.2s\tremaining: 5.7s\n",
      "740:\tlearn: 0.2548914\ttotal: 16.2s\tremaining: 5.68s\n",
      "741:\tlearn: 0.2547129\ttotal: 16.3s\tremaining: 5.66s\n",
      "742:\tlearn: 0.2544783\ttotal: 16.3s\tremaining: 5.64s\n",
      "743:\tlearn: 0.2542013\ttotal: 16.3s\tremaining: 5.61s\n",
      "744:\tlearn: 0.2540108\ttotal: 16.3s\tremaining: 5.59s\n",
      "745:\tlearn: 0.2537629\ttotal: 16.4s\tremaining: 5.57s\n",
      "746:\tlearn: 0.2535412\ttotal: 16.4s\tremaining: 5.54s\n",
      "747:\tlearn: 0.2532534\ttotal: 16.4s\tremaining: 5.52s\n",
      "748:\tlearn: 0.2530565\ttotal: 16.4s\tremaining: 5.5s\n",
      "749:\tlearn: 0.2529190\ttotal: 16.4s\tremaining: 5.48s\n",
      "750:\tlearn: 0.2527001\ttotal: 16.5s\tremaining: 5.48s\n",
      "751:\tlearn: 0.2524917\ttotal: 16.5s\tremaining: 5.45s\n",
      "752:\tlearn: 0.2523263\ttotal: 16.6s\tremaining: 5.43s\n",
      "753:\tlearn: 0.2522054\ttotal: 16.6s\tremaining: 5.41s\n",
      "754:\tlearn: 0.2519880\ttotal: 16.6s\tremaining: 5.39s\n",
      "755:\tlearn: 0.2518338\ttotal: 16.6s\tremaining: 5.37s\n",
      "756:\tlearn: 0.2516588\ttotal: 16.6s\tremaining: 5.34s\n",
      "757:\tlearn: 0.2515526\ttotal: 16.7s\tremaining: 5.32s\n",
      "758:\tlearn: 0.2513845\ttotal: 16.7s\tremaining: 5.29s\n",
      "759:\tlearn: 0.2512153\ttotal: 16.7s\tremaining: 5.28s\n",
      "760:\tlearn: 0.2510462\ttotal: 16.7s\tremaining: 5.25s\n",
      "761:\tlearn: 0.2508420\ttotal: 16.7s\tremaining: 5.23s\n",
      "762:\tlearn: 0.2506814\ttotal: 16.8s\tremaining: 5.2s\n",
      "763:\tlearn: 0.2504966\ttotal: 16.8s\tremaining: 5.18s\n",
      "764:\tlearn: 0.2503683\ttotal: 16.8s\tremaining: 5.16s\n",
      "765:\tlearn: 0.2502316\ttotal: 16.8s\tremaining: 5.13s\n",
      "766:\tlearn: 0.2500605\ttotal: 16.8s\tremaining: 5.11s\n",
      "767:\tlearn: 0.2498803\ttotal: 16.9s\tremaining: 5.09s\n",
      "768:\tlearn: 0.2497323\ttotal: 16.9s\tremaining: 5.07s\n",
      "769:\tlearn: 0.2495470\ttotal: 16.9s\tremaining: 5.05s\n",
      "770:\tlearn: 0.2493842\ttotal: 16.9s\tremaining: 5.03s\n",
      "771:\tlearn: 0.2490244\ttotal: 17s\tremaining: 5.01s\n",
      "772:\tlearn: 0.2486729\ttotal: 17s\tremaining: 4.98s\n",
      "773:\tlearn: 0.2484618\ttotal: 17s\tremaining: 4.96s\n",
      "774:\tlearn: 0.2481963\ttotal: 17s\tremaining: 4.94s\n",
      "775:\tlearn: 0.2479913\ttotal: 17s\tremaining: 4.91s\n",
      "776:\tlearn: 0.2476921\ttotal: 17s\tremaining: 4.89s\n",
      "777:\tlearn: 0.2475334\ttotal: 17.1s\tremaining: 4.88s\n",
      "778:\tlearn: 0.2472927\ttotal: 17.1s\tremaining: 4.86s\n",
      "779:\tlearn: 0.2471044\ttotal: 17.2s\tremaining: 4.84s\n",
      "780:\tlearn: 0.2469671\ttotal: 17.2s\tremaining: 4.82s\n",
      "781:\tlearn: 0.2467603\ttotal: 17.2s\tremaining: 4.8s\n",
      "782:\tlearn: 0.2465099\ttotal: 17.2s\tremaining: 4.78s\n",
      "783:\tlearn: 0.2463844\ttotal: 17.3s\tremaining: 4.76s\n",
      "784:\tlearn: 0.2462104\ttotal: 17.3s\tremaining: 4.74s\n",
      "785:\tlearn: 0.2460861\ttotal: 17.3s\tremaining: 4.72s\n",
      "786:\tlearn: 0.2458923\ttotal: 17.4s\tremaining: 4.7s\n",
      "787:\tlearn: 0.2457266\ttotal: 17.4s\tremaining: 4.68s\n",
      "788:\tlearn: 0.2454247\ttotal: 17.4s\tremaining: 4.65s\n",
      "789:\tlearn: 0.2451870\ttotal: 17.4s\tremaining: 4.63s\n",
      "790:\tlearn: 0.2450442\ttotal: 17.4s\tremaining: 4.61s\n",
      "791:\tlearn: 0.2448540\ttotal: 17.5s\tremaining: 4.59s\n",
      "792:\tlearn: 0.2447304\ttotal: 17.5s\tremaining: 4.58s\n",
      "793:\tlearn: 0.2444722\ttotal: 17.6s\tremaining: 4.56s\n",
      "794:\tlearn: 0.2442715\ttotal: 17.6s\tremaining: 4.54s\n",
      "795:\tlearn: 0.2441776\ttotal: 17.6s\tremaining: 4.52s\n",
      "796:\tlearn: 0.2439914\ttotal: 17.6s\tremaining: 4.49s\n",
      "797:\tlearn: 0.2438604\ttotal: 17.7s\tremaining: 4.47s\n",
      "798:\tlearn: 0.2437850\ttotal: 17.7s\tremaining: 4.45s\n",
      "799:\tlearn: 0.2436127\ttotal: 17.7s\tremaining: 4.43s\n",
      "800:\tlearn: 0.2434307\ttotal: 17.7s\tremaining: 4.41s\n",
      "801:\tlearn: 0.2432544\ttotal: 17.8s\tremaining: 4.38s\n",
      "802:\tlearn: 0.2431311\ttotal: 17.8s\tremaining: 4.36s\n",
      "803:\tlearn: 0.2429356\ttotal: 17.8s\tremaining: 4.34s\n",
      "804:\tlearn: 0.2427508\ttotal: 17.8s\tremaining: 4.32s\n",
      "805:\tlearn: 0.2424623\ttotal: 17.9s\tremaining: 4.3s\n",
      "806:\tlearn: 0.2421827\ttotal: 17.9s\tremaining: 4.28s\n",
      "807:\tlearn: 0.2419354\ttotal: 17.9s\tremaining: 4.25s\n",
      "808:\tlearn: 0.2415911\ttotal: 17.9s\tremaining: 4.23s\n",
      "809:\tlearn: 0.2414111\ttotal: 18s\tremaining: 4.21s\n",
      "810:\tlearn: 0.2412546\ttotal: 18s\tremaining: 4.19s\n",
      "811:\tlearn: 0.2411167\ttotal: 18s\tremaining: 4.16s\n",
      "812:\tlearn: 0.2409724\ttotal: 18s\tremaining: 4.14s\n",
      "813:\tlearn: 0.2407603\ttotal: 18s\tremaining: 4.12s\n",
      "814:\tlearn: 0.2405839\ttotal: 18s\tremaining: 4.09s\n",
      "815:\tlearn: 0.2404130\ttotal: 18.1s\tremaining: 4.07s\n",
      "816:\tlearn: 0.2403309\ttotal: 18.1s\tremaining: 4.05s\n",
      "817:\tlearn: 0.2400116\ttotal: 18.1s\tremaining: 4.03s\n",
      "818:\tlearn: 0.2397991\ttotal: 18.1s\tremaining: 4.01s\n",
      "819:\tlearn: 0.2395887\ttotal: 18.2s\tremaining: 3.99s\n",
      "820:\tlearn: 0.2394441\ttotal: 18.2s\tremaining: 3.96s\n",
      "821:\tlearn: 0.2392455\ttotal: 18.2s\tremaining: 3.94s\n",
      "822:\tlearn: 0.2389707\ttotal: 18.2s\tremaining: 3.92s\n",
      "823:\tlearn: 0.2388530\ttotal: 18.2s\tremaining: 3.89s\n",
      "824:\tlearn: 0.2385719\ttotal: 18.2s\tremaining: 3.87s\n",
      "825:\tlearn: 0.2384439\ttotal: 18.3s\tremaining: 3.85s\n",
      "826:\tlearn: 0.2383171\ttotal: 18.3s\tremaining: 3.84s\n",
      "827:\tlearn: 0.2381700\ttotal: 18.4s\tremaining: 3.82s\n",
      "828:\tlearn: 0.2379853\ttotal: 18.4s\tremaining: 3.8s\n",
      "829:\tlearn: 0.2378991\ttotal: 18.4s\tremaining: 3.78s\n",
      "830:\tlearn: 0.2375972\ttotal: 18.5s\tremaining: 3.76s\n",
      "831:\tlearn: 0.2373652\ttotal: 18.5s\tremaining: 3.73s\n",
      "832:\tlearn: 0.2372095\ttotal: 18.5s\tremaining: 3.71s\n",
      "833:\tlearn: 0.2370753\ttotal: 18.5s\tremaining: 3.69s\n",
      "834:\tlearn: 0.2369070\ttotal: 18.6s\tremaining: 3.68s\n",
      "835:\tlearn: 0.2366559\ttotal: 18.7s\tremaining: 3.66s\n",
      "836:\tlearn: 0.2364925\ttotal: 18.7s\tremaining: 3.64s\n",
      "837:\tlearn: 0.2363736\ttotal: 18.7s\tremaining: 3.62s\n",
      "838:\tlearn: 0.2361918\ttotal: 18.7s\tremaining: 3.59s\n",
      "839:\tlearn: 0.2359180\ttotal: 18.7s\tremaining: 3.57s\n",
      "840:\tlearn: 0.2357339\ttotal: 18.8s\tremaining: 3.55s\n",
      "841:\tlearn: 0.2353164\ttotal: 18.8s\tremaining: 3.52s\n",
      "842:\tlearn: 0.2351288\ttotal: 18.8s\tremaining: 3.5s\n",
      "843:\tlearn: 0.2348083\ttotal: 18.8s\tremaining: 3.48s\n",
      "844:\tlearn: 0.2346198\ttotal: 18.8s\tremaining: 3.46s\n",
      "845:\tlearn: 0.2342644\ttotal: 18.9s\tremaining: 3.43s\n",
      "846:\tlearn: 0.2339074\ttotal: 18.9s\tremaining: 3.41s\n",
      "847:\tlearn: 0.2336330\ttotal: 18.9s\tremaining: 3.39s\n",
      "848:\tlearn: 0.2333623\ttotal: 18.9s\tremaining: 3.37s\n",
      "849:\tlearn: 0.2330810\ttotal: 18.9s\tremaining: 3.34s\n",
      "850:\tlearn: 0.2329290\ttotal: 19s\tremaining: 3.32s\n",
      "851:\tlearn: 0.2326985\ttotal: 19s\tremaining: 3.3s\n",
      "852:\tlearn: 0.2325457\ttotal: 19s\tremaining: 3.27s\n",
      "853:\tlearn: 0.2323651\ttotal: 19s\tremaining: 3.25s\n",
      "854:\tlearn: 0.2321255\ttotal: 19.1s\tremaining: 3.23s\n",
      "855:\tlearn: 0.2319648\ttotal: 19.1s\tremaining: 3.21s\n",
      "856:\tlearn: 0.2317951\ttotal: 19.1s\tremaining: 3.19s\n",
      "857:\tlearn: 0.2316936\ttotal: 19.1s\tremaining: 3.16s\n",
      "858:\tlearn: 0.2316015\ttotal: 19.1s\tremaining: 3.14s\n",
      "859:\tlearn: 0.2313970\ttotal: 19.1s\tremaining: 3.12s\n",
      "860:\tlearn: 0.2311991\ttotal: 19.2s\tremaining: 3.09s\n",
      "861:\tlearn: 0.2310059\ttotal: 19.2s\tremaining: 3.07s\n",
      "862:\tlearn: 0.2307610\ttotal: 19.2s\tremaining: 3.05s\n",
      "863:\tlearn: 0.2305751\ttotal: 19.2s\tremaining: 3.02s\n",
      "864:\tlearn: 0.2303589\ttotal: 19.2s\tremaining: 3s\n",
      "865:\tlearn: 0.2301247\ttotal: 19.3s\tremaining: 2.98s\n",
      "866:\tlearn: 0.2299709\ttotal: 19.3s\tremaining: 2.96s\n",
      "867:\tlearn: 0.2298717\ttotal: 19.3s\tremaining: 2.94s\n",
      "868:\tlearn: 0.2297827\ttotal: 19.3s\tremaining: 2.91s\n",
      "869:\tlearn: 0.2295278\ttotal: 19.3s\tremaining: 2.89s\n",
      "870:\tlearn: 0.2293701\ttotal: 19.4s\tremaining: 2.87s\n",
      "871:\tlearn: 0.2292491\ttotal: 19.4s\tremaining: 2.84s\n",
      "872:\tlearn: 0.2291842\ttotal: 19.4s\tremaining: 2.82s\n",
      "873:\tlearn: 0.2290209\ttotal: 19.4s\tremaining: 2.8s\n",
      "874:\tlearn: 0.2288740\ttotal: 19.4s\tremaining: 2.77s\n",
      "875:\tlearn: 0.2287313\ttotal: 19.4s\tremaining: 2.75s\n",
      "876:\tlearn: 0.2285722\ttotal: 19.5s\tremaining: 2.73s\n",
      "877:\tlearn: 0.2283742\ttotal: 19.5s\tremaining: 2.71s\n",
      "878:\tlearn: 0.2281947\ttotal: 19.5s\tremaining: 2.69s\n",
      "879:\tlearn: 0.2279730\ttotal: 19.5s\tremaining: 2.66s\n",
      "880:\tlearn: 0.2277700\ttotal: 19.6s\tremaining: 2.64s\n",
      "881:\tlearn: 0.2275421\ttotal: 19.6s\tremaining: 2.62s\n",
      "882:\tlearn: 0.2274251\ttotal: 19.6s\tremaining: 2.6s\n",
      "883:\tlearn: 0.2271864\ttotal: 19.6s\tremaining: 2.57s\n",
      "884:\tlearn: 0.2270045\ttotal: 19.6s\tremaining: 2.55s\n",
      "885:\tlearn: 0.2268548\ttotal: 19.6s\tremaining: 2.53s\n",
      "886:\tlearn: 0.2266573\ttotal: 19.7s\tremaining: 2.5s\n",
      "887:\tlearn: 0.2263601\ttotal: 19.7s\tremaining: 2.48s\n",
      "888:\tlearn: 0.2260799\ttotal: 19.7s\tremaining: 2.46s\n",
      "889:\tlearn: 0.2258922\ttotal: 19.8s\tremaining: 2.44s\n",
      "890:\tlearn: 0.2256664\ttotal: 19.8s\tremaining: 2.42s\n",
      "891:\tlearn: 0.2254896\ttotal: 19.8s\tremaining: 2.4s\n",
      "892:\tlearn: 0.2251944\ttotal: 19.8s\tremaining: 2.37s\n",
      "893:\tlearn: 0.2250156\ttotal: 19.8s\tremaining: 2.35s\n",
      "894:\tlearn: 0.2248536\ttotal: 19.9s\tremaining: 2.33s\n",
      "895:\tlearn: 0.2246599\ttotal: 19.9s\tremaining: 2.31s\n",
      "896:\tlearn: 0.2244521\ttotal: 19.9s\tremaining: 2.29s\n",
      "897:\tlearn: 0.2241720\ttotal: 19.9s\tremaining: 2.26s\n",
      "898:\tlearn: 0.2240221\ttotal: 19.9s\tremaining: 2.24s\n",
      "899:\tlearn: 0.2237340\ttotal: 20s\tremaining: 2.22s\n",
      "900:\tlearn: 0.2234201\ttotal: 20s\tremaining: 2.19s\n",
      "901:\tlearn: 0.2232837\ttotal: 20s\tremaining: 2.17s\n",
      "902:\tlearn: 0.2231561\ttotal: 20s\tremaining: 2.15s\n",
      "903:\tlearn: 0.2229652\ttotal: 20s\tremaining: 2.13s\n",
      "904:\tlearn: 0.2228034\ttotal: 20.1s\tremaining: 2.1s\n",
      "905:\tlearn: 0.2225942\ttotal: 20.1s\tremaining: 2.08s\n",
      "906:\tlearn: 0.2222078\ttotal: 20.1s\tremaining: 2.06s\n",
      "907:\tlearn: 0.2221265\ttotal: 20.1s\tremaining: 2.04s\n",
      "908:\tlearn: 0.2218741\ttotal: 20.1s\tremaining: 2.01s\n",
      "909:\tlearn: 0.2216770\ttotal: 20.1s\tremaining: 1.99s\n",
      "910:\tlearn: 0.2215224\ttotal: 20.2s\tremaining: 1.97s\n",
      "911:\tlearn: 0.2213055\ttotal: 20.2s\tremaining: 1.95s\n",
      "912:\tlearn: 0.2211006\ttotal: 20.2s\tremaining: 1.92s\n",
      "913:\tlearn: 0.2208917\ttotal: 20.2s\tremaining: 1.9s\n",
      "914:\tlearn: 0.2206539\ttotal: 20.2s\tremaining: 1.88s\n",
      "915:\tlearn: 0.2203485\ttotal: 20.2s\tremaining: 1.85s\n",
      "916:\tlearn: 0.2202204\ttotal: 20.3s\tremaining: 1.83s\n",
      "917:\tlearn: 0.2201036\ttotal: 20.3s\tremaining: 1.81s\n",
      "918:\tlearn: 0.2199838\ttotal: 20.3s\tremaining: 1.79s\n",
      "919:\tlearn: 0.2197224\ttotal: 20.3s\tremaining: 1.77s\n",
      "920:\tlearn: 0.2194749\ttotal: 20.4s\tremaining: 1.75s\n",
      "921:\tlearn: 0.2192544\ttotal: 20.4s\tremaining: 1.72s\n",
      "922:\tlearn: 0.2190240\ttotal: 20.4s\tremaining: 1.7s\n",
      "923:\tlearn: 0.2188930\ttotal: 20.4s\tremaining: 1.68s\n",
      "924:\tlearn: 0.2187597\ttotal: 20.4s\tremaining: 1.66s\n",
      "925:\tlearn: 0.2186520\ttotal: 20.6s\tremaining: 1.64s\n",
      "926:\tlearn: 0.2184941\ttotal: 20.6s\tremaining: 1.62s\n",
      "927:\tlearn: 0.2181848\ttotal: 20.6s\tremaining: 1.6s\n",
      "928:\tlearn: 0.2179320\ttotal: 20.6s\tremaining: 1.57s\n",
      "929:\tlearn: 0.2177361\ttotal: 20.6s\tremaining: 1.55s\n",
      "930:\tlearn: 0.2175972\ttotal: 20.6s\tremaining: 1.53s\n",
      "931:\tlearn: 0.2174923\ttotal: 20.6s\tremaining: 1.51s\n",
      "932:\tlearn: 0.2174063\ttotal: 20.7s\tremaining: 1.48s\n",
      "933:\tlearn: 0.2172342\ttotal: 20.7s\tremaining: 1.46s\n",
      "934:\tlearn: 0.2171344\ttotal: 20.7s\tremaining: 1.44s\n",
      "935:\tlearn: 0.2169114\ttotal: 20.7s\tremaining: 1.42s\n",
      "936:\tlearn: 0.2167043\ttotal: 20.7s\tremaining: 1.39s\n",
      "937:\tlearn: 0.2165950\ttotal: 20.8s\tremaining: 1.37s\n",
      "938:\tlearn: 0.2164713\ttotal: 20.8s\tremaining: 1.35s\n",
      "939:\tlearn: 0.2162857\ttotal: 20.9s\tremaining: 1.33s\n",
      "940:\tlearn: 0.2161581\ttotal: 20.9s\tremaining: 1.31s\n",
      "941:\tlearn: 0.2160484\ttotal: 20.9s\tremaining: 1.29s\n",
      "942:\tlearn: 0.2158826\ttotal: 20.9s\tremaining: 1.26s\n",
      "943:\tlearn: 0.2157419\ttotal: 20.9s\tremaining: 1.24s\n",
      "944:\tlearn: 0.2155794\ttotal: 21s\tremaining: 1.22s\n",
      "945:\tlearn: 0.2155394\ttotal: 21s\tremaining: 1.2s\n",
      "946:\tlearn: 0.2153282\ttotal: 21s\tremaining: 1.18s\n",
      "947:\tlearn: 0.2151395\ttotal: 21s\tremaining: 1.15s\n",
      "948:\tlearn: 0.2150075\ttotal: 21.1s\tremaining: 1.13s\n",
      "949:\tlearn: 0.2146634\ttotal: 21.1s\tremaining: 1.11s\n",
      "950:\tlearn: 0.2144242\ttotal: 21.1s\tremaining: 1.09s\n",
      "951:\tlearn: 0.2142764\ttotal: 21.1s\tremaining: 1.06s\n",
      "952:\tlearn: 0.2141100\ttotal: 21.1s\tremaining: 1.04s\n",
      "953:\tlearn: 0.2139665\ttotal: 21.1s\tremaining: 1.02s\n",
      "954:\tlearn: 0.2137592\ttotal: 21.2s\tremaining: 997ms\n",
      "955:\tlearn: 0.2135693\ttotal: 21.2s\tremaining: 975ms\n",
      "956:\tlearn: 0.2133882\ttotal: 21.2s\tremaining: 953ms\n",
      "957:\tlearn: 0.2132514\ttotal: 21.2s\tremaining: 931ms\n",
      "958:\tlearn: 0.2131394\ttotal: 21.2s\tremaining: 908ms\n",
      "959:\tlearn: 0.2129706\ttotal: 21.3s\tremaining: 886ms\n",
      "960:\tlearn: 0.2127394\ttotal: 21.3s\tremaining: 864ms\n",
      "961:\tlearn: 0.2125260\ttotal: 21.3s\tremaining: 842ms\n",
      "962:\tlearn: 0.2124324\ttotal: 21.3s\tremaining: 820ms\n",
      "963:\tlearn: 0.2123482\ttotal: 21.3s\tremaining: 797ms\n",
      "964:\tlearn: 0.2120819\ttotal: 21.4s\tremaining: 775ms\n",
      "965:\tlearn: 0.2119741\ttotal: 21.4s\tremaining: 753ms\n",
      "966:\tlearn: 0.2117483\ttotal: 21.4s\tremaining: 730ms\n",
      "967:\tlearn: 0.2116718\ttotal: 21.4s\tremaining: 708ms\n",
      "968:\tlearn: 0.2115018\ttotal: 21.4s\tremaining: 686ms\n",
      "969:\tlearn: 0.2113895\ttotal: 21.5s\tremaining: 663ms\n",
      "970:\tlearn: 0.2113279\ttotal: 21.5s\tremaining: 641ms\n",
      "971:\tlearn: 0.2112131\ttotal: 21.5s\tremaining: 619ms\n",
      "972:\tlearn: 0.2111007\ttotal: 21.5s\tremaining: 597ms\n",
      "973:\tlearn: 0.2107520\ttotal: 21.5s\tremaining: 575ms\n",
      "974:\tlearn: 0.2104725\ttotal: 21.6s\tremaining: 553ms\n",
      "975:\tlearn: 0.2103436\ttotal: 21.6s\tremaining: 531ms\n",
      "976:\tlearn: 0.2101480\ttotal: 21.6s\tremaining: 509ms\n",
      "977:\tlearn: 0.2099987\ttotal: 21.6s\tremaining: 486ms\n",
      "978:\tlearn: 0.2097937\ttotal: 21.6s\tremaining: 464ms\n",
      "979:\tlearn: 0.2096077\ttotal: 21.7s\tremaining: 442ms\n",
      "980:\tlearn: 0.2094691\ttotal: 21.7s\tremaining: 420ms\n",
      "981:\tlearn: 0.2093282\ttotal: 21.7s\tremaining: 398ms\n",
      "982:\tlearn: 0.2091980\ttotal: 21.7s\tremaining: 375ms\n",
      "983:\tlearn: 0.2088349\ttotal: 21.7s\tremaining: 353ms\n",
      "984:\tlearn: 0.2085796\ttotal: 21.7s\tremaining: 331ms\n",
      "985:\tlearn: 0.2084072\ttotal: 21.8s\tremaining: 309ms\n",
      "986:\tlearn: 0.2083033\ttotal: 21.8s\tremaining: 287ms\n",
      "987:\tlearn: 0.2081656\ttotal: 21.8s\tremaining: 265ms\n",
      "988:\tlearn: 0.2080382\ttotal: 21.8s\tremaining: 243ms\n",
      "989:\tlearn: 0.2078683\ttotal: 21.9s\tremaining: 221ms\n",
      "990:\tlearn: 0.2076895\ttotal: 21.9s\tremaining: 199ms\n",
      "991:\tlearn: 0.2075494\ttotal: 22s\tremaining: 177ms\n",
      "992:\tlearn: 0.2072052\ttotal: 22s\tremaining: 155ms\n",
      "993:\tlearn: 0.2070933\ttotal: 22.1s\tremaining: 133ms\n",
      "994:\tlearn: 0.2069354\ttotal: 22.1s\tremaining: 111ms\n",
      "995:\tlearn: 0.2067177\ttotal: 22.1s\tremaining: 88.9ms\n",
      "996:\tlearn: 0.2065545\ttotal: 22.2s\tremaining: 66.7ms\n",
      "997:\tlearn: 0.2063609\ttotal: 22.2s\tremaining: 44.5ms\n",
      "998:\tlearn: 0.2062106\ttotal: 22.2s\tremaining: 22.2ms\n",
      "999:\tlearn: 0.2059024\ttotal: 22.3s\tremaining: 0us\n",
      "Accuracy, fold_2: 0.8048780487804879\n",
      "Learning rate set to 0.007604\n",
      "0:\tlearn: 0.6888305\ttotal: 88ms\tremaining: 1m 27s\n",
      "1:\tlearn: 0.6844117\ttotal: 132ms\tremaining: 1m 5s\n",
      "2:\tlearn: 0.6801018\ttotal: 165ms\tremaining: 54.7s\n",
      "3:\tlearn: 0.6758608\ttotal: 184ms\tremaining: 45.9s\n",
      "4:\tlearn: 0.6715805\ttotal: 225ms\tremaining: 44.7s\n",
      "5:\tlearn: 0.6673892\ttotal: 290ms\tremaining: 48.1s\n",
      "6:\tlearn: 0.6631807\ttotal: 330ms\tremaining: 46.8s\n",
      "7:\tlearn: 0.6591343\ttotal: 360ms\tremaining: 44.6s\n",
      "8:\tlearn: 0.6550697\ttotal: 385ms\tremaining: 42.4s\n",
      "9:\tlearn: 0.6515586\ttotal: 410ms\tremaining: 40.6s\n",
      "10:\tlearn: 0.6478613\ttotal: 461ms\tremaining: 41.4s\n",
      "11:\tlearn: 0.6441733\ttotal: 520ms\tremaining: 42.8s\n",
      "12:\tlearn: 0.6405917\ttotal: 562ms\tremaining: 42.6s\n",
      "13:\tlearn: 0.6370422\ttotal: 596ms\tremaining: 42s\n",
      "14:\tlearn: 0.6336761\ttotal: 661ms\tremaining: 43.4s\n",
      "15:\tlearn: 0.6304140\ttotal: 789ms\tremaining: 48.5s\n",
      "16:\tlearn: 0.6271885\ttotal: 905ms\tremaining: 52.3s\n",
      "17:\tlearn: 0.6237543\ttotal: 1.06s\tremaining: 58.1s\n",
      "18:\tlearn: 0.6203623\ttotal: 1.13s\tremaining: 58.6s\n",
      "19:\tlearn: 0.6174156\ttotal: 1.19s\tremaining: 58.5s\n",
      "20:\tlearn: 0.6141942\ttotal: 1.38s\tremaining: 1m 4s\n",
      "21:\tlearn: 0.6109829\ttotal: 1.52s\tremaining: 1m 7s\n",
      "22:\tlearn: 0.6074913\ttotal: 1.6s\tremaining: 1m 8s\n",
      "23:\tlearn: 0.6043724\ttotal: 1.69s\tremaining: 1m 8s\n",
      "24:\tlearn: 0.6011453\ttotal: 1.77s\tremaining: 1m 8s\n",
      "25:\tlearn: 0.5982039\ttotal: 1.84s\tremaining: 1m 8s\n",
      "26:\tlearn: 0.5954752\ttotal: 1.9s\tremaining: 1m 8s\n",
      "27:\tlearn: 0.5927206\ttotal: 2.01s\tremaining: 1m 9s\n",
      "28:\tlearn: 0.5898210\ttotal: 2.11s\tremaining: 1m 10s\n",
      "29:\tlearn: 0.5869948\ttotal: 2.17s\tremaining: 1m 10s\n",
      "30:\tlearn: 0.5842304\ttotal: 2.3s\tremaining: 1m 12s\n",
      "31:\tlearn: 0.5814754\ttotal: 2.39s\tremaining: 1m 12s\n",
      "32:\tlearn: 0.5790176\ttotal: 2.52s\tremaining: 1m 14s\n",
      "33:\tlearn: 0.5768660\ttotal: 2.54s\tremaining: 1m 12s\n",
      "34:\tlearn: 0.5743352\ttotal: 2.61s\tremaining: 1m 11s\n",
      "35:\tlearn: 0.5718611\ttotal: 2.65s\tremaining: 1m 10s\n",
      "36:\tlearn: 0.5690668\ttotal: 2.73s\tremaining: 1m 10s\n",
      "37:\tlearn: 0.5665483\ttotal: 2.79s\tremaining: 1m 10s\n",
      "38:\tlearn: 0.5639769\ttotal: 2.84s\tremaining: 1m 10s\n",
      "39:\tlearn: 0.5616156\ttotal: 3.02s\tremaining: 1m 12s\n",
      "40:\tlearn: 0.5591813\ttotal: 3.1s\tremaining: 1m 12s\n",
      "41:\tlearn: 0.5567945\ttotal: 3.22s\tremaining: 1m 13s\n",
      "42:\tlearn: 0.5542311\ttotal: 3.35s\tremaining: 1m 14s\n",
      "43:\tlearn: 0.5518509\ttotal: 3.47s\tremaining: 1m 15s\n",
      "44:\tlearn: 0.5499173\ttotal: 3.58s\tremaining: 1m 15s\n",
      "45:\tlearn: 0.5478229\ttotal: 3.67s\tremaining: 1m 16s\n",
      "46:\tlearn: 0.5457917\ttotal: 3.77s\tremaining: 1m 16s\n",
      "47:\tlearn: 0.5437308\ttotal: 3.87s\tremaining: 1m 16s\n",
      "48:\tlearn: 0.5418313\ttotal: 3.99s\tremaining: 1m 17s\n",
      "49:\tlearn: 0.5396661\ttotal: 4.06s\tremaining: 1m 17s\n",
      "50:\tlearn: 0.5374988\ttotal: 4.17s\tremaining: 1m 17s\n",
      "51:\tlearn: 0.5354995\ttotal: 4.25s\tremaining: 1m 17s\n",
      "52:\tlearn: 0.5334518\ttotal: 4.32s\tremaining: 1m 17s\n",
      "53:\tlearn: 0.5316305\ttotal: 4.41s\tremaining: 1m 17s\n",
      "54:\tlearn: 0.5297553\ttotal: 4.48s\tremaining: 1m 16s\n",
      "55:\tlearn: 0.5279170\ttotal: 4.55s\tremaining: 1m 16s\n",
      "56:\tlearn: 0.5263620\ttotal: 4.63s\tremaining: 1m 16s\n",
      "57:\tlearn: 0.5244378\ttotal: 4.69s\tremaining: 1m 16s\n",
      "58:\tlearn: 0.5228919\ttotal: 4.74s\tremaining: 1m 15s\n",
      "59:\tlearn: 0.5213405\ttotal: 4.81s\tremaining: 1m 15s\n",
      "60:\tlearn: 0.5195981\ttotal: 4.88s\tremaining: 1m 15s\n",
      "61:\tlearn: 0.5177911\ttotal: 4.93s\tremaining: 1m 14s\n",
      "62:\tlearn: 0.5162310\ttotal: 5.01s\tremaining: 1m 14s\n",
      "63:\tlearn: 0.5143081\ttotal: 5.13s\tremaining: 1m 15s\n",
      "64:\tlearn: 0.5127665\ttotal: 5.18s\tremaining: 1m 14s\n",
      "65:\tlearn: 0.5111433\ttotal: 5.27s\tremaining: 1m 14s\n",
      "66:\tlearn: 0.5097695\ttotal: 5.33s\tremaining: 1m 14s\n",
      "67:\tlearn: 0.5079832\ttotal: 5.39s\tremaining: 1m 13s\n",
      "68:\tlearn: 0.5064558\ttotal: 5.48s\tremaining: 1m 13s\n",
      "69:\tlearn: 0.5047733\ttotal: 5.53s\tremaining: 1m 13s\n",
      "70:\tlearn: 0.5027572\ttotal: 5.56s\tremaining: 1m 12s\n",
      "71:\tlearn: 0.5012295\ttotal: 5.61s\tremaining: 1m 12s\n",
      "72:\tlearn: 0.4996261\ttotal: 5.67s\tremaining: 1m 11s\n",
      "73:\tlearn: 0.4981542\ttotal: 5.76s\tremaining: 1m 12s\n",
      "74:\tlearn: 0.4967438\ttotal: 5.82s\tremaining: 1m 11s\n",
      "75:\tlearn: 0.4951526\ttotal: 5.86s\tremaining: 1m 11s\n",
      "76:\tlearn: 0.4935996\ttotal: 5.89s\tremaining: 1m 10s\n",
      "77:\tlearn: 0.4923347\ttotal: 5.95s\tremaining: 1m 10s\n",
      "78:\tlearn: 0.4911824\ttotal: 6.02s\tremaining: 1m 10s\n",
      "79:\tlearn: 0.4898039\ttotal: 6.06s\tremaining: 1m 9s\n",
      "80:\tlearn: 0.4883398\ttotal: 6.1s\tremaining: 1m 9s\n",
      "81:\tlearn: 0.4872109\ttotal: 6.12s\tremaining: 1m 8s\n",
      "82:\tlearn: 0.4858882\ttotal: 6.16s\tremaining: 1m 8s\n",
      "83:\tlearn: 0.4843234\ttotal: 6.23s\tremaining: 1m 7s\n",
      "84:\tlearn: 0.4827746\ttotal: 6.27s\tremaining: 1m 7s\n",
      "85:\tlearn: 0.4813837\ttotal: 6.31s\tremaining: 1m 7s\n",
      "86:\tlearn: 0.4799790\ttotal: 6.34s\tremaining: 1m 6s\n",
      "87:\tlearn: 0.4787375\ttotal: 6.37s\tremaining: 1m 5s\n",
      "88:\tlearn: 0.4774563\ttotal: 6.39s\tremaining: 1m 5s\n",
      "89:\tlearn: 0.4760894\ttotal: 6.42s\tremaining: 1m 4s\n",
      "90:\tlearn: 0.4753562\ttotal: 6.54s\tremaining: 1m 5s\n",
      "91:\tlearn: 0.4741565\ttotal: 6.61s\tremaining: 1m 5s\n",
      "92:\tlearn: 0.4733938\ttotal: 6.67s\tremaining: 1m 5s\n",
      "93:\tlearn: 0.4721092\ttotal: 6.74s\tremaining: 1m 4s\n",
      "94:\tlearn: 0.4708188\ttotal: 6.81s\tremaining: 1m 4s\n",
      "95:\tlearn: 0.4700123\ttotal: 6.86s\tremaining: 1m 4s\n",
      "96:\tlearn: 0.4687800\ttotal: 6.89s\tremaining: 1m 4s\n",
      "97:\tlearn: 0.4677828\ttotal: 6.92s\tremaining: 1m 3s\n",
      "98:\tlearn: 0.4667611\ttotal: 6.96s\tremaining: 1m 3s\n",
      "99:\tlearn: 0.4657275\ttotal: 6.99s\tremaining: 1m 2s\n",
      "100:\tlearn: 0.4645149\ttotal: 7.05s\tremaining: 1m 2s\n",
      "101:\tlearn: 0.4636035\ttotal: 7.15s\tremaining: 1m 2s\n",
      "102:\tlearn: 0.4626712\ttotal: 7.23s\tremaining: 1m 2s\n",
      "103:\tlearn: 0.4620251\ttotal: 7.31s\tremaining: 1m 2s\n",
      "104:\tlearn: 0.4614147\ttotal: 7.35s\tremaining: 1m 2s\n",
      "105:\tlearn: 0.4602880\ttotal: 7.38s\tremaining: 1m 2s\n",
      "106:\tlearn: 0.4592333\ttotal: 7.41s\tremaining: 1m 1s\n",
      "107:\tlearn: 0.4586629\ttotal: 7.46s\tremaining: 1m 1s\n",
      "108:\tlearn: 0.4576418\ttotal: 7.49s\tremaining: 1m 1s\n",
      "109:\tlearn: 0.4564797\ttotal: 7.5s\tremaining: 1m\n",
      "110:\tlearn: 0.4554664\ttotal: 7.53s\tremaining: 1m\n",
      "111:\tlearn: 0.4548064\ttotal: 7.58s\tremaining: 1m\n",
      "112:\tlearn: 0.4539709\ttotal: 7.6s\tremaining: 59.6s\n",
      "113:\tlearn: 0.4529670\ttotal: 7.62s\tremaining: 59.3s\n",
      "114:\tlearn: 0.4523999\ttotal: 7.65s\tremaining: 58.9s\n",
      "115:\tlearn: 0.4513713\ttotal: 7.76s\tremaining: 59.2s\n",
      "116:\tlearn: 0.4509757\ttotal: 7.83s\tremaining: 59.1s\n",
      "117:\tlearn: 0.4498702\ttotal: 7.88s\tremaining: 58.9s\n",
      "118:\tlearn: 0.4490167\ttotal: 7.98s\tremaining: 59.1s\n",
      "119:\tlearn: 0.4481773\ttotal: 8.05s\tremaining: 59s\n",
      "120:\tlearn: 0.4477066\ttotal: 8.13s\tremaining: 59.1s\n",
      "121:\tlearn: 0.4467661\ttotal: 8.21s\tremaining: 59.1s\n",
      "122:\tlearn: 0.4458718\ttotal: 8.32s\tremaining: 59.4s\n",
      "123:\tlearn: 0.4448634\ttotal: 8.38s\tremaining: 59.2s\n",
      "124:\tlearn: 0.4439701\ttotal: 8.47s\tremaining: 59.3s\n",
      "125:\tlearn: 0.4434585\ttotal: 8.55s\tremaining: 59.3s\n",
      "126:\tlearn: 0.4429937\ttotal: 8.58s\tremaining: 59s\n",
      "127:\tlearn: 0.4421862\ttotal: 8.64s\tremaining: 58.9s\n",
      "128:\tlearn: 0.4413300\ttotal: 8.71s\tremaining: 58.8s\n",
      "129:\tlearn: 0.4408230\ttotal: 8.79s\tremaining: 58.8s\n",
      "130:\tlearn: 0.4402454\ttotal: 8.88s\tremaining: 58.9s\n",
      "131:\tlearn: 0.4393780\ttotal: 8.94s\tremaining: 58.8s\n",
      "132:\tlearn: 0.4386225\ttotal: 9.03s\tremaining: 58.9s\n",
      "133:\tlearn: 0.4376191\ttotal: 9.1s\tremaining: 58.8s\n",
      "134:\tlearn: 0.4370370\ttotal: 9.15s\tremaining: 58.6s\n",
      "135:\tlearn: 0.4362516\ttotal: 9.22s\tremaining: 58.6s\n",
      "136:\tlearn: 0.4355458\ttotal: 9.3s\tremaining: 58.6s\n",
      "137:\tlearn: 0.4347752\ttotal: 9.53s\tremaining: 59.5s\n",
      "138:\tlearn: 0.4340814\ttotal: 9.62s\tremaining: 59.6s\n",
      "139:\tlearn: 0.4331946\ttotal: 9.7s\tremaining: 59.6s\n",
      "140:\tlearn: 0.4323793\ttotal: 9.74s\tremaining: 59.4s\n",
      "141:\tlearn: 0.4317524\ttotal: 9.8s\tremaining: 59.2s\n",
      "142:\tlearn: 0.4310385\ttotal: 9.84s\tremaining: 59s\n",
      "143:\tlearn: 0.4301619\ttotal: 9.89s\tremaining: 58.8s\n",
      "144:\tlearn: 0.4295374\ttotal: 9.96s\tremaining: 58.7s\n",
      "145:\tlearn: 0.4286755\ttotal: 10.1s\tremaining: 59s\n",
      "146:\tlearn: 0.4280735\ttotal: 10.2s\tremaining: 59s\n",
      "147:\tlearn: 0.4276153\ttotal: 10.2s\tremaining: 58.9s\n",
      "148:\tlearn: 0.4270181\ttotal: 10.3s\tremaining: 59.1s\n",
      "149:\tlearn: 0.4262757\ttotal: 10.4s\tremaining: 58.9s\n",
      "150:\tlearn: 0.4255248\ttotal: 10.4s\tremaining: 58.7s\n",
      "151:\tlearn: 0.4248730\ttotal: 10.6s\tremaining: 58.9s\n",
      "152:\tlearn: 0.4242856\ttotal: 10.7s\tremaining: 59.1s\n",
      "153:\tlearn: 0.4238708\ttotal: 10.7s\tremaining: 59s\n",
      "154:\tlearn: 0.4232551\ttotal: 10.8s\tremaining: 58.9s\n",
      "155:\tlearn: 0.4226356\ttotal: 10.8s\tremaining: 58.6s\n",
      "156:\tlearn: 0.4220092\ttotal: 10.9s\tremaining: 58.3s\n",
      "157:\tlearn: 0.4215364\ttotal: 10.9s\tremaining: 58s\n",
      "158:\tlearn: 0.4206049\ttotal: 10.9s\tremaining: 57.8s\n",
      "159:\tlearn: 0.4201554\ttotal: 11s\tremaining: 57.6s\n",
      "160:\tlearn: 0.4198548\ttotal: 11s\tremaining: 57.2s\n",
      "161:\tlearn: 0.4194698\ttotal: 11s\tremaining: 57s\n",
      "162:\tlearn: 0.4189687\ttotal: 11s\tremaining: 56.7s\n",
      "163:\tlearn: 0.4182237\ttotal: 11.1s\tremaining: 56.5s\n",
      "164:\tlearn: 0.4178494\ttotal: 11.1s\tremaining: 56.3s\n",
      "165:\tlearn: 0.4172544\ttotal: 11.1s\tremaining: 56s\n",
      "166:\tlearn: 0.4165887\ttotal: 11.2s\tremaining: 55.8s\n",
      "167:\tlearn: 0.4161769\ttotal: 11.2s\tremaining: 55.6s\n",
      "168:\tlearn: 0.4156357\ttotal: 11.3s\tremaining: 55.4s\n",
      "169:\tlearn: 0.4150285\ttotal: 11.3s\tremaining: 55.2s\n",
      "170:\tlearn: 0.4143167\ttotal: 11.3s\tremaining: 55s\n",
      "171:\tlearn: 0.4138716\ttotal: 11.4s\tremaining: 54.9s\n",
      "172:\tlearn: 0.4133033\ttotal: 11.5s\tremaining: 54.8s\n",
      "173:\tlearn: 0.4127142\ttotal: 11.5s\tremaining: 54.6s\n",
      "174:\tlearn: 0.4121450\ttotal: 11.5s\tremaining: 54.3s\n",
      "175:\tlearn: 0.4115048\ttotal: 11.6s\tremaining: 54.1s\n",
      "176:\tlearn: 0.4107962\ttotal: 11.6s\tremaining: 53.9s\n",
      "177:\tlearn: 0.4104451\ttotal: 11.6s\tremaining: 53.6s\n",
      "178:\tlearn: 0.4099300\ttotal: 11.6s\tremaining: 53.3s\n",
      "179:\tlearn: 0.4092981\ttotal: 11.7s\tremaining: 53.1s\n",
      "180:\tlearn: 0.4089034\ttotal: 11.7s\tremaining: 52.9s\n",
      "181:\tlearn: 0.4084003\ttotal: 11.7s\tremaining: 52.7s\n",
      "182:\tlearn: 0.4080007\ttotal: 11.8s\tremaining: 52.6s\n",
      "183:\tlearn: 0.4074723\ttotal: 11.8s\tremaining: 52.4s\n",
      "184:\tlearn: 0.4067793\ttotal: 11.8s\tremaining: 52.1s\n",
      "185:\tlearn: 0.4063342\ttotal: 11.9s\tremaining: 51.9s\n",
      "186:\tlearn: 0.4058094\ttotal: 11.9s\tremaining: 51.6s\n",
      "187:\tlearn: 0.4054958\ttotal: 11.9s\tremaining: 51.5s\n",
      "188:\tlearn: 0.4050658\ttotal: 12s\tremaining: 51.3s\n",
      "189:\tlearn: 0.4045364\ttotal: 12s\tremaining: 51.1s\n",
      "190:\tlearn: 0.4039888\ttotal: 12s\tremaining: 50.9s\n",
      "191:\tlearn: 0.4036094\ttotal: 12s\tremaining: 50.6s\n",
      "192:\tlearn: 0.4031427\ttotal: 12.1s\tremaining: 50.4s\n",
      "193:\tlearn: 0.4027120\ttotal: 12.1s\tremaining: 50.2s\n",
      "194:\tlearn: 0.4024202\ttotal: 12.1s\tremaining: 50s\n",
      "195:\tlearn: 0.4019505\ttotal: 12.1s\tremaining: 49.8s\n",
      "196:\tlearn: 0.4014849\ttotal: 12.2s\tremaining: 49.7s\n",
      "197:\tlearn: 0.4010035\ttotal: 12.2s\tremaining: 49.5s\n",
      "198:\tlearn: 0.4003132\ttotal: 12.2s\tremaining: 49.3s\n",
      "199:\tlearn: 0.3998984\ttotal: 12.3s\tremaining: 49.1s\n",
      "200:\tlearn: 0.3992250\ttotal: 12.3s\tremaining: 48.9s\n",
      "201:\tlearn: 0.3987758\ttotal: 12.3s\tremaining: 48.7s\n",
      "202:\tlearn: 0.3984256\ttotal: 12.4s\tremaining: 48.5s\n",
      "203:\tlearn: 0.3980664\ttotal: 12.4s\tremaining: 48.3s\n",
      "204:\tlearn: 0.3977815\ttotal: 12.4s\tremaining: 48.3s\n",
      "205:\tlearn: 0.3974112\ttotal: 12.5s\tremaining: 48.1s\n",
      "206:\tlearn: 0.3971722\ttotal: 12.5s\tremaining: 47.9s\n",
      "207:\tlearn: 0.3967708\ttotal: 12.5s\tremaining: 47.7s\n",
      "208:\tlearn: 0.3962429\ttotal: 12.5s\tremaining: 47.5s\n",
      "209:\tlearn: 0.3958914\ttotal: 12.6s\tremaining: 47.3s\n",
      "210:\tlearn: 0.3951911\ttotal: 12.6s\tremaining: 47.1s\n",
      "211:\tlearn: 0.3947206\ttotal: 12.6s\tremaining: 47s\n",
      "212:\tlearn: 0.3943531\ttotal: 12.7s\tremaining: 46.9s\n",
      "213:\tlearn: 0.3940932\ttotal: 12.7s\tremaining: 46.7s\n",
      "214:\tlearn: 0.3937762\ttotal: 12.8s\tremaining: 46.6s\n",
      "215:\tlearn: 0.3933551\ttotal: 12.8s\tremaining: 46.5s\n",
      "216:\tlearn: 0.3928731\ttotal: 12.9s\tremaining: 46.4s\n",
      "217:\tlearn: 0.3923306\ttotal: 12.9s\tremaining: 46.4s\n",
      "218:\tlearn: 0.3919796\ttotal: 13s\tremaining: 46.3s\n",
      "219:\tlearn: 0.3917380\ttotal: 13s\tremaining: 46.1s\n",
      "220:\tlearn: 0.3912022\ttotal: 13s\tremaining: 45.9s\n",
      "221:\tlearn: 0.3909484\ttotal: 13s\tremaining: 45.7s\n",
      "222:\tlearn: 0.3903792\ttotal: 13.1s\tremaining: 45.5s\n",
      "223:\tlearn: 0.3900550\ttotal: 13.1s\tremaining: 45.3s\n",
      "224:\tlearn: 0.3893170\ttotal: 13.1s\tremaining: 45.2s\n",
      "225:\tlearn: 0.3889226\ttotal: 13.1s\tremaining: 45s\n",
      "226:\tlearn: 0.3885509\ttotal: 13.2s\tremaining: 44.9s\n",
      "227:\tlearn: 0.3878887\ttotal: 13.2s\tremaining: 44.7s\n",
      "228:\tlearn: 0.3874156\ttotal: 13.2s\tremaining: 44.6s\n",
      "229:\tlearn: 0.3869922\ttotal: 13.2s\tremaining: 44.4s\n",
      "230:\tlearn: 0.3866046\ttotal: 13.3s\tremaining: 44.2s\n",
      "231:\tlearn: 0.3861320\ttotal: 13.3s\tremaining: 44s\n",
      "232:\tlearn: 0.3859072\ttotal: 13.3s\tremaining: 43.8s\n",
      "233:\tlearn: 0.3855760\ttotal: 13.3s\tremaining: 43.6s\n",
      "234:\tlearn: 0.3851714\ttotal: 13.3s\tremaining: 43.4s\n",
      "235:\tlearn: 0.3849165\ttotal: 13.4s\tremaining: 43.3s\n",
      "236:\tlearn: 0.3844686\ttotal: 13.4s\tremaining: 43.3s\n",
      "237:\tlearn: 0.3841917\ttotal: 13.5s\tremaining: 43.1s\n",
      "238:\tlearn: 0.3838266\ttotal: 13.5s\tremaining: 42.9s\n",
      "239:\tlearn: 0.3833979\ttotal: 13.5s\tremaining: 42.7s\n",
      "240:\tlearn: 0.3830253\ttotal: 13.5s\tremaining: 42.6s\n",
      "241:\tlearn: 0.3827148\ttotal: 13.5s\tremaining: 42.4s\n",
      "242:\tlearn: 0.3823362\ttotal: 13.6s\tremaining: 42.2s\n",
      "243:\tlearn: 0.3821248\ttotal: 13.6s\tremaining: 42.1s\n",
      "244:\tlearn: 0.3816343\ttotal: 13.6s\tremaining: 41.9s\n",
      "245:\tlearn: 0.3813869\ttotal: 13.6s\tremaining: 41.7s\n",
      "246:\tlearn: 0.3810104\ttotal: 13.6s\tremaining: 41.6s\n",
      "247:\tlearn: 0.3806775\ttotal: 13.7s\tremaining: 41.5s\n",
      "248:\tlearn: 0.3802620\ttotal: 13.7s\tremaining: 41.3s\n",
      "249:\tlearn: 0.3800414\ttotal: 13.7s\tremaining: 41.2s\n",
      "250:\tlearn: 0.3797647\ttotal: 13.7s\tremaining: 41s\n",
      "251:\tlearn: 0.3794798\ttotal: 13.8s\tremaining: 40.8s\n",
      "252:\tlearn: 0.3792114\ttotal: 13.8s\tremaining: 40.7s\n",
      "253:\tlearn: 0.3789834\ttotal: 13.8s\tremaining: 40.5s\n",
      "254:\tlearn: 0.3787144\ttotal: 13.8s\tremaining: 40.4s\n",
      "255:\tlearn: 0.3783313\ttotal: 13.8s\tremaining: 40.2s\n",
      "256:\tlearn: 0.3780039\ttotal: 13.9s\tremaining: 40s\n",
      "257:\tlearn: 0.3774054\ttotal: 13.9s\tremaining: 40s\n",
      "258:\tlearn: 0.3771760\ttotal: 13.9s\tremaining: 39.8s\n",
      "259:\tlearn: 0.3766648\ttotal: 14s\tremaining: 39.7s\n",
      "260:\tlearn: 0.3760987\ttotal: 14s\tremaining: 39.6s\n",
      "261:\tlearn: 0.3756919\ttotal: 14s\tremaining: 39.4s\n",
      "262:\tlearn: 0.3753180\ttotal: 14s\tremaining: 39.3s\n",
      "263:\tlearn: 0.3749963\ttotal: 14.1s\tremaining: 39.2s\n",
      "264:\tlearn: 0.3745768\ttotal: 14.1s\tremaining: 39.1s\n",
      "265:\tlearn: 0.3743260\ttotal: 14.1s\tremaining: 39s\n",
      "266:\tlearn: 0.3740663\ttotal: 14.1s\tremaining: 38.8s\n",
      "267:\tlearn: 0.3738853\ttotal: 14.2s\tremaining: 38.7s\n",
      "268:\tlearn: 0.3734944\ttotal: 14.2s\tremaining: 38.6s\n",
      "269:\tlearn: 0.3732204\ttotal: 14.2s\tremaining: 38.4s\n",
      "270:\tlearn: 0.3729094\ttotal: 14.2s\tremaining: 38.3s\n",
      "271:\tlearn: 0.3724557\ttotal: 14.3s\tremaining: 38.2s\n",
      "272:\tlearn: 0.3718945\ttotal: 14.3s\tremaining: 38.1s\n",
      "273:\tlearn: 0.3716502\ttotal: 14.3s\tremaining: 38s\n",
      "274:\tlearn: 0.3712787\ttotal: 14.4s\tremaining: 37.9s\n",
      "275:\tlearn: 0.3708533\ttotal: 14.4s\tremaining: 37.7s\n",
      "276:\tlearn: 0.3704574\ttotal: 14.4s\tremaining: 37.6s\n",
      "277:\tlearn: 0.3700848\ttotal: 14.4s\tremaining: 37.5s\n",
      "278:\tlearn: 0.3697890\ttotal: 14.5s\tremaining: 37.4s\n",
      "279:\tlearn: 0.3693763\ttotal: 14.5s\tremaining: 37.2s\n",
      "280:\tlearn: 0.3689899\ttotal: 14.5s\tremaining: 37.1s\n",
      "281:\tlearn: 0.3687748\ttotal: 14.6s\tremaining: 37.1s\n",
      "282:\tlearn: 0.3684536\ttotal: 14.6s\tremaining: 37s\n",
      "283:\tlearn: 0.3682201\ttotal: 14.6s\tremaining: 36.8s\n",
      "284:\tlearn: 0.3679931\ttotal: 14.6s\tremaining: 36.7s\n",
      "285:\tlearn: 0.3677646\ttotal: 14.6s\tremaining: 36.6s\n",
      "286:\tlearn: 0.3673968\ttotal: 14.7s\tremaining: 36.5s\n",
      "287:\tlearn: 0.3671942\ttotal: 14.7s\tremaining: 36.3s\n",
      "288:\tlearn: 0.3669142\ttotal: 14.7s\tremaining: 36.2s\n",
      "289:\tlearn: 0.3664778\ttotal: 14.8s\tremaining: 36.1s\n",
      "290:\tlearn: 0.3662900\ttotal: 14.8s\tremaining: 36.1s\n",
      "291:\tlearn: 0.3660975\ttotal: 14.8s\tremaining: 35.9s\n",
      "292:\tlearn: 0.3656560\ttotal: 14.8s\tremaining: 35.8s\n",
      "293:\tlearn: 0.3654084\ttotal: 14.9s\tremaining: 35.8s\n",
      "294:\tlearn: 0.3648742\ttotal: 14.9s\tremaining: 35.7s\n",
      "295:\tlearn: 0.3644693\ttotal: 15s\tremaining: 35.6s\n",
      "296:\tlearn: 0.3642391\ttotal: 15s\tremaining: 35.5s\n",
      "297:\tlearn: 0.3640354\ttotal: 15s\tremaining: 35.4s\n",
      "298:\tlearn: 0.3637773\ttotal: 15.1s\tremaining: 35.4s\n",
      "299:\tlearn: 0.3634580\ttotal: 15.1s\tremaining: 35.3s\n",
      "300:\tlearn: 0.3630559\ttotal: 15.2s\tremaining: 35.2s\n",
      "301:\tlearn: 0.3628942\ttotal: 15.2s\tremaining: 35.2s\n",
      "302:\tlearn: 0.3621888\ttotal: 15.3s\tremaining: 35.2s\n",
      "303:\tlearn: 0.3617705\ttotal: 15.4s\tremaining: 35.3s\n",
      "304:\tlearn: 0.3614120\ttotal: 15.5s\tremaining: 35.2s\n",
      "305:\tlearn: 0.3611182\ttotal: 15.6s\tremaining: 35.3s\n",
      "306:\tlearn: 0.3608640\ttotal: 15.6s\tremaining: 35.3s\n",
      "307:\tlearn: 0.3606278\ttotal: 15.7s\tremaining: 35.2s\n",
      "308:\tlearn: 0.3603760\ttotal: 15.7s\tremaining: 35.1s\n",
      "309:\tlearn: 0.3599207\ttotal: 15.7s\tremaining: 35.1s\n",
      "310:\tlearn: 0.3595403\ttotal: 15.8s\tremaining: 35s\n",
      "311:\tlearn: 0.3592829\ttotal: 15.8s\tremaining: 34.9s\n",
      "312:\tlearn: 0.3589460\ttotal: 15.9s\tremaining: 34.8s\n",
      "313:\tlearn: 0.3585245\ttotal: 15.9s\tremaining: 34.8s\n",
      "314:\tlearn: 0.3582967\ttotal: 16s\tremaining: 34.8s\n",
      "315:\tlearn: 0.3579809\ttotal: 16.1s\tremaining: 34.8s\n",
      "316:\tlearn: 0.3578118\ttotal: 16.1s\tremaining: 34.7s\n",
      "317:\tlearn: 0.3576317\ttotal: 16.1s\tremaining: 34.6s\n",
      "318:\tlearn: 0.3573068\ttotal: 16.2s\tremaining: 34.5s\n",
      "319:\tlearn: 0.3570755\ttotal: 16.2s\tremaining: 34.4s\n",
      "320:\tlearn: 0.3567317\ttotal: 16.2s\tremaining: 34.3s\n",
      "321:\tlearn: 0.3564291\ttotal: 16.3s\tremaining: 34.3s\n",
      "322:\tlearn: 0.3562184\ttotal: 16.3s\tremaining: 34.2s\n",
      "323:\tlearn: 0.3559973\ttotal: 16.4s\tremaining: 34.1s\n",
      "324:\tlearn: 0.3558034\ttotal: 16.4s\tremaining: 34.1s\n",
      "325:\tlearn: 0.3554603\ttotal: 16.4s\tremaining: 34s\n",
      "326:\tlearn: 0.3552333\ttotal: 16.5s\tremaining: 34.1s\n",
      "327:\tlearn: 0.3547700\ttotal: 16.6s\tremaining: 34s\n",
      "328:\tlearn: 0.3543158\ttotal: 16.7s\tremaining: 34s\n",
      "329:\tlearn: 0.3539308\ttotal: 16.7s\tremaining: 33.9s\n",
      "330:\tlearn: 0.3535692\ttotal: 16.7s\tremaining: 33.8s\n",
      "331:\tlearn: 0.3532078\ttotal: 16.8s\tremaining: 33.8s\n",
      "332:\tlearn: 0.3530263\ttotal: 16.8s\tremaining: 33.7s\n",
      "333:\tlearn: 0.3528214\ttotal: 16.9s\tremaining: 33.6s\n",
      "334:\tlearn: 0.3523984\ttotal: 16.9s\tremaining: 33.5s\n",
      "335:\tlearn: 0.3521796\ttotal: 16.9s\tremaining: 33.4s\n",
      "336:\tlearn: 0.3517435\ttotal: 16.9s\tremaining: 33.3s\n",
      "337:\tlearn: 0.3514426\ttotal: 16.9s\tremaining: 33.2s\n",
      "338:\tlearn: 0.3511706\ttotal: 17s\tremaining: 33.1s\n",
      "339:\tlearn: 0.3508143\ttotal: 17s\tremaining: 33s\n",
      "340:\tlearn: 0.3506200\ttotal: 17.1s\tremaining: 33s\n",
      "341:\tlearn: 0.3502602\ttotal: 17.1s\tremaining: 33s\n",
      "342:\tlearn: 0.3499371\ttotal: 17.2s\tremaining: 32.9s\n",
      "343:\tlearn: 0.3497480\ttotal: 17.2s\tremaining: 32.8s\n",
      "344:\tlearn: 0.3494680\ttotal: 17.2s\tremaining: 32.7s\n",
      "345:\tlearn: 0.3492584\ttotal: 17.3s\tremaining: 32.8s\n",
      "346:\tlearn: 0.3489639\ttotal: 17.4s\tremaining: 32.7s\n",
      "347:\tlearn: 0.3486384\ttotal: 17.4s\tremaining: 32.6s\n",
      "348:\tlearn: 0.3482593\ttotal: 17.4s\tremaining: 32.5s\n",
      "349:\tlearn: 0.3479732\ttotal: 17.5s\tremaining: 32.5s\n",
      "350:\tlearn: 0.3477452\ttotal: 17.5s\tremaining: 32.4s\n",
      "351:\tlearn: 0.3476157\ttotal: 17.5s\tremaining: 32.3s\n",
      "352:\tlearn: 0.3473218\ttotal: 17.6s\tremaining: 32.2s\n",
      "353:\tlearn: 0.3470812\ttotal: 17.6s\tremaining: 32.1s\n",
      "354:\tlearn: 0.3466848\ttotal: 17.6s\tremaining: 32s\n",
      "355:\tlearn: 0.3464654\ttotal: 17.6s\tremaining: 31.9s\n",
      "356:\tlearn: 0.3462817\ttotal: 17.7s\tremaining: 31.8s\n",
      "357:\tlearn: 0.3460299\ttotal: 17.7s\tremaining: 31.7s\n",
      "358:\tlearn: 0.3458300\ttotal: 17.7s\tremaining: 31.6s\n",
      "359:\tlearn: 0.3455697\ttotal: 17.8s\tremaining: 31.6s\n",
      "360:\tlearn: 0.3450588\ttotal: 17.8s\tremaining: 31.5s\n",
      "361:\tlearn: 0.3448384\ttotal: 17.8s\tremaining: 31.4s\n",
      "362:\tlearn: 0.3443711\ttotal: 17.8s\tremaining: 31.3s\n",
      "363:\tlearn: 0.3439969\ttotal: 17.9s\tremaining: 31.2s\n",
      "364:\tlearn: 0.3436114\ttotal: 17.9s\tremaining: 31.1s\n",
      "365:\tlearn: 0.3433487\ttotal: 17.9s\tremaining: 31s\n",
      "366:\tlearn: 0.3430578\ttotal: 17.9s\tremaining: 31s\n",
      "367:\tlearn: 0.3426973\ttotal: 18s\tremaining: 30.9s\n",
      "368:\tlearn: 0.3425618\ttotal: 18s\tremaining: 30.8s\n",
      "369:\tlearn: 0.3422952\ttotal: 18s\tremaining: 30.7s\n",
      "370:\tlearn: 0.3419269\ttotal: 18.1s\tremaining: 30.6s\n",
      "371:\tlearn: 0.3415181\ttotal: 18.1s\tremaining: 30.5s\n",
      "372:\tlearn: 0.3411531\ttotal: 18.1s\tremaining: 30.5s\n",
      "373:\tlearn: 0.3409164\ttotal: 18.3s\tremaining: 30.6s\n",
      "374:\tlearn: 0.3406211\ttotal: 18.3s\tremaining: 30.5s\n",
      "375:\tlearn: 0.3404071\ttotal: 18.3s\tremaining: 30.4s\n",
      "376:\tlearn: 0.3400694\ttotal: 18.4s\tremaining: 30.4s\n",
      "377:\tlearn: 0.3397365\ttotal: 18.4s\tremaining: 30.3s\n",
      "378:\tlearn: 0.3393802\ttotal: 18.4s\tremaining: 30.2s\n",
      "379:\tlearn: 0.3391693\ttotal: 18.4s\tremaining: 30.1s\n",
      "380:\tlearn: 0.3389020\ttotal: 18.5s\tremaining: 30s\n",
      "381:\tlearn: 0.3385541\ttotal: 18.5s\tremaining: 29.9s\n",
      "382:\tlearn: 0.3382956\ttotal: 18.5s\tremaining: 29.9s\n",
      "383:\tlearn: 0.3379544\ttotal: 18.6s\tremaining: 29.8s\n",
      "384:\tlearn: 0.3377912\ttotal: 18.6s\tremaining: 29.7s\n",
      "385:\tlearn: 0.3374896\ttotal: 18.6s\tremaining: 29.6s\n",
      "386:\tlearn: 0.3372655\ttotal: 18.6s\tremaining: 29.5s\n",
      "387:\tlearn: 0.3370404\ttotal: 18.7s\tremaining: 29.4s\n",
      "388:\tlearn: 0.3367873\ttotal: 18.7s\tremaining: 29.4s\n",
      "389:\tlearn: 0.3364535\ttotal: 18.7s\tremaining: 29.3s\n",
      "390:\tlearn: 0.3361798\ttotal: 18.8s\tremaining: 29.2s\n",
      "391:\tlearn: 0.3358959\ttotal: 18.8s\tremaining: 29.2s\n",
      "392:\tlearn: 0.3356284\ttotal: 18.8s\tremaining: 29.1s\n",
      "393:\tlearn: 0.3352982\ttotal: 18.9s\tremaining: 29s\n",
      "394:\tlearn: 0.3351543\ttotal: 18.9s\tremaining: 28.9s\n",
      "395:\tlearn: 0.3349449\ttotal: 18.9s\tremaining: 28.8s\n",
      "396:\tlearn: 0.3345371\ttotal: 18.9s\tremaining: 28.7s\n",
      "397:\tlearn: 0.3343423\ttotal: 18.9s\tremaining: 28.7s\n",
      "398:\tlearn: 0.3341357\ttotal: 19s\tremaining: 28.6s\n",
      "399:\tlearn: 0.3338387\ttotal: 19s\tremaining: 28.5s\n",
      "400:\tlearn: 0.3336802\ttotal: 19s\tremaining: 28.4s\n",
      "401:\tlearn: 0.3333602\ttotal: 19s\tremaining: 28.3s\n",
      "402:\tlearn: 0.3331600\ttotal: 19.1s\tremaining: 28.2s\n",
      "403:\tlearn: 0.3329408\ttotal: 19.1s\tremaining: 28.2s\n",
      "404:\tlearn: 0.3327392\ttotal: 19.1s\tremaining: 28.1s\n",
      "405:\tlearn: 0.3324360\ttotal: 19.2s\tremaining: 28s\n",
      "406:\tlearn: 0.3322142\ttotal: 19.2s\tremaining: 28s\n",
      "407:\tlearn: 0.3320223\ttotal: 19.2s\tremaining: 27.9s\n",
      "408:\tlearn: 0.3319073\ttotal: 19.3s\tremaining: 27.8s\n",
      "409:\tlearn: 0.3317622\ttotal: 19.3s\tremaining: 27.8s\n",
      "410:\tlearn: 0.3315303\ttotal: 19.4s\tremaining: 27.8s\n",
      "411:\tlearn: 0.3312235\ttotal: 19.4s\tremaining: 27.7s\n",
      "412:\tlearn: 0.3310362\ttotal: 19.4s\tremaining: 27.6s\n",
      "413:\tlearn: 0.3307533\ttotal: 19.5s\tremaining: 27.6s\n",
      "414:\tlearn: 0.3303704\ttotal: 19.5s\tremaining: 27.5s\n",
      "415:\tlearn: 0.3301305\ttotal: 19.6s\tremaining: 27.5s\n",
      "416:\tlearn: 0.3298620\ttotal: 19.6s\tremaining: 27.4s\n",
      "417:\tlearn: 0.3296493\ttotal: 19.7s\tremaining: 27.4s\n",
      "418:\tlearn: 0.3292916\ttotal: 19.8s\tremaining: 27.4s\n",
      "419:\tlearn: 0.3290945\ttotal: 19.8s\tremaining: 27.3s\n",
      "420:\tlearn: 0.3289982\ttotal: 19.8s\tremaining: 27.3s\n",
      "421:\tlearn: 0.3287720\ttotal: 19.9s\tremaining: 27.2s\n",
      "422:\tlearn: 0.3284707\ttotal: 19.9s\tremaining: 27.1s\n",
      "423:\tlearn: 0.3282406\ttotal: 20s\tremaining: 27.1s\n",
      "424:\tlearn: 0.3279877\ttotal: 20s\tremaining: 27s\n",
      "425:\tlearn: 0.3279081\ttotal: 20s\tremaining: 27s\n",
      "426:\tlearn: 0.3277438\ttotal: 20.1s\tremaining: 26.9s\n",
      "427:\tlearn: 0.3274592\ttotal: 20.1s\tremaining: 26.8s\n",
      "428:\tlearn: 0.3272778\ttotal: 20.1s\tremaining: 26.8s\n",
      "429:\tlearn: 0.3271332\ttotal: 20.1s\tremaining: 26.7s\n",
      "430:\tlearn: 0.3268970\ttotal: 20.2s\tremaining: 26.6s\n",
      "431:\tlearn: 0.3267299\ttotal: 20.2s\tremaining: 26.6s\n",
      "432:\tlearn: 0.3261945\ttotal: 20.3s\tremaining: 26.5s\n",
      "433:\tlearn: 0.3259883\ttotal: 20.3s\tremaining: 26.5s\n",
      "434:\tlearn: 0.3255245\ttotal: 20.4s\tremaining: 26.5s\n",
      "435:\tlearn: 0.3251383\ttotal: 20.5s\tremaining: 26.5s\n",
      "436:\tlearn: 0.3250023\ttotal: 20.5s\tremaining: 26.4s\n",
      "437:\tlearn: 0.3246578\ttotal: 20.5s\tremaining: 26.4s\n",
      "438:\tlearn: 0.3244978\ttotal: 20.6s\tremaining: 26.3s\n",
      "439:\tlearn: 0.3243306\ttotal: 20.6s\tremaining: 26.2s\n",
      "440:\tlearn: 0.3241951\ttotal: 20.6s\tremaining: 26.1s\n",
      "441:\tlearn: 0.3240028\ttotal: 20.6s\tremaining: 26.1s\n",
      "442:\tlearn: 0.3236596\ttotal: 20.7s\tremaining: 26s\n",
      "443:\tlearn: 0.3234384\ttotal: 20.8s\tremaining: 26s\n",
      "444:\tlearn: 0.3231611\ttotal: 20.8s\tremaining: 26s\n",
      "445:\tlearn: 0.3230744\ttotal: 20.9s\tremaining: 25.9s\n",
      "446:\tlearn: 0.3228117\ttotal: 20.9s\tremaining: 25.9s\n",
      "447:\tlearn: 0.3224520\ttotal: 21s\tremaining: 25.9s\n",
      "448:\tlearn: 0.3221730\ttotal: 21s\tremaining: 25.8s\n",
      "449:\tlearn: 0.3219988\ttotal: 21s\tremaining: 25.7s\n",
      "450:\tlearn: 0.3218666\ttotal: 21.1s\tremaining: 25.6s\n",
      "451:\tlearn: 0.3216108\ttotal: 21.1s\tremaining: 25.6s\n",
      "452:\tlearn: 0.3213145\ttotal: 21.1s\tremaining: 25.5s\n",
      "453:\tlearn: 0.3211150\ttotal: 21.1s\tremaining: 25.4s\n",
      "454:\tlearn: 0.3208797\ttotal: 21.2s\tremaining: 25.3s\n",
      "455:\tlearn: 0.3205497\ttotal: 21.2s\tremaining: 25.3s\n",
      "456:\tlearn: 0.3202466\ttotal: 21.3s\tremaining: 25.3s\n",
      "457:\tlearn: 0.3199301\ttotal: 21.5s\tremaining: 25.4s\n",
      "458:\tlearn: 0.3198151\ttotal: 21.6s\tremaining: 25.4s\n",
      "459:\tlearn: 0.3195080\ttotal: 21.7s\tremaining: 25.5s\n",
      "460:\tlearn: 0.3191883\ttotal: 21.8s\tremaining: 25.4s\n",
      "461:\tlearn: 0.3190120\ttotal: 21.8s\tremaining: 25.4s\n",
      "462:\tlearn: 0.3187879\ttotal: 21.8s\tremaining: 25.3s\n",
      "463:\tlearn: 0.3184935\ttotal: 21.9s\tremaining: 25.3s\n",
      "464:\tlearn: 0.3182713\ttotal: 21.9s\tremaining: 25.2s\n",
      "465:\tlearn: 0.3179930\ttotal: 21.9s\tremaining: 25.1s\n",
      "466:\tlearn: 0.3177148\ttotal: 22s\tremaining: 25.1s\n",
      "467:\tlearn: 0.3174977\ttotal: 22s\tremaining: 25s\n",
      "468:\tlearn: 0.3172751\ttotal: 22s\tremaining: 24.9s\n",
      "469:\tlearn: 0.3168481\ttotal: 22s\tremaining: 24.9s\n",
      "470:\tlearn: 0.3166633\ttotal: 22.1s\tremaining: 24.8s\n",
      "471:\tlearn: 0.3163808\ttotal: 22.1s\tremaining: 24.7s\n",
      "472:\tlearn: 0.3160851\ttotal: 22.1s\tremaining: 24.7s\n",
      "473:\tlearn: 0.3158847\ttotal: 22.2s\tremaining: 24.7s\n",
      "474:\tlearn: 0.3156790\ttotal: 22.3s\tremaining: 24.6s\n",
      "475:\tlearn: 0.3154481\ttotal: 22.3s\tremaining: 24.6s\n",
      "476:\tlearn: 0.3153021\ttotal: 22.4s\tremaining: 24.5s\n",
      "477:\tlearn: 0.3151222\ttotal: 22.4s\tremaining: 24.5s\n",
      "478:\tlearn: 0.3148090\ttotal: 22.5s\tremaining: 24.4s\n",
      "479:\tlearn: 0.3144976\ttotal: 22.5s\tremaining: 24.4s\n",
      "480:\tlearn: 0.3141967\ttotal: 22.5s\tremaining: 24.3s\n",
      "481:\tlearn: 0.3140235\ttotal: 22.5s\tremaining: 24.2s\n",
      "482:\tlearn: 0.3138027\ttotal: 22.6s\tremaining: 24.1s\n",
      "483:\tlearn: 0.3136807\ttotal: 22.6s\tremaining: 24.1s\n",
      "484:\tlearn: 0.3133560\ttotal: 22.6s\tremaining: 24s\n",
      "485:\tlearn: 0.3130879\ttotal: 22.6s\tremaining: 23.9s\n",
      "486:\tlearn: 0.3127423\ttotal: 22.7s\tremaining: 23.9s\n",
      "487:\tlearn: 0.3125895\ttotal: 22.7s\tremaining: 23.9s\n",
      "488:\tlearn: 0.3124183\ttotal: 22.8s\tremaining: 23.9s\n",
      "489:\tlearn: 0.3121576\ttotal: 22.9s\tremaining: 23.8s\n",
      "490:\tlearn: 0.3118156\ttotal: 23s\tremaining: 23.8s\n",
      "491:\tlearn: 0.3114715\ttotal: 23s\tremaining: 23.8s\n",
      "492:\tlearn: 0.3112271\ttotal: 23.1s\tremaining: 23.7s\n",
      "493:\tlearn: 0.3111261\ttotal: 23.2s\tremaining: 23.8s\n",
      "494:\tlearn: 0.3108305\ttotal: 23.2s\tremaining: 23.7s\n",
      "495:\tlearn: 0.3106972\ttotal: 23.3s\tremaining: 23.7s\n",
      "496:\tlearn: 0.3105555\ttotal: 23.4s\tremaining: 23.6s\n",
      "497:\tlearn: 0.3104484\ttotal: 23.5s\tremaining: 23.6s\n",
      "498:\tlearn: 0.3101333\ttotal: 23.5s\tremaining: 23.6s\n",
      "499:\tlearn: 0.3100945\ttotal: 23.5s\tremaining: 23.5s\n",
      "500:\tlearn: 0.3098905\ttotal: 23.6s\tremaining: 23.5s\n",
      "501:\tlearn: 0.3097313\ttotal: 23.6s\tremaining: 23.4s\n",
      "502:\tlearn: 0.3094455\ttotal: 23.6s\tremaining: 23.3s\n",
      "503:\tlearn: 0.3092060\ttotal: 23.7s\tremaining: 23.3s\n",
      "504:\tlearn: 0.3090065\ttotal: 23.7s\tremaining: 23.2s\n",
      "505:\tlearn: 0.3089386\ttotal: 23.7s\tremaining: 23.2s\n",
      "506:\tlearn: 0.3087754\ttotal: 23.8s\tremaining: 23.1s\n",
      "507:\tlearn: 0.3085766\ttotal: 23.8s\tremaining: 23.1s\n",
      "508:\tlearn: 0.3082450\ttotal: 23.9s\tremaining: 23.1s\n",
      "509:\tlearn: 0.3078716\ttotal: 24s\tremaining: 23s\n",
      "510:\tlearn: 0.3076854\ttotal: 24s\tremaining: 23s\n",
      "511:\tlearn: 0.3075295\ttotal: 24.1s\tremaining: 22.9s\n",
      "512:\tlearn: 0.3072265\ttotal: 24.1s\tremaining: 22.9s\n",
      "513:\tlearn: 0.3071244\ttotal: 24.1s\tremaining: 22.8s\n",
      "514:\tlearn: 0.3069465\ttotal: 24.2s\tremaining: 22.8s\n",
      "515:\tlearn: 0.3067265\ttotal: 24.2s\tremaining: 22.7s\n",
      "516:\tlearn: 0.3065302\ttotal: 24.2s\tremaining: 22.7s\n",
      "517:\tlearn: 0.3064542\ttotal: 24.3s\tremaining: 22.6s\n",
      "518:\tlearn: 0.3063218\ttotal: 24.3s\tremaining: 22.5s\n",
      "519:\tlearn: 0.3061826\ttotal: 24.3s\tremaining: 22.5s\n",
      "520:\tlearn: 0.3059845\ttotal: 24.4s\tremaining: 22.4s\n",
      "521:\tlearn: 0.3056594\ttotal: 24.4s\tremaining: 22.4s\n",
      "522:\tlearn: 0.3055272\ttotal: 24.4s\tremaining: 22.3s\n",
      "523:\tlearn: 0.3051122\ttotal: 24.5s\tremaining: 22.2s\n",
      "524:\tlearn: 0.3049428\ttotal: 24.5s\tremaining: 22.2s\n",
      "525:\tlearn: 0.3046533\ttotal: 24.5s\tremaining: 22.1s\n",
      "526:\tlearn: 0.3045620\ttotal: 24.6s\tremaining: 22s\n",
      "527:\tlearn: 0.3042814\ttotal: 24.6s\tremaining: 22s\n",
      "528:\tlearn: 0.3040608\ttotal: 24.6s\tremaining: 21.9s\n",
      "529:\tlearn: 0.3038548\ttotal: 24.7s\tremaining: 21.9s\n",
      "530:\tlearn: 0.3037475\ttotal: 24.7s\tremaining: 21.8s\n",
      "531:\tlearn: 0.3036264\ttotal: 24.7s\tremaining: 21.8s\n",
      "532:\tlearn: 0.3033697\ttotal: 24.8s\tremaining: 21.7s\n",
      "533:\tlearn: 0.3031200\ttotal: 24.8s\tremaining: 21.7s\n",
      "534:\tlearn: 0.3028569\ttotal: 24.9s\tremaining: 21.6s\n",
      "535:\tlearn: 0.3025930\ttotal: 24.9s\tremaining: 21.6s\n",
      "536:\tlearn: 0.3023847\ttotal: 24.9s\tremaining: 21.5s\n",
      "537:\tlearn: 0.3022432\ttotal: 25s\tremaining: 21.5s\n",
      "538:\tlearn: 0.3021165\ttotal: 25.1s\tremaining: 21.4s\n",
      "539:\tlearn: 0.3019393\ttotal: 25.1s\tremaining: 21.4s\n",
      "540:\tlearn: 0.3017737\ttotal: 25.1s\tremaining: 21.3s\n",
      "541:\tlearn: 0.3013514\ttotal: 25.1s\tremaining: 21.2s\n",
      "542:\tlearn: 0.3011774\ttotal: 25.2s\tremaining: 21.2s\n",
      "543:\tlearn: 0.3011034\ttotal: 25.2s\tremaining: 21.1s\n",
      "544:\tlearn: 0.3009159\ttotal: 25.2s\tremaining: 21.1s\n",
      "545:\tlearn: 0.3007743\ttotal: 25.3s\tremaining: 21s\n",
      "546:\tlearn: 0.3004801\ttotal: 25.3s\tremaining: 21s\n",
      "547:\tlearn: 0.3002173\ttotal: 25.3s\tremaining: 20.9s\n",
      "548:\tlearn: 0.2999681\ttotal: 25.3s\tremaining: 20.8s\n",
      "549:\tlearn: 0.2996767\ttotal: 25.4s\tremaining: 20.8s\n",
      "550:\tlearn: 0.2995545\ttotal: 25.4s\tremaining: 20.7s\n",
      "551:\tlearn: 0.2994407\ttotal: 25.4s\tremaining: 20.6s\n",
      "552:\tlearn: 0.2992439\ttotal: 25.5s\tremaining: 20.6s\n",
      "553:\tlearn: 0.2990476\ttotal: 25.5s\tremaining: 20.5s\n",
      "554:\tlearn: 0.2989542\ttotal: 25.5s\tremaining: 20.5s\n",
      "555:\tlearn: 0.2987962\ttotal: 25.5s\tremaining: 20.4s\n",
      "556:\tlearn: 0.2985149\ttotal: 25.6s\tremaining: 20.3s\n",
      "557:\tlearn: 0.2983359\ttotal: 25.6s\tremaining: 20.3s\n",
      "558:\tlearn: 0.2981545\ttotal: 25.7s\tremaining: 20.3s\n",
      "559:\tlearn: 0.2978211\ttotal: 25.7s\tremaining: 20.2s\n",
      "560:\tlearn: 0.2974700\ttotal: 25.8s\tremaining: 20.2s\n",
      "561:\tlearn: 0.2973645\ttotal: 25.8s\tremaining: 20.1s\n",
      "562:\tlearn: 0.2972772\ttotal: 25.8s\tremaining: 20.1s\n",
      "563:\tlearn: 0.2970923\ttotal: 25.9s\tremaining: 20s\n",
      "564:\tlearn: 0.2968717\ttotal: 25.9s\tremaining: 20s\n",
      "565:\tlearn: 0.2966572\ttotal: 26s\tremaining: 19.9s\n",
      "566:\tlearn: 0.2963696\ttotal: 26s\tremaining: 19.8s\n",
      "567:\tlearn: 0.2961523\ttotal: 26s\tremaining: 19.8s\n",
      "568:\tlearn: 0.2959847\ttotal: 26s\tremaining: 19.7s\n",
      "569:\tlearn: 0.2957347\ttotal: 26.1s\tremaining: 19.7s\n",
      "570:\tlearn: 0.2954368\ttotal: 26.1s\tremaining: 19.6s\n",
      "571:\tlearn: 0.2953041\ttotal: 26.2s\tremaining: 19.6s\n",
      "572:\tlearn: 0.2951036\ttotal: 26.2s\tremaining: 19.5s\n",
      "573:\tlearn: 0.2948537\ttotal: 26.2s\tremaining: 19.5s\n",
      "574:\tlearn: 0.2945780\ttotal: 26.2s\tremaining: 19.4s\n",
      "575:\tlearn: 0.2943241\ttotal: 26.3s\tremaining: 19.3s\n",
      "576:\tlearn: 0.2939225\ttotal: 26.3s\tremaining: 19.3s\n",
      "577:\tlearn: 0.2936948\ttotal: 26.3s\tremaining: 19.2s\n",
      "578:\tlearn: 0.2935148\ttotal: 26.4s\tremaining: 19.2s\n",
      "579:\tlearn: 0.2933604\ttotal: 26.4s\tremaining: 19.1s\n",
      "580:\tlearn: 0.2930654\ttotal: 26.4s\tremaining: 19.1s\n",
      "581:\tlearn: 0.2929149\ttotal: 26.4s\tremaining: 19s\n",
      "582:\tlearn: 0.2926523\ttotal: 26.5s\tremaining: 18.9s\n",
      "583:\tlearn: 0.2924751\ttotal: 26.5s\tremaining: 18.9s\n",
      "584:\tlearn: 0.2922671\ttotal: 26.5s\tremaining: 18.8s\n",
      "585:\tlearn: 0.2919580\ttotal: 26.6s\tremaining: 18.8s\n",
      "586:\tlearn: 0.2918346\ttotal: 26.6s\tremaining: 18.7s\n",
      "587:\tlearn: 0.2915518\ttotal: 26.7s\tremaining: 18.7s\n",
      "588:\tlearn: 0.2914095\ttotal: 26.7s\tremaining: 18.6s\n",
      "589:\tlearn: 0.2912164\ttotal: 26.7s\tremaining: 18.6s\n",
      "590:\tlearn: 0.2909583\ttotal: 26.9s\tremaining: 18.6s\n",
      "591:\tlearn: 0.2906782\ttotal: 27s\tremaining: 18.6s\n",
      "592:\tlearn: 0.2905323\ttotal: 27.1s\tremaining: 18.6s\n",
      "593:\tlearn: 0.2903771\ttotal: 27.1s\tremaining: 18.5s\n",
      "594:\tlearn: 0.2901144\ttotal: 27.1s\tremaining: 18.5s\n",
      "595:\tlearn: 0.2899772\ttotal: 27.2s\tremaining: 18.4s\n",
      "596:\tlearn: 0.2898652\ttotal: 27.2s\tremaining: 18.4s\n",
      "597:\tlearn: 0.2897261\ttotal: 27.3s\tremaining: 18.3s\n",
      "598:\tlearn: 0.2895185\ttotal: 27.3s\tremaining: 18.3s\n",
      "599:\tlearn: 0.2892931\ttotal: 27.4s\tremaining: 18.2s\n",
      "600:\tlearn: 0.2890749\ttotal: 27.4s\tremaining: 18.2s\n",
      "601:\tlearn: 0.2887390\ttotal: 27.4s\tremaining: 18.1s\n",
      "602:\tlearn: 0.2885073\ttotal: 27.4s\tremaining: 18.1s\n",
      "603:\tlearn: 0.2883201\ttotal: 27.5s\tremaining: 18s\n",
      "604:\tlearn: 0.2881174\ttotal: 27.5s\tremaining: 18s\n",
      "605:\tlearn: 0.2879019\ttotal: 27.5s\tremaining: 17.9s\n",
      "606:\tlearn: 0.2876041\ttotal: 27.6s\tremaining: 17.9s\n",
      "607:\tlearn: 0.2874692\ttotal: 27.6s\tremaining: 17.8s\n",
      "608:\tlearn: 0.2873049\ttotal: 27.6s\tremaining: 17.8s\n",
      "609:\tlearn: 0.2871798\ttotal: 27.7s\tremaining: 17.7s\n",
      "610:\tlearn: 0.2869698\ttotal: 27.7s\tremaining: 17.7s\n",
      "611:\tlearn: 0.2867562\ttotal: 27.8s\tremaining: 17.6s\n",
      "612:\tlearn: 0.2866654\ttotal: 27.9s\tremaining: 17.6s\n",
      "613:\tlearn: 0.2864818\ttotal: 28s\tremaining: 17.6s\n",
      "614:\tlearn: 0.2863011\ttotal: 28s\tremaining: 17.5s\n",
      "615:\tlearn: 0.2861338\ttotal: 28s\tremaining: 17.5s\n",
      "616:\tlearn: 0.2858187\ttotal: 28s\tremaining: 17.4s\n",
      "617:\tlearn: 0.2857016\ttotal: 28s\tremaining: 17.3s\n",
      "618:\tlearn: 0.2854768\ttotal: 28.1s\tremaining: 17.3s\n",
      "619:\tlearn: 0.2852550\ttotal: 28.1s\tremaining: 17.2s\n",
      "620:\tlearn: 0.2851572\ttotal: 28.1s\tremaining: 17.2s\n",
      "621:\tlearn: 0.2849821\ttotal: 28.2s\tremaining: 17.1s\n",
      "622:\tlearn: 0.2847658\ttotal: 28.2s\tremaining: 17s\n",
      "623:\tlearn: 0.2844062\ttotal: 28.2s\tremaining: 17s\n",
      "624:\tlearn: 0.2842695\ttotal: 28.2s\tremaining: 16.9s\n",
      "625:\tlearn: 0.2840523\ttotal: 28.2s\tremaining: 16.9s\n",
      "626:\tlearn: 0.2838430\ttotal: 28.3s\tremaining: 16.8s\n",
      "627:\tlearn: 0.2837756\ttotal: 28.3s\tremaining: 16.8s\n",
      "628:\tlearn: 0.2835455\ttotal: 28.3s\tremaining: 16.7s\n",
      "629:\tlearn: 0.2833854\ttotal: 28.4s\tremaining: 16.7s\n",
      "630:\tlearn: 0.2833156\ttotal: 28.4s\tremaining: 16.6s\n",
      "631:\tlearn: 0.2831826\ttotal: 28.4s\tremaining: 16.5s\n",
      "632:\tlearn: 0.2829403\ttotal: 28.4s\tremaining: 16.5s\n",
      "633:\tlearn: 0.2827512\ttotal: 28.4s\tremaining: 16.4s\n",
      "634:\tlearn: 0.2825512\ttotal: 28.5s\tremaining: 16.4s\n",
      "635:\tlearn: 0.2823823\ttotal: 28.5s\tremaining: 16.3s\n",
      "636:\tlearn: 0.2822400\ttotal: 28.5s\tremaining: 16.2s\n",
      "637:\tlearn: 0.2820849\ttotal: 28.5s\tremaining: 16.2s\n",
      "638:\tlearn: 0.2818650\ttotal: 28.6s\tremaining: 16.1s\n",
      "639:\tlearn: 0.2816473\ttotal: 28.6s\tremaining: 16.1s\n",
      "640:\tlearn: 0.2814877\ttotal: 28.6s\tremaining: 16s\n",
      "641:\tlearn: 0.2813780\ttotal: 28.6s\tremaining: 16s\n",
      "642:\tlearn: 0.2809783\ttotal: 28.6s\tremaining: 15.9s\n",
      "643:\tlearn: 0.2807071\ttotal: 28.7s\tremaining: 15.8s\n",
      "644:\tlearn: 0.2805030\ttotal: 28.7s\tremaining: 15.8s\n",
      "645:\tlearn: 0.2802787\ttotal: 28.7s\tremaining: 15.7s\n",
      "646:\tlearn: 0.2801799\ttotal: 28.7s\tremaining: 15.7s\n",
      "647:\tlearn: 0.2800204\ttotal: 28.7s\tremaining: 15.6s\n",
      "648:\tlearn: 0.2797815\ttotal: 28.8s\tremaining: 15.6s\n",
      "649:\tlearn: 0.2796004\ttotal: 28.8s\tremaining: 15.5s\n",
      "650:\tlearn: 0.2793628\ttotal: 28.8s\tremaining: 15.4s\n",
      "651:\tlearn: 0.2791700\ttotal: 28.8s\tremaining: 15.4s\n",
      "652:\tlearn: 0.2790914\ttotal: 28.9s\tremaining: 15.3s\n",
      "653:\tlearn: 0.2787753\ttotal: 28.9s\tremaining: 15.3s\n",
      "654:\tlearn: 0.2786329\ttotal: 28.9s\tremaining: 15.2s\n",
      "655:\tlearn: 0.2783034\ttotal: 28.9s\tremaining: 15.2s\n",
      "656:\tlearn: 0.2781922\ttotal: 28.9s\tremaining: 15.1s\n",
      "657:\tlearn: 0.2780446\ttotal: 29s\tremaining: 15.1s\n",
      "658:\tlearn: 0.2778932\ttotal: 29s\tremaining: 15s\n",
      "659:\tlearn: 0.2775834\ttotal: 29s\tremaining: 14.9s\n",
      "660:\tlearn: 0.2774257\ttotal: 29s\tremaining: 14.9s\n",
      "661:\tlearn: 0.2773111\ttotal: 29s\tremaining: 14.8s\n",
      "662:\tlearn: 0.2770770\ttotal: 29s\tremaining: 14.8s\n",
      "663:\tlearn: 0.2768362\ttotal: 29.1s\tremaining: 14.7s\n",
      "664:\tlearn: 0.2765824\ttotal: 29.1s\tremaining: 14.7s\n",
      "665:\tlearn: 0.2762561\ttotal: 29.1s\tremaining: 14.6s\n",
      "666:\tlearn: 0.2761099\ttotal: 29.2s\tremaining: 14.6s\n",
      "667:\tlearn: 0.2759442\ttotal: 29.2s\tremaining: 14.5s\n",
      "668:\tlearn: 0.2758492\ttotal: 29.2s\tremaining: 14.4s\n",
      "669:\tlearn: 0.2756931\ttotal: 29.2s\tremaining: 14.4s\n",
      "670:\tlearn: 0.2754777\ttotal: 29.2s\tremaining: 14.3s\n",
      "671:\tlearn: 0.2754074\ttotal: 29.3s\tremaining: 14.3s\n",
      "672:\tlearn: 0.2753271\ttotal: 29.3s\tremaining: 14.2s\n",
      "673:\tlearn: 0.2750798\ttotal: 29.3s\tremaining: 14.2s\n",
      "674:\tlearn: 0.2747610\ttotal: 29.3s\tremaining: 14.1s\n",
      "675:\tlearn: 0.2744736\ttotal: 29.4s\tremaining: 14.1s\n",
      "676:\tlearn: 0.2742214\ttotal: 29.4s\tremaining: 14s\n",
      "677:\tlearn: 0.2741336\ttotal: 29.4s\tremaining: 14s\n",
      "678:\tlearn: 0.2739038\ttotal: 29.4s\tremaining: 13.9s\n",
      "679:\tlearn: 0.2737681\ttotal: 29.4s\tremaining: 13.9s\n",
      "680:\tlearn: 0.2735615\ttotal: 29.5s\tremaining: 13.8s\n",
      "681:\tlearn: 0.2734363\ttotal: 29.5s\tremaining: 13.7s\n",
      "682:\tlearn: 0.2731716\ttotal: 29.5s\tremaining: 13.7s\n",
      "683:\tlearn: 0.2728910\ttotal: 29.5s\tremaining: 13.6s\n",
      "684:\tlearn: 0.2727164\ttotal: 29.5s\tremaining: 13.6s\n",
      "685:\tlearn: 0.2725457\ttotal: 29.5s\tremaining: 13.5s\n",
      "686:\tlearn: 0.2723625\ttotal: 29.6s\tremaining: 13.5s\n",
      "687:\tlearn: 0.2722066\ttotal: 29.6s\tremaining: 13.4s\n",
      "688:\tlearn: 0.2720952\ttotal: 29.6s\tremaining: 13.4s\n",
      "689:\tlearn: 0.2719267\ttotal: 29.6s\tremaining: 13.3s\n",
      "690:\tlearn: 0.2717524\ttotal: 29.6s\tremaining: 13.3s\n",
      "691:\tlearn: 0.2716103\ttotal: 29.7s\tremaining: 13.2s\n",
      "692:\tlearn: 0.2712848\ttotal: 29.7s\tremaining: 13.1s\n",
      "693:\tlearn: 0.2710588\ttotal: 29.7s\tremaining: 13.1s\n",
      "694:\tlearn: 0.2708202\ttotal: 29.7s\tremaining: 13s\n",
      "695:\tlearn: 0.2705998\ttotal: 29.7s\tremaining: 13s\n",
      "696:\tlearn: 0.2702590\ttotal: 29.7s\tremaining: 12.9s\n",
      "697:\tlearn: 0.2701797\ttotal: 29.8s\tremaining: 12.9s\n",
      "698:\tlearn: 0.2700971\ttotal: 29.8s\tremaining: 12.8s\n",
      "699:\tlearn: 0.2697215\ttotal: 29.8s\tremaining: 12.8s\n",
      "700:\tlearn: 0.2696393\ttotal: 29.8s\tremaining: 12.7s\n",
      "701:\tlearn: 0.2694592\ttotal: 29.8s\tremaining: 12.7s\n",
      "702:\tlearn: 0.2692992\ttotal: 29.8s\tremaining: 12.6s\n",
      "703:\tlearn: 0.2690945\ttotal: 29.9s\tremaining: 12.6s\n",
      "704:\tlearn: 0.2689013\ttotal: 29.9s\tremaining: 12.5s\n",
      "705:\tlearn: 0.2686633\ttotal: 29.9s\tremaining: 12.4s\n",
      "706:\tlearn: 0.2684201\ttotal: 29.9s\tremaining: 12.4s\n",
      "707:\tlearn: 0.2681521\ttotal: 29.9s\tremaining: 12.3s\n",
      "708:\tlearn: 0.2680193\ttotal: 29.9s\tremaining: 12.3s\n",
      "709:\tlearn: 0.2678495\ttotal: 30s\tremaining: 12.2s\n",
      "710:\tlearn: 0.2676728\ttotal: 30s\tremaining: 12.2s\n",
      "711:\tlearn: 0.2674293\ttotal: 30s\tremaining: 12.1s\n",
      "712:\tlearn: 0.2670250\ttotal: 30s\tremaining: 12.1s\n",
      "713:\tlearn: 0.2667714\ttotal: 30s\tremaining: 12s\n",
      "714:\tlearn: 0.2665376\ttotal: 30.1s\tremaining: 12s\n",
      "715:\tlearn: 0.2662652\ttotal: 30.1s\tremaining: 11.9s\n",
      "716:\tlearn: 0.2661361\ttotal: 30.1s\tremaining: 11.9s\n",
      "717:\tlearn: 0.2658107\ttotal: 30.1s\tremaining: 11.8s\n",
      "718:\tlearn: 0.2655571\ttotal: 30.1s\tremaining: 11.8s\n",
      "719:\tlearn: 0.2654657\ttotal: 30.1s\tremaining: 11.7s\n",
      "720:\tlearn: 0.2650543\ttotal: 30.2s\tremaining: 11.7s\n",
      "721:\tlearn: 0.2648529\ttotal: 30.2s\tremaining: 11.6s\n",
      "722:\tlearn: 0.2646196\ttotal: 30.2s\tremaining: 11.6s\n",
      "723:\tlearn: 0.2643691\ttotal: 30.2s\tremaining: 11.5s\n",
      "724:\tlearn: 0.2642522\ttotal: 30.2s\tremaining: 11.5s\n",
      "725:\tlearn: 0.2641212\ttotal: 30.2s\tremaining: 11.4s\n",
      "726:\tlearn: 0.2639827\ttotal: 30.3s\tremaining: 11.4s\n",
      "727:\tlearn: 0.2637905\ttotal: 30.3s\tremaining: 11.3s\n",
      "728:\tlearn: 0.2636137\ttotal: 30.3s\tremaining: 11.3s\n",
      "729:\tlearn: 0.2633743\ttotal: 30.3s\tremaining: 11.2s\n",
      "730:\tlearn: 0.2631913\ttotal: 30.4s\tremaining: 11.2s\n",
      "731:\tlearn: 0.2630769\ttotal: 30.4s\tremaining: 11.1s\n",
      "732:\tlearn: 0.2629012\ttotal: 30.4s\tremaining: 11.1s\n",
      "733:\tlearn: 0.2626277\ttotal: 30.4s\tremaining: 11s\n",
      "734:\tlearn: 0.2624521\ttotal: 30.4s\tremaining: 11s\n",
      "735:\tlearn: 0.2622095\ttotal: 30.5s\tremaining: 10.9s\n",
      "736:\tlearn: 0.2620583\ttotal: 30.5s\tremaining: 10.9s\n",
      "737:\tlearn: 0.2618432\ttotal: 30.5s\tremaining: 10.8s\n",
      "738:\tlearn: 0.2616192\ttotal: 30.5s\tremaining: 10.8s\n",
      "739:\tlearn: 0.2614747\ttotal: 30.5s\tremaining: 10.7s\n",
      "740:\tlearn: 0.2613270\ttotal: 30.6s\tremaining: 10.7s\n",
      "741:\tlearn: 0.2610026\ttotal: 30.6s\tremaining: 10.6s\n",
      "742:\tlearn: 0.2608463\ttotal: 30.6s\tremaining: 10.6s\n",
      "743:\tlearn: 0.2605527\ttotal: 30.6s\tremaining: 10.5s\n",
      "744:\tlearn: 0.2604363\ttotal: 30.6s\tremaining: 10.5s\n",
      "745:\tlearn: 0.2600579\ttotal: 30.6s\tremaining: 10.4s\n",
      "746:\tlearn: 0.2598653\ttotal: 30.7s\tremaining: 10.4s\n",
      "747:\tlearn: 0.2597714\ttotal: 30.7s\tremaining: 10.3s\n",
      "748:\tlearn: 0.2596759\ttotal: 30.7s\tremaining: 10.3s\n",
      "749:\tlearn: 0.2595346\ttotal: 30.7s\tremaining: 10.2s\n",
      "750:\tlearn: 0.2592232\ttotal: 30.7s\tremaining: 10.2s\n",
      "751:\tlearn: 0.2590199\ttotal: 30.7s\tremaining: 10.1s\n",
      "752:\tlearn: 0.2588625\ttotal: 30.8s\tremaining: 10.1s\n",
      "753:\tlearn: 0.2587736\ttotal: 30.8s\tremaining: 10s\n",
      "754:\tlearn: 0.2586731\ttotal: 30.8s\tremaining: 10s\n",
      "755:\tlearn: 0.2584778\ttotal: 30.8s\tremaining: 9.95s\n",
      "756:\tlearn: 0.2583104\ttotal: 30.8s\tremaining: 9.9s\n",
      "757:\tlearn: 0.2581537\ttotal: 30.9s\tremaining: 9.85s\n",
      "758:\tlearn: 0.2580929\ttotal: 30.9s\tremaining: 9.8s\n",
      "759:\tlearn: 0.2580270\ttotal: 30.9s\tremaining: 9.75s\n",
      "760:\tlearn: 0.2579171\ttotal: 30.9s\tremaining: 9.7s\n",
      "761:\tlearn: 0.2577318\ttotal: 30.9s\tremaining: 9.65s\n",
      "762:\tlearn: 0.2575850\ttotal: 30.9s\tremaining: 9.61s\n",
      "763:\tlearn: 0.2574051\ttotal: 30.9s\tremaining: 9.56s\n",
      "764:\tlearn: 0.2572214\ttotal: 31s\tremaining: 9.51s\n",
      "765:\tlearn: 0.2571207\ttotal: 31s\tremaining: 9.46s\n",
      "766:\tlearn: 0.2567506\ttotal: 31s\tremaining: 9.41s\n",
      "767:\tlearn: 0.2565362\ttotal: 31s\tremaining: 9.37s\n",
      "768:\tlearn: 0.2563897\ttotal: 31s\tremaining: 9.32s\n",
      "769:\tlearn: 0.2562947\ttotal: 31s\tremaining: 9.27s\n",
      "770:\tlearn: 0.2560894\ttotal: 31.1s\tremaining: 9.22s\n",
      "771:\tlearn: 0.2559184\ttotal: 31.1s\tremaining: 9.18s\n",
      "772:\tlearn: 0.2557450\ttotal: 31.1s\tremaining: 9.13s\n",
      "773:\tlearn: 0.2556297\ttotal: 31.1s\tremaining: 9.08s\n",
      "774:\tlearn: 0.2553302\ttotal: 31.1s\tremaining: 9.03s\n",
      "775:\tlearn: 0.2552115\ttotal: 31.1s\tremaining: 8.99s\n",
      "776:\tlearn: 0.2549845\ttotal: 31.1s\tremaining: 8.94s\n",
      "777:\tlearn: 0.2547520\ttotal: 31.2s\tremaining: 8.89s\n",
      "778:\tlearn: 0.2543785\ttotal: 31.2s\tremaining: 8.85s\n",
      "779:\tlearn: 0.2541891\ttotal: 31.2s\tremaining: 8.8s\n",
      "780:\tlearn: 0.2539533\ttotal: 31.2s\tremaining: 8.75s\n",
      "781:\tlearn: 0.2537536\ttotal: 31.2s\tremaining: 8.7s\n",
      "782:\tlearn: 0.2536544\ttotal: 31.2s\tremaining: 8.66s\n",
      "783:\tlearn: 0.2535236\ttotal: 31.3s\tremaining: 8.61s\n",
      "784:\tlearn: 0.2531523\ttotal: 31.3s\tremaining: 8.57s\n",
      "785:\tlearn: 0.2527925\ttotal: 31.4s\tremaining: 8.54s\n",
      "786:\tlearn: 0.2526748\ttotal: 31.4s\tremaining: 8.49s\n",
      "787:\tlearn: 0.2523120\ttotal: 31.4s\tremaining: 8.45s\n",
      "788:\tlearn: 0.2522090\ttotal: 31.4s\tremaining: 8.4s\n",
      "789:\tlearn: 0.2519880\ttotal: 31.5s\tremaining: 8.36s\n",
      "790:\tlearn: 0.2519056\ttotal: 31.5s\tremaining: 8.32s\n",
      "791:\tlearn: 0.2517603\ttotal: 31.5s\tremaining: 8.27s\n",
      "792:\tlearn: 0.2516474\ttotal: 31.5s\tremaining: 8.23s\n",
      "793:\tlearn: 0.2514196\ttotal: 31.5s\tremaining: 8.18s\n",
      "794:\tlearn: 0.2512655\ttotal: 31.6s\tremaining: 8.14s\n",
      "795:\tlearn: 0.2510095\ttotal: 31.6s\tremaining: 8.09s\n",
      "796:\tlearn: 0.2509547\ttotal: 31.6s\tremaining: 8.05s\n",
      "797:\tlearn: 0.2508152\ttotal: 31.6s\tremaining: 8s\n",
      "798:\tlearn: 0.2506007\ttotal: 31.6s\tremaining: 7.96s\n",
      "799:\tlearn: 0.2503861\ttotal: 31.6s\tremaining: 7.91s\n",
      "800:\tlearn: 0.2502313\ttotal: 31.7s\tremaining: 7.87s\n",
      "801:\tlearn: 0.2500861\ttotal: 31.7s\tremaining: 7.82s\n",
      "802:\tlearn: 0.2499726\ttotal: 31.7s\tremaining: 7.78s\n",
      "803:\tlearn: 0.2499027\ttotal: 31.7s\tremaining: 7.73s\n",
      "804:\tlearn: 0.2497066\ttotal: 31.7s\tremaining: 7.69s\n",
      "805:\tlearn: 0.2494339\ttotal: 31.7s\tremaining: 7.64s\n",
      "806:\tlearn: 0.2493114\ttotal: 31.8s\tremaining: 7.6s\n",
      "807:\tlearn: 0.2492620\ttotal: 31.8s\tremaining: 7.55s\n",
      "808:\tlearn: 0.2491562\ttotal: 31.8s\tremaining: 7.51s\n",
      "809:\tlearn: 0.2489351\ttotal: 31.8s\tremaining: 7.46s\n",
      "810:\tlearn: 0.2487351\ttotal: 31.8s\tremaining: 7.42s\n",
      "811:\tlearn: 0.2485608\ttotal: 31.8s\tremaining: 7.37s\n",
      "812:\tlearn: 0.2483874\ttotal: 31.9s\tremaining: 7.33s\n",
      "813:\tlearn: 0.2483380\ttotal: 31.9s\tremaining: 7.28s\n",
      "814:\tlearn: 0.2481961\ttotal: 31.9s\tremaining: 7.24s\n",
      "815:\tlearn: 0.2480568\ttotal: 31.9s\tremaining: 7.19s\n",
      "816:\tlearn: 0.2479240\ttotal: 31.9s\tremaining: 7.15s\n",
      "817:\tlearn: 0.2475780\ttotal: 31.9s\tremaining: 7.11s\n",
      "818:\tlearn: 0.2473559\ttotal: 31.9s\tremaining: 7.06s\n",
      "819:\tlearn: 0.2470810\ttotal: 32s\tremaining: 7.02s\n",
      "820:\tlearn: 0.2468539\ttotal: 32s\tremaining: 6.97s\n",
      "821:\tlearn: 0.2467201\ttotal: 32s\tremaining: 6.93s\n",
      "822:\tlearn: 0.2465781\ttotal: 32s\tremaining: 6.89s\n",
      "823:\tlearn: 0.2462871\ttotal: 32s\tremaining: 6.84s\n",
      "824:\tlearn: 0.2460507\ttotal: 32.1s\tremaining: 6.8s\n",
      "825:\tlearn: 0.2458699\ttotal: 32.1s\tremaining: 6.75s\n",
      "826:\tlearn: 0.2456004\ttotal: 32.1s\tremaining: 6.71s\n",
      "827:\tlearn: 0.2455383\ttotal: 32.1s\tremaining: 6.67s\n",
      "828:\tlearn: 0.2454159\ttotal: 32.1s\tremaining: 6.62s\n",
      "829:\tlearn: 0.2453461\ttotal: 32.1s\tremaining: 6.58s\n",
      "830:\tlearn: 0.2452303\ttotal: 32.1s\tremaining: 6.54s\n",
      "831:\tlearn: 0.2449450\ttotal: 32.2s\tremaining: 6.49s\n",
      "832:\tlearn: 0.2447825\ttotal: 32.2s\tremaining: 6.45s\n",
      "833:\tlearn: 0.2445435\ttotal: 32.2s\tremaining: 6.41s\n",
      "834:\tlearn: 0.2444766\ttotal: 32.2s\tremaining: 6.36s\n",
      "835:\tlearn: 0.2443637\ttotal: 32.2s\tremaining: 6.32s\n",
      "836:\tlearn: 0.2442310\ttotal: 32.2s\tremaining: 6.28s\n",
      "837:\tlearn: 0.2441277\ttotal: 32.3s\tremaining: 6.23s\n",
      "838:\tlearn: 0.2439788\ttotal: 32.3s\tremaining: 6.19s\n",
      "839:\tlearn: 0.2436708\ttotal: 32.3s\tremaining: 6.15s\n",
      "840:\tlearn: 0.2435571\ttotal: 32.3s\tremaining: 6.11s\n",
      "841:\tlearn: 0.2432938\ttotal: 32.3s\tremaining: 6.07s\n",
      "842:\tlearn: 0.2431737\ttotal: 32.3s\tremaining: 6.02s\n",
      "843:\tlearn: 0.2430003\ttotal: 32.4s\tremaining: 5.98s\n",
      "844:\tlearn: 0.2428131\ttotal: 32.4s\tremaining: 5.94s\n",
      "845:\tlearn: 0.2426747\ttotal: 32.4s\tremaining: 5.89s\n",
      "846:\tlearn: 0.2426119\ttotal: 32.4s\tremaining: 5.85s\n",
      "847:\tlearn: 0.2425361\ttotal: 32.4s\tremaining: 5.81s\n",
      "848:\tlearn: 0.2424063\ttotal: 32.4s\tremaining: 5.77s\n",
      "849:\tlearn: 0.2421985\ttotal: 32.4s\tremaining: 5.72s\n",
      "850:\tlearn: 0.2420448\ttotal: 32.5s\tremaining: 5.68s\n",
      "851:\tlearn: 0.2417995\ttotal: 32.5s\tremaining: 5.65s\n",
      "852:\tlearn: 0.2416755\ttotal: 32.5s\tremaining: 5.61s\n",
      "853:\tlearn: 0.2414902\ttotal: 32.6s\tremaining: 5.57s\n",
      "854:\tlearn: 0.2412605\ttotal: 32.6s\tremaining: 5.52s\n",
      "855:\tlearn: 0.2410947\ttotal: 32.6s\tremaining: 5.48s\n",
      "856:\tlearn: 0.2409351\ttotal: 32.6s\tremaining: 5.44s\n",
      "857:\tlearn: 0.2406478\ttotal: 32.6s\tremaining: 5.4s\n",
      "858:\tlearn: 0.2404310\ttotal: 32.6s\tremaining: 5.36s\n",
      "859:\tlearn: 0.2403568\ttotal: 32.7s\tremaining: 5.32s\n",
      "860:\tlearn: 0.2402016\ttotal: 32.7s\tremaining: 5.28s\n",
      "861:\tlearn: 0.2399793\ttotal: 32.7s\tremaining: 5.23s\n",
      "862:\tlearn: 0.2395915\ttotal: 32.7s\tremaining: 5.19s\n",
      "863:\tlearn: 0.2394106\ttotal: 32.7s\tremaining: 5.15s\n",
      "864:\tlearn: 0.2392275\ttotal: 32.8s\tremaining: 5.11s\n",
      "865:\tlearn: 0.2390827\ttotal: 32.8s\tremaining: 5.07s\n",
      "866:\tlearn: 0.2389909\ttotal: 32.8s\tremaining: 5.03s\n",
      "867:\tlearn: 0.2388708\ttotal: 32.8s\tremaining: 4.99s\n",
      "868:\tlearn: 0.2387301\ttotal: 32.8s\tremaining: 4.95s\n",
      "869:\tlearn: 0.2384782\ttotal: 32.9s\tremaining: 4.91s\n",
      "870:\tlearn: 0.2383926\ttotal: 32.9s\tremaining: 4.87s\n",
      "871:\tlearn: 0.2382111\ttotal: 32.9s\tremaining: 4.83s\n",
      "872:\tlearn: 0.2380858\ttotal: 32.9s\tremaining: 4.79s\n",
      "873:\tlearn: 0.2379404\ttotal: 32.9s\tremaining: 4.75s\n",
      "874:\tlearn: 0.2378372\ttotal: 33s\tremaining: 4.71s\n",
      "875:\tlearn: 0.2376976\ttotal: 33s\tremaining: 4.67s\n",
      "876:\tlearn: 0.2373909\ttotal: 33s\tremaining: 4.63s\n",
      "877:\tlearn: 0.2370084\ttotal: 33s\tremaining: 4.59s\n",
      "878:\tlearn: 0.2368821\ttotal: 33s\tremaining: 4.55s\n",
      "879:\tlearn: 0.2365730\ttotal: 33.1s\tremaining: 4.51s\n",
      "880:\tlearn: 0.2364416\ttotal: 33.1s\tremaining: 4.47s\n",
      "881:\tlearn: 0.2363211\ttotal: 33.1s\tremaining: 4.43s\n",
      "882:\tlearn: 0.2361655\ttotal: 33.1s\tremaining: 4.39s\n",
      "883:\tlearn: 0.2358810\ttotal: 33.1s\tremaining: 4.34s\n",
      "884:\tlearn: 0.2356813\ttotal: 33.1s\tremaining: 4.31s\n",
      "885:\tlearn: 0.2355463\ttotal: 33.2s\tremaining: 4.27s\n",
      "886:\tlearn: 0.2352750\ttotal: 33.2s\tremaining: 4.23s\n",
      "887:\tlearn: 0.2350016\ttotal: 33.2s\tremaining: 4.19s\n",
      "888:\tlearn: 0.2349126\ttotal: 33.2s\tremaining: 4.15s\n",
      "889:\tlearn: 0.2347396\ttotal: 33.3s\tremaining: 4.11s\n",
      "890:\tlearn: 0.2346430\ttotal: 33.3s\tremaining: 4.07s\n",
      "891:\tlearn: 0.2345641\ttotal: 33.3s\tremaining: 4.03s\n",
      "892:\tlearn: 0.2344405\ttotal: 33.3s\tremaining: 3.99s\n",
      "893:\tlearn: 0.2343665\ttotal: 33.3s\tremaining: 3.95s\n",
      "894:\tlearn: 0.2342418\ttotal: 33.4s\tremaining: 3.91s\n",
      "895:\tlearn: 0.2339786\ttotal: 33.4s\tremaining: 3.87s\n",
      "896:\tlearn: 0.2338579\ttotal: 33.4s\tremaining: 3.83s\n",
      "897:\tlearn: 0.2336968\ttotal: 33.4s\tremaining: 3.8s\n",
      "898:\tlearn: 0.2334545\ttotal: 33.4s\tremaining: 3.76s\n",
      "899:\tlearn: 0.2332009\ttotal: 33.5s\tremaining: 3.72s\n",
      "900:\tlearn: 0.2328996\ttotal: 33.5s\tremaining: 3.68s\n",
      "901:\tlearn: 0.2326368\ttotal: 33.5s\tremaining: 3.64s\n",
      "902:\tlearn: 0.2323394\ttotal: 33.6s\tremaining: 3.6s\n",
      "903:\tlearn: 0.2321423\ttotal: 33.6s\tremaining: 3.57s\n",
      "904:\tlearn: 0.2319901\ttotal: 33.6s\tremaining: 3.53s\n",
      "905:\tlearn: 0.2318138\ttotal: 33.6s\tremaining: 3.49s\n",
      "906:\tlearn: 0.2316506\ttotal: 33.6s\tremaining: 3.45s\n",
      "907:\tlearn: 0.2315167\ttotal: 33.7s\tremaining: 3.41s\n",
      "908:\tlearn: 0.2313868\ttotal: 33.7s\tremaining: 3.37s\n",
      "909:\tlearn: 0.2312708\ttotal: 33.7s\tremaining: 3.33s\n",
      "910:\tlearn: 0.2310972\ttotal: 33.7s\tremaining: 3.29s\n",
      "911:\tlearn: 0.2309322\ttotal: 33.7s\tremaining: 3.25s\n",
      "912:\tlearn: 0.2308111\ttotal: 33.8s\tremaining: 3.22s\n",
      "913:\tlearn: 0.2306475\ttotal: 33.8s\tremaining: 3.18s\n",
      "914:\tlearn: 0.2305324\ttotal: 33.8s\tremaining: 3.14s\n",
      "915:\tlearn: 0.2303142\ttotal: 33.8s\tremaining: 3.1s\n",
      "916:\tlearn: 0.2301427\ttotal: 33.8s\tremaining: 3.06s\n",
      "917:\tlearn: 0.2300465\ttotal: 33.8s\tremaining: 3.02s\n",
      "918:\tlearn: 0.2297499\ttotal: 33.9s\tremaining: 2.98s\n",
      "919:\tlearn: 0.2296399\ttotal: 33.9s\tremaining: 2.94s\n",
      "920:\tlearn: 0.2295325\ttotal: 33.9s\tremaining: 2.91s\n",
      "921:\tlearn: 0.2294095\ttotal: 33.9s\tremaining: 2.87s\n",
      "922:\tlearn: 0.2291424\ttotal: 33.9s\tremaining: 2.83s\n",
      "923:\tlearn: 0.2290093\ttotal: 33.9s\tremaining: 2.79s\n",
      "924:\tlearn: 0.2287712\ttotal: 33.9s\tremaining: 2.75s\n",
      "925:\tlearn: 0.2286323\ttotal: 34s\tremaining: 2.71s\n",
      "926:\tlearn: 0.2284531\ttotal: 34s\tremaining: 2.68s\n",
      "927:\tlearn: 0.2281506\ttotal: 34s\tremaining: 2.64s\n",
      "928:\tlearn: 0.2279185\ttotal: 34s\tremaining: 2.6s\n",
      "929:\tlearn: 0.2278346\ttotal: 34s\tremaining: 2.56s\n",
      "930:\tlearn: 0.2276264\ttotal: 34s\tremaining: 2.52s\n",
      "931:\tlearn: 0.2273373\ttotal: 34.1s\tremaining: 2.48s\n",
      "932:\tlearn: 0.2271860\ttotal: 34.1s\tremaining: 2.45s\n",
      "933:\tlearn: 0.2270445\ttotal: 34.1s\tremaining: 2.41s\n",
      "934:\tlearn: 0.2268000\ttotal: 34.1s\tremaining: 2.37s\n",
      "935:\tlearn: 0.2266667\ttotal: 34.1s\tremaining: 2.33s\n",
      "936:\tlearn: 0.2265073\ttotal: 34.1s\tremaining: 2.29s\n",
      "937:\tlearn: 0.2263402\ttotal: 34.2s\tremaining: 2.26s\n",
      "938:\tlearn: 0.2261178\ttotal: 34.2s\tremaining: 2.22s\n",
      "939:\tlearn: 0.2260684\ttotal: 34.2s\tremaining: 2.18s\n",
      "940:\tlearn: 0.2259799\ttotal: 34.2s\tremaining: 2.14s\n",
      "941:\tlearn: 0.2258859\ttotal: 34.2s\tremaining: 2.11s\n",
      "942:\tlearn: 0.2256924\ttotal: 34.2s\tremaining: 2.07s\n",
      "943:\tlearn: 0.2255620\ttotal: 34.3s\tremaining: 2.03s\n",
      "944:\tlearn: 0.2251847\ttotal: 34.3s\tremaining: 1.99s\n",
      "945:\tlearn: 0.2249647\ttotal: 34.3s\tremaining: 1.96s\n",
      "946:\tlearn: 0.2248874\ttotal: 34.3s\tremaining: 1.92s\n",
      "947:\tlearn: 0.2246947\ttotal: 34.3s\tremaining: 1.88s\n",
      "948:\tlearn: 0.2245937\ttotal: 34.3s\tremaining: 1.84s\n",
      "949:\tlearn: 0.2244031\ttotal: 34.3s\tremaining: 1.81s\n",
      "950:\tlearn: 0.2241664\ttotal: 34.4s\tremaining: 1.77s\n",
      "951:\tlearn: 0.2239857\ttotal: 34.4s\tremaining: 1.73s\n",
      "952:\tlearn: 0.2238649\ttotal: 34.4s\tremaining: 1.7s\n",
      "953:\tlearn: 0.2237411\ttotal: 34.4s\tremaining: 1.66s\n",
      "954:\tlearn: 0.2235622\ttotal: 34.4s\tremaining: 1.62s\n",
      "955:\tlearn: 0.2234014\ttotal: 34.4s\tremaining: 1.58s\n",
      "956:\tlearn: 0.2231438\ttotal: 34.5s\tremaining: 1.55s\n",
      "957:\tlearn: 0.2229109\ttotal: 34.5s\tremaining: 1.51s\n",
      "958:\tlearn: 0.2227651\ttotal: 34.5s\tremaining: 1.47s\n",
      "959:\tlearn: 0.2225197\ttotal: 34.5s\tremaining: 1.44s\n",
      "960:\tlearn: 0.2224326\ttotal: 34.6s\tremaining: 1.41s\n",
      "961:\tlearn: 0.2222700\ttotal: 34.7s\tremaining: 1.37s\n",
      "962:\tlearn: 0.2221999\ttotal: 34.7s\tremaining: 1.33s\n",
      "963:\tlearn: 0.2221142\ttotal: 34.7s\tremaining: 1.29s\n",
      "964:\tlearn: 0.2220397\ttotal: 34.7s\tremaining: 1.26s\n",
      "965:\tlearn: 0.2219219\ttotal: 34.7s\tremaining: 1.22s\n",
      "966:\tlearn: 0.2217058\ttotal: 34.7s\tremaining: 1.19s\n",
      "967:\tlearn: 0.2215207\ttotal: 34.8s\tremaining: 1.15s\n",
      "968:\tlearn: 0.2212124\ttotal: 34.8s\tremaining: 1.11s\n",
      "969:\tlearn: 0.2211238\ttotal: 34.8s\tremaining: 1.08s\n",
      "970:\tlearn: 0.2208764\ttotal: 34.9s\tremaining: 1.04s\n",
      "971:\tlearn: 0.2207878\ttotal: 34.9s\tremaining: 1s\n",
      "972:\tlearn: 0.2205169\ttotal: 35s\tremaining: 970ms\n",
      "973:\tlearn: 0.2204032\ttotal: 35s\tremaining: 934ms\n",
      "974:\tlearn: 0.2202207\ttotal: 35s\tremaining: 898ms\n",
      "975:\tlearn: 0.2200022\ttotal: 35.1s\tremaining: 862ms\n",
      "976:\tlearn: 0.2198533\ttotal: 35.1s\tremaining: 826ms\n",
      "977:\tlearn: 0.2197650\ttotal: 35.1s\tremaining: 790ms\n",
      "978:\tlearn: 0.2197035\ttotal: 35.1s\tremaining: 753ms\n",
      "979:\tlearn: 0.2194225\ttotal: 35.1s\tremaining: 717ms\n",
      "980:\tlearn: 0.2192644\ttotal: 35.2s\tremaining: 681ms\n",
      "981:\tlearn: 0.2190590\ttotal: 35.2s\tremaining: 645ms\n",
      "982:\tlearn: 0.2187049\ttotal: 35.2s\tremaining: 610ms\n",
      "983:\tlearn: 0.2184554\ttotal: 35.3s\tremaining: 574ms\n",
      "984:\tlearn: 0.2183009\ttotal: 35.3s\tremaining: 538ms\n",
      "985:\tlearn: 0.2182175\ttotal: 35.4s\tremaining: 502ms\n",
      "986:\tlearn: 0.2180159\ttotal: 35.4s\tremaining: 467ms\n",
      "987:\tlearn: 0.2178155\ttotal: 35.5s\tremaining: 431ms\n",
      "988:\tlearn: 0.2177497\ttotal: 35.5s\tremaining: 394ms\n",
      "989:\tlearn: 0.2176913\ttotal: 35.5s\tremaining: 358ms\n",
      "990:\tlearn: 0.2175883\ttotal: 35.5s\tremaining: 322ms\n",
      "991:\tlearn: 0.2174602\ttotal: 35.5s\tremaining: 286ms\n",
      "992:\tlearn: 0.2171947\ttotal: 35.5s\tremaining: 251ms\n",
      "993:\tlearn: 0.2170506\ttotal: 35.6s\tremaining: 215ms\n",
      "994:\tlearn: 0.2168182\ttotal: 35.6s\tremaining: 179ms\n",
      "995:\tlearn: 0.2165643\ttotal: 35.6s\tremaining: 143ms\n",
      "996:\tlearn: 0.2163811\ttotal: 35.6s\tremaining: 107ms\n",
      "997:\tlearn: 0.2162038\ttotal: 35.6s\tremaining: 71.4ms\n",
      "998:\tlearn: 0.2161056\ttotal: 35.7s\tremaining: 35.7ms\n",
      "999:\tlearn: 0.2158197\ttotal: 35.7s\tremaining: 0us\n",
      "Accuracy, fold_3: 0.7804878048780488\n",
      "Learning rate set to 0.007604\n",
      "0:\tlearn: 0.6893343\ttotal: 15.2ms\tremaining: 15.2s\n",
      "1:\tlearn: 0.6852174\ttotal: 29.2ms\tremaining: 14.6s\n",
      "2:\tlearn: 0.6812487\ttotal: 44.2ms\tremaining: 14.7s\n",
      "3:\tlearn: 0.6775548\ttotal: 58ms\tremaining: 14.4s\n",
      "4:\tlearn: 0.6739144\ttotal: 72.7ms\tremaining: 14.5s\n",
      "5:\tlearn: 0.6701082\ttotal: 99.5ms\tremaining: 16.5s\n",
      "6:\tlearn: 0.6664888\ttotal: 115ms\tremaining: 16.3s\n",
      "7:\tlearn: 0.6628685\ttotal: 132ms\tremaining: 16.3s\n",
      "8:\tlearn: 0.6595791\ttotal: 147ms\tremaining: 16.1s\n",
      "9:\tlearn: 0.6564759\ttotal: 164ms\tremaining: 16.2s\n",
      "10:\tlearn: 0.6529488\ttotal: 178ms\tremaining: 16s\n",
      "11:\tlearn: 0.6496095\ttotal: 192ms\tremaining: 15.8s\n",
      "12:\tlearn: 0.6462343\ttotal: 207ms\tremaining: 15.7s\n",
      "13:\tlearn: 0.6430223\ttotal: 221ms\tremaining: 15.6s\n",
      "14:\tlearn: 0.6402781\ttotal: 236ms\tremaining: 15.5s\n",
      "15:\tlearn: 0.6373380\ttotal: 250ms\tremaining: 15.3s\n",
      "16:\tlearn: 0.6344952\ttotal: 264ms\tremaining: 15.3s\n",
      "17:\tlearn: 0.6312854\ttotal: 278ms\tremaining: 15.1s\n",
      "18:\tlearn: 0.6283073\ttotal: 292ms\tremaining: 15.1s\n",
      "19:\tlearn: 0.6257241\ttotal: 307ms\tremaining: 15.1s\n",
      "20:\tlearn: 0.6227547\ttotal: 333ms\tremaining: 15.5s\n",
      "21:\tlearn: 0.6197758\ttotal: 349ms\tremaining: 15.5s\n",
      "22:\tlearn: 0.6170256\ttotal: 365ms\tremaining: 15.5s\n",
      "23:\tlearn: 0.6142046\ttotal: 380ms\tremaining: 15.5s\n",
      "24:\tlearn: 0.6110631\ttotal: 397ms\tremaining: 15.5s\n",
      "25:\tlearn: 0.6084577\ttotal: 411ms\tremaining: 15.4s\n",
      "26:\tlearn: 0.6059701\ttotal: 426ms\tremaining: 15.4s\n",
      "27:\tlearn: 0.6032686\ttotal: 443ms\tremaining: 15.4s\n",
      "28:\tlearn: 0.6006528\ttotal: 459ms\tremaining: 15.4s\n",
      "29:\tlearn: 0.5983285\ttotal: 473ms\tremaining: 15.3s\n",
      "30:\tlearn: 0.5958663\ttotal: 489ms\tremaining: 15.3s\n",
      "31:\tlearn: 0.5931015\ttotal: 506ms\tremaining: 15.3s\n",
      "32:\tlearn: 0.5905764\ttotal: 521ms\tremaining: 15.3s\n",
      "33:\tlearn: 0.5887498\ttotal: 524ms\tremaining: 14.9s\n",
      "34:\tlearn: 0.5859243\ttotal: 544ms\tremaining: 15s\n",
      "35:\tlearn: 0.5835780\ttotal: 571ms\tremaining: 15.3s\n",
      "36:\tlearn: 0.5810919\ttotal: 586ms\tremaining: 15.2s\n",
      "37:\tlearn: 0.5789412\ttotal: 600ms\tremaining: 15.2s\n",
      "38:\tlearn: 0.5768438\ttotal: 615ms\tremaining: 15.2s\n",
      "39:\tlearn: 0.5746802\ttotal: 632ms\tremaining: 15.2s\n",
      "40:\tlearn: 0.5725030\ttotal: 647ms\tremaining: 15.1s\n",
      "41:\tlearn: 0.5699599\ttotal: 662ms\tremaining: 15.1s\n",
      "42:\tlearn: 0.5678057\ttotal: 689ms\tremaining: 15.3s\n",
      "43:\tlearn: 0.5656925\ttotal: 737ms\tremaining: 16s\n",
      "44:\tlearn: 0.5638407\ttotal: 759ms\tremaining: 16.1s\n",
      "45:\tlearn: 0.5618688\ttotal: 779ms\tremaining: 16.2s\n",
      "46:\tlearn: 0.5596715\ttotal: 808ms\tremaining: 16.4s\n",
      "47:\tlearn: 0.5578424\ttotal: 826ms\tremaining: 16.4s\n",
      "48:\tlearn: 0.5555760\ttotal: 846ms\tremaining: 16.4s\n",
      "49:\tlearn: 0.5535954\ttotal: 864ms\tremaining: 16.4s\n",
      "50:\tlearn: 0.5519091\ttotal: 885ms\tremaining: 16.5s\n",
      "51:\tlearn: 0.5499924\ttotal: 905ms\tremaining: 16.5s\n",
      "52:\tlearn: 0.5482692\ttotal: 924ms\tremaining: 16.5s\n",
      "53:\tlearn: 0.5464647\ttotal: 940ms\tremaining: 16.5s\n",
      "54:\tlearn: 0.5447804\ttotal: 955ms\tremaining: 16.4s\n",
      "55:\tlearn: 0.5428345\ttotal: 970ms\tremaining: 16.4s\n",
      "56:\tlearn: 0.5412872\ttotal: 985ms\tremaining: 16.3s\n",
      "57:\tlearn: 0.5398333\ttotal: 1s\tremaining: 16.3s\n",
      "58:\tlearn: 0.5379756\ttotal: 1.01s\tremaining: 16.2s\n",
      "59:\tlearn: 0.5362110\ttotal: 1.03s\tremaining: 16.1s\n",
      "60:\tlearn: 0.5342476\ttotal: 1.05s\tremaining: 16.2s\n",
      "61:\tlearn: 0.5325122\ttotal: 1.08s\tremaining: 16.3s\n",
      "62:\tlearn: 0.5309353\ttotal: 1.09s\tremaining: 16.2s\n",
      "63:\tlearn: 0.5290034\ttotal: 1.1s\tremaining: 16.2s\n",
      "64:\tlearn: 0.5272639\ttotal: 1.12s\tremaining: 16.1s\n",
      "65:\tlearn: 0.5254750\ttotal: 1.13s\tremaining: 16.1s\n",
      "66:\tlearn: 0.5238349\ttotal: 1.15s\tremaining: 16s\n",
      "67:\tlearn: 0.5216534\ttotal: 1.17s\tremaining: 16s\n",
      "68:\tlearn: 0.5201005\ttotal: 1.18s\tremaining: 15.9s\n",
      "69:\tlearn: 0.5184959\ttotal: 1.2s\tremaining: 15.9s\n",
      "70:\tlearn: 0.5171717\ttotal: 1.22s\tremaining: 15.9s\n",
      "71:\tlearn: 0.5157117\ttotal: 1.23s\tremaining: 15.9s\n",
      "72:\tlearn: 0.5143082\ttotal: 1.25s\tremaining: 15.8s\n",
      "73:\tlearn: 0.5129333\ttotal: 1.26s\tremaining: 15.8s\n",
      "74:\tlearn: 0.5114439\ttotal: 1.28s\tremaining: 15.8s\n",
      "75:\tlearn: 0.5106428\ttotal: 1.31s\tremaining: 15.9s\n",
      "76:\tlearn: 0.5094231\ttotal: 1.32s\tremaining: 15.8s\n",
      "77:\tlearn: 0.5079405\ttotal: 1.33s\tremaining: 15.8s\n",
      "78:\tlearn: 0.5061552\ttotal: 1.35s\tremaining: 15.7s\n",
      "79:\tlearn: 0.5048455\ttotal: 1.37s\tremaining: 15.7s\n",
      "80:\tlearn: 0.5035355\ttotal: 1.38s\tremaining: 15.7s\n",
      "81:\tlearn: 0.5022935\ttotal: 1.4s\tremaining: 15.7s\n",
      "82:\tlearn: 0.5008308\ttotal: 1.42s\tremaining: 15.6s\n",
      "83:\tlearn: 0.4995025\ttotal: 1.43s\tremaining: 15.6s\n",
      "84:\tlearn: 0.4987031\ttotal: 1.45s\tremaining: 15.6s\n",
      "85:\tlearn: 0.4977476\ttotal: 1.46s\tremaining: 15.5s\n",
      "86:\tlearn: 0.4960887\ttotal: 1.47s\tremaining: 15.5s\n",
      "87:\tlearn: 0.4947503\ttotal: 1.49s\tremaining: 15.4s\n",
      "88:\tlearn: 0.4934270\ttotal: 1.5s\tremaining: 15.4s\n",
      "89:\tlearn: 0.4922257\ttotal: 1.52s\tremaining: 15.4s\n",
      "90:\tlearn: 0.4908947\ttotal: 1.53s\tremaining: 15.3s\n",
      "91:\tlearn: 0.4897617\ttotal: 1.57s\tremaining: 15.5s\n",
      "92:\tlearn: 0.4885486\ttotal: 1.58s\tremaining: 15.4s\n",
      "93:\tlearn: 0.4875040\ttotal: 1.6s\tremaining: 15.4s\n",
      "94:\tlearn: 0.4866799\ttotal: 1.61s\tremaining: 15.4s\n",
      "95:\tlearn: 0.4853820\ttotal: 1.63s\tremaining: 15.4s\n",
      "96:\tlearn: 0.4840145\ttotal: 1.65s\tremaining: 15.3s\n",
      "97:\tlearn: 0.4830439\ttotal: 1.66s\tremaining: 15.3s\n",
      "98:\tlearn: 0.4820305\ttotal: 1.67s\tremaining: 15.2s\n",
      "99:\tlearn: 0.4806944\ttotal: 1.69s\tremaining: 15.2s\n",
      "100:\tlearn: 0.4797560\ttotal: 1.7s\tremaining: 15.2s\n",
      "101:\tlearn: 0.4787179\ttotal: 1.72s\tremaining: 15.1s\n",
      "102:\tlearn: 0.4776784\ttotal: 1.73s\tremaining: 15.1s\n",
      "103:\tlearn: 0.4769532\ttotal: 1.75s\tremaining: 15.1s\n",
      "104:\tlearn: 0.4759556\ttotal: 1.8s\tremaining: 15.3s\n",
      "105:\tlearn: 0.4751665\ttotal: 1.82s\tremaining: 15.3s\n",
      "106:\tlearn: 0.4741771\ttotal: 1.83s\tremaining: 15.3s\n",
      "107:\tlearn: 0.4734102\ttotal: 1.85s\tremaining: 15.3s\n",
      "108:\tlearn: 0.4725383\ttotal: 1.86s\tremaining: 15.3s\n",
      "109:\tlearn: 0.4717052\ttotal: 1.88s\tremaining: 15.2s\n",
      "110:\tlearn: 0.4707556\ttotal: 1.9s\tremaining: 15.2s\n",
      "111:\tlearn: 0.4697398\ttotal: 1.91s\tremaining: 15.2s\n",
      "112:\tlearn: 0.4690594\ttotal: 1.93s\tremaining: 15.1s\n",
      "113:\tlearn: 0.4683087\ttotal: 1.94s\tremaining: 15.1s\n",
      "114:\tlearn: 0.4678781\ttotal: 1.95s\tremaining: 15s\n",
      "115:\tlearn: 0.4671062\ttotal: 1.97s\tremaining: 15s\n",
      "116:\tlearn: 0.4661757\ttotal: 1.99s\tremaining: 15s\n",
      "117:\tlearn: 0.4655604\ttotal: 2s\tremaining: 14.9s\n",
      "118:\tlearn: 0.4650507\ttotal: 2.02s\tremaining: 14.9s\n",
      "119:\tlearn: 0.4643832\ttotal: 2.08s\tremaining: 15.2s\n",
      "120:\tlearn: 0.4635944\ttotal: 2.12s\tremaining: 15.4s\n",
      "121:\tlearn: 0.4625188\ttotal: 2.15s\tremaining: 15.4s\n",
      "122:\tlearn: 0.4616633\ttotal: 2.16s\tremaining: 15.4s\n",
      "123:\tlearn: 0.4611576\ttotal: 2.17s\tremaining: 15.4s\n",
      "124:\tlearn: 0.4602119\ttotal: 2.19s\tremaining: 15.3s\n",
      "125:\tlearn: 0.4594992\ttotal: 2.21s\tremaining: 15.3s\n",
      "126:\tlearn: 0.4586939\ttotal: 2.22s\tremaining: 15.3s\n",
      "127:\tlearn: 0.4579751\ttotal: 2.24s\tremaining: 15.3s\n",
      "128:\tlearn: 0.4575511\ttotal: 2.25s\tremaining: 15.2s\n",
      "129:\tlearn: 0.4565818\ttotal: 2.27s\tremaining: 15.2s\n",
      "130:\tlearn: 0.4557604\ttotal: 2.3s\tremaining: 15.2s\n",
      "131:\tlearn: 0.4549397\ttotal: 2.31s\tremaining: 15.2s\n",
      "132:\tlearn: 0.4540954\ttotal: 2.33s\tremaining: 15.2s\n",
      "133:\tlearn: 0.4531918\ttotal: 2.34s\tremaining: 15.1s\n",
      "134:\tlearn: 0.4524210\ttotal: 2.35s\tremaining: 15.1s\n",
      "135:\tlearn: 0.4516616\ttotal: 2.37s\tremaining: 15.1s\n",
      "136:\tlearn: 0.4506598\ttotal: 2.39s\tremaining: 15s\n",
      "137:\tlearn: 0.4502081\ttotal: 2.4s\tremaining: 15s\n",
      "138:\tlearn: 0.4494096\ttotal: 2.42s\tremaining: 15s\n",
      "139:\tlearn: 0.4488244\ttotal: 2.44s\tremaining: 15s\n",
      "140:\tlearn: 0.4481949\ttotal: 2.45s\tremaining: 14.9s\n",
      "141:\tlearn: 0.4475236\ttotal: 2.47s\tremaining: 14.9s\n",
      "142:\tlearn: 0.4467803\ttotal: 2.48s\tremaining: 14.9s\n",
      "143:\tlearn: 0.4461204\ttotal: 2.5s\tremaining: 14.9s\n",
      "144:\tlearn: 0.4453603\ttotal: 2.52s\tremaining: 14.8s\n",
      "145:\tlearn: 0.4448611\ttotal: 2.54s\tremaining: 14.9s\n",
      "146:\tlearn: 0.4441854\ttotal: 2.56s\tremaining: 14.8s\n",
      "147:\tlearn: 0.4438046\ttotal: 2.57s\tremaining: 14.8s\n",
      "148:\tlearn: 0.4431401\ttotal: 2.59s\tremaining: 14.8s\n",
      "149:\tlearn: 0.4427484\ttotal: 2.6s\tremaining: 14.8s\n",
      "150:\tlearn: 0.4419786\ttotal: 2.62s\tremaining: 14.7s\n",
      "151:\tlearn: 0.4412430\ttotal: 2.64s\tremaining: 14.7s\n",
      "152:\tlearn: 0.4404055\ttotal: 2.65s\tremaining: 14.7s\n",
      "153:\tlearn: 0.4399605\ttotal: 2.67s\tremaining: 14.6s\n",
      "154:\tlearn: 0.4391768\ttotal: 2.68s\tremaining: 14.6s\n",
      "155:\tlearn: 0.4386982\ttotal: 2.69s\tremaining: 14.6s\n",
      "156:\tlearn: 0.4379535\ttotal: 2.71s\tremaining: 14.6s\n",
      "157:\tlearn: 0.4373241\ttotal: 2.72s\tremaining: 14.5s\n",
      "158:\tlearn: 0.4366865\ttotal: 2.74s\tremaining: 14.5s\n",
      "159:\tlearn: 0.4360038\ttotal: 2.75s\tremaining: 14.5s\n",
      "160:\tlearn: 0.4353432\ttotal: 2.77s\tremaining: 14.5s\n",
      "161:\tlearn: 0.4345445\ttotal: 2.79s\tremaining: 14.5s\n",
      "162:\tlearn: 0.4338879\ttotal: 2.82s\tremaining: 14.5s\n",
      "163:\tlearn: 0.4331619\ttotal: 2.85s\tremaining: 14.5s\n",
      "164:\tlearn: 0.4326672\ttotal: 2.87s\tremaining: 14.5s\n",
      "165:\tlearn: 0.4318653\ttotal: 2.88s\tremaining: 14.5s\n",
      "166:\tlearn: 0.4310701\ttotal: 2.9s\tremaining: 14.5s\n",
      "167:\tlearn: 0.4305525\ttotal: 2.92s\tremaining: 14.5s\n",
      "168:\tlearn: 0.4301117\ttotal: 2.94s\tremaining: 14.4s\n",
      "169:\tlearn: 0.4295246\ttotal: 2.95s\tremaining: 14.4s\n",
      "170:\tlearn: 0.4290952\ttotal: 2.97s\tremaining: 14.4s\n",
      "171:\tlearn: 0.4283544\ttotal: 2.99s\tremaining: 14.4s\n",
      "172:\tlearn: 0.4278414\ttotal: 3s\tremaining: 14.4s\n",
      "173:\tlearn: 0.4274429\ttotal: 3.03s\tremaining: 14.4s\n",
      "174:\tlearn: 0.4268665\ttotal: 3.05s\tremaining: 14.4s\n",
      "175:\tlearn: 0.4262896\ttotal: 3.06s\tremaining: 14.3s\n",
      "176:\tlearn: 0.4258343\ttotal: 3.08s\tremaining: 14.3s\n",
      "177:\tlearn: 0.4253808\ttotal: 3.1s\tremaining: 14.3s\n",
      "178:\tlearn: 0.4248528\ttotal: 3.11s\tremaining: 14.3s\n",
      "179:\tlearn: 0.4244919\ttotal: 3.13s\tremaining: 14.2s\n",
      "180:\tlearn: 0.4241201\ttotal: 3.14s\tremaining: 14.2s\n",
      "181:\tlearn: 0.4235383\ttotal: 3.16s\tremaining: 14.2s\n",
      "182:\tlearn: 0.4230699\ttotal: 3.17s\tremaining: 14.2s\n",
      "183:\tlearn: 0.4224329\ttotal: 3.19s\tremaining: 14.1s\n",
      "184:\tlearn: 0.4220942\ttotal: 3.2s\tremaining: 14.1s\n",
      "185:\tlearn: 0.4214752\ttotal: 3.22s\tremaining: 14.1s\n",
      "186:\tlearn: 0.4211739\ttotal: 3.24s\tremaining: 14.1s\n",
      "187:\tlearn: 0.4207847\ttotal: 3.26s\tremaining: 14.1s\n",
      "188:\tlearn: 0.4203708\ttotal: 3.27s\tremaining: 14.1s\n",
      "189:\tlearn: 0.4198734\ttotal: 3.29s\tremaining: 14s\n",
      "190:\tlearn: 0.4194700\ttotal: 3.31s\tremaining: 14s\n",
      "191:\tlearn: 0.4190275\ttotal: 3.32s\tremaining: 14s\n",
      "192:\tlearn: 0.4184422\ttotal: 3.33s\tremaining: 13.9s\n",
      "193:\tlearn: 0.4178671\ttotal: 3.35s\tremaining: 13.9s\n",
      "194:\tlearn: 0.4174518\ttotal: 3.36s\tremaining: 13.9s\n",
      "195:\tlearn: 0.4170858\ttotal: 3.38s\tremaining: 13.9s\n",
      "196:\tlearn: 0.4166441\ttotal: 3.4s\tremaining: 13.8s\n",
      "197:\tlearn: 0.4162855\ttotal: 3.41s\tremaining: 13.8s\n",
      "198:\tlearn: 0.4158775\ttotal: 3.43s\tremaining: 13.8s\n",
      "199:\tlearn: 0.4151936\ttotal: 3.44s\tremaining: 13.8s\n",
      "200:\tlearn: 0.4143447\ttotal: 3.46s\tremaining: 13.8s\n",
      "201:\tlearn: 0.4139016\ttotal: 3.49s\tremaining: 13.8s\n",
      "202:\tlearn: 0.4136457\ttotal: 3.51s\tremaining: 13.8s\n",
      "203:\tlearn: 0.4131765\ttotal: 3.53s\tremaining: 13.8s\n",
      "204:\tlearn: 0.4127069\ttotal: 3.55s\tremaining: 13.8s\n",
      "205:\tlearn: 0.4120069\ttotal: 3.56s\tremaining: 13.7s\n",
      "206:\tlearn: 0.4116167\ttotal: 3.58s\tremaining: 13.7s\n",
      "207:\tlearn: 0.4112310\ttotal: 3.59s\tremaining: 13.7s\n",
      "208:\tlearn: 0.4108294\ttotal: 3.61s\tremaining: 13.7s\n",
      "209:\tlearn: 0.4101693\ttotal: 3.63s\tremaining: 13.6s\n",
      "210:\tlearn: 0.4096326\ttotal: 3.64s\tremaining: 13.6s\n",
      "211:\tlearn: 0.4092429\ttotal: 3.66s\tremaining: 13.6s\n",
      "212:\tlearn: 0.4085929\ttotal: 3.67s\tremaining: 13.6s\n",
      "213:\tlearn: 0.4080469\ttotal: 3.69s\tremaining: 13.5s\n",
      "214:\tlearn: 0.4076478\ttotal: 3.7s\tremaining: 13.5s\n",
      "215:\tlearn: 0.4073656\ttotal: 3.71s\tremaining: 13.5s\n",
      "216:\tlearn: 0.4068300\ttotal: 3.74s\tremaining: 13.5s\n",
      "217:\tlearn: 0.4064559\ttotal: 3.75s\tremaining: 13.5s\n",
      "218:\tlearn: 0.4059865\ttotal: 3.77s\tremaining: 13.4s\n",
      "219:\tlearn: 0.4054532\ttotal: 3.78s\tremaining: 13.4s\n",
      "220:\tlearn: 0.4050269\ttotal: 3.8s\tremaining: 13.4s\n",
      "221:\tlearn: 0.4044490\ttotal: 3.81s\tremaining: 13.4s\n",
      "222:\tlearn: 0.4041477\ttotal: 3.83s\tremaining: 13.4s\n",
      "223:\tlearn: 0.4038001\ttotal: 3.86s\tremaining: 13.4s\n",
      "224:\tlearn: 0.4033369\ttotal: 3.89s\tremaining: 13.4s\n",
      "225:\tlearn: 0.4027774\ttotal: 3.91s\tremaining: 13.4s\n",
      "226:\tlearn: 0.4022658\ttotal: 3.92s\tremaining: 13.4s\n",
      "227:\tlearn: 0.4017017\ttotal: 3.94s\tremaining: 13.3s\n",
      "228:\tlearn: 0.4013404\ttotal: 3.95s\tremaining: 13.3s\n",
      "229:\tlearn: 0.4009901\ttotal: 3.97s\tremaining: 13.3s\n",
      "230:\tlearn: 0.4005947\ttotal: 3.99s\tremaining: 13.3s\n",
      "231:\tlearn: 0.4002788\ttotal: 4.01s\tremaining: 13.3s\n",
      "232:\tlearn: 0.4000054\ttotal: 4.03s\tremaining: 13.3s\n",
      "233:\tlearn: 0.3996419\ttotal: 4.04s\tremaining: 13.2s\n",
      "234:\tlearn: 0.3990571\ttotal: 4.06s\tremaining: 13.2s\n",
      "235:\tlearn: 0.3986984\ttotal: 4.07s\tremaining: 13.2s\n",
      "236:\tlearn: 0.3983924\ttotal: 4.09s\tremaining: 13.2s\n",
      "237:\tlearn: 0.3982494\ttotal: 4.09s\tremaining: 13.1s\n",
      "238:\tlearn: 0.3979703\ttotal: 4.1s\tremaining: 13.1s\n",
      "239:\tlearn: 0.3976375\ttotal: 4.12s\tremaining: 13s\n",
      "240:\tlearn: 0.3973076\ttotal: 4.13s\tremaining: 13s\n",
      "241:\tlearn: 0.3969498\ttotal: 4.14s\tremaining: 13s\n",
      "242:\tlearn: 0.3964918\ttotal: 4.16s\tremaining: 13s\n",
      "243:\tlearn: 0.3962748\ttotal: 4.17s\tremaining: 12.9s\n",
      "244:\tlearn: 0.3957944\ttotal: 4.18s\tremaining: 12.9s\n",
      "245:\tlearn: 0.3953353\ttotal: 4.2s\tremaining: 12.9s\n",
      "246:\tlearn: 0.3950151\ttotal: 4.21s\tremaining: 12.8s\n",
      "247:\tlearn: 0.3945632\ttotal: 4.24s\tremaining: 12.8s\n",
      "248:\tlearn: 0.3942191\ttotal: 4.25s\tremaining: 12.8s\n",
      "249:\tlearn: 0.3937757\ttotal: 4.27s\tremaining: 12.8s\n",
      "250:\tlearn: 0.3933752\ttotal: 4.29s\tremaining: 12.8s\n",
      "251:\tlearn: 0.3931491\ttotal: 4.3s\tremaining: 12.8s\n",
      "252:\tlearn: 0.3927189\ttotal: 4.32s\tremaining: 12.8s\n",
      "253:\tlearn: 0.3924607\ttotal: 4.33s\tremaining: 12.7s\n",
      "254:\tlearn: 0.3921438\ttotal: 4.35s\tremaining: 12.7s\n",
      "255:\tlearn: 0.3917927\ttotal: 4.36s\tremaining: 12.7s\n",
      "256:\tlearn: 0.3915524\ttotal: 4.38s\tremaining: 12.7s\n",
      "257:\tlearn: 0.3913088\ttotal: 4.39s\tremaining: 12.6s\n",
      "258:\tlearn: 0.3908622\ttotal: 4.41s\tremaining: 12.6s\n",
      "259:\tlearn: 0.3906122\ttotal: 4.42s\tremaining: 12.6s\n",
      "260:\tlearn: 0.3901887\ttotal: 4.44s\tremaining: 12.6s\n",
      "261:\tlearn: 0.3898743\ttotal: 4.46s\tremaining: 12.6s\n",
      "262:\tlearn: 0.3893554\ttotal: 4.49s\tremaining: 12.6s\n",
      "263:\tlearn: 0.3890425\ttotal: 4.5s\tremaining: 12.5s\n",
      "264:\tlearn: 0.3886886\ttotal: 4.52s\tremaining: 12.5s\n",
      "265:\tlearn: 0.3883194\ttotal: 4.53s\tremaining: 12.5s\n",
      "266:\tlearn: 0.3879715\ttotal: 4.55s\tremaining: 12.5s\n",
      "267:\tlearn: 0.3877662\ttotal: 4.56s\tremaining: 12.5s\n",
      "268:\tlearn: 0.3875479\ttotal: 4.58s\tremaining: 12.4s\n",
      "269:\tlearn: 0.3869090\ttotal: 4.59s\tremaining: 12.4s\n",
      "270:\tlearn: 0.3865467\ttotal: 4.61s\tremaining: 12.4s\n",
      "271:\tlearn: 0.3860480\ttotal: 4.63s\tremaining: 12.4s\n",
      "272:\tlearn: 0.3856011\ttotal: 4.64s\tremaining: 12.4s\n",
      "273:\tlearn: 0.3852429\ttotal: 4.66s\tremaining: 12.3s\n",
      "274:\tlearn: 0.3848631\ttotal: 4.67s\tremaining: 12.3s\n",
      "275:\tlearn: 0.3844569\ttotal: 4.68s\tremaining: 12.3s\n",
      "276:\tlearn: 0.3841300\ttotal: 4.7s\tremaining: 12.3s\n",
      "277:\tlearn: 0.3837706\ttotal: 4.72s\tremaining: 12.3s\n",
      "278:\tlearn: 0.3834613\ttotal: 4.74s\tremaining: 12.2s\n",
      "279:\tlearn: 0.3831764\ttotal: 4.75s\tremaining: 12.2s\n",
      "280:\tlearn: 0.3829389\ttotal: 4.76s\tremaining: 12.2s\n",
      "281:\tlearn: 0.3825643\ttotal: 4.78s\tremaining: 12.2s\n",
      "282:\tlearn: 0.3823995\ttotal: 4.79s\tremaining: 12.1s\n",
      "283:\tlearn: 0.3820507\ttotal: 4.81s\tremaining: 12.1s\n",
      "284:\tlearn: 0.3816409\ttotal: 4.83s\tremaining: 12.1s\n",
      "285:\tlearn: 0.3810614\ttotal: 4.84s\tremaining: 12.1s\n",
      "286:\tlearn: 0.3808067\ttotal: 4.86s\tremaining: 12.1s\n",
      "287:\tlearn: 0.3805245\ttotal: 4.87s\tremaining: 12.1s\n",
      "288:\tlearn: 0.3799513\ttotal: 4.89s\tremaining: 12s\n",
      "289:\tlearn: 0.3797065\ttotal: 4.92s\tremaining: 12s\n",
      "290:\tlearn: 0.3794858\ttotal: 4.95s\tremaining: 12s\n",
      "291:\tlearn: 0.3790179\ttotal: 4.97s\tremaining: 12.1s\n",
      "292:\tlearn: 0.3787062\ttotal: 4.99s\tremaining: 12s\n",
      "293:\tlearn: 0.3782551\ttotal: 5.01s\tremaining: 12s\n",
      "294:\tlearn: 0.3780354\ttotal: 5.02s\tremaining: 12s\n",
      "295:\tlearn: 0.3777228\ttotal: 5.04s\tremaining: 12s\n",
      "296:\tlearn: 0.3771873\ttotal: 5.06s\tremaining: 12s\n",
      "297:\tlearn: 0.3768436\ttotal: 5.07s\tremaining: 11.9s\n",
      "298:\tlearn: 0.3764691\ttotal: 5.09s\tremaining: 11.9s\n",
      "299:\tlearn: 0.3761977\ttotal: 5.1s\tremaining: 11.9s\n",
      "300:\tlearn: 0.3758906\ttotal: 5.12s\tremaining: 11.9s\n",
      "301:\tlearn: 0.3756393\ttotal: 5.13s\tremaining: 11.9s\n",
      "302:\tlearn: 0.3752912\ttotal: 5.14s\tremaining: 11.8s\n",
      "303:\tlearn: 0.3749137\ttotal: 5.16s\tremaining: 11.8s\n",
      "304:\tlearn: 0.3744916\ttotal: 5.17s\tremaining: 11.8s\n",
      "305:\tlearn: 0.3741529\ttotal: 5.26s\tremaining: 11.9s\n",
      "306:\tlearn: 0.3738582\ttotal: 5.29s\tremaining: 11.9s\n",
      "307:\tlearn: 0.3735008\ttotal: 5.31s\tremaining: 11.9s\n",
      "308:\tlearn: 0.3732877\ttotal: 5.32s\tremaining: 11.9s\n",
      "309:\tlearn: 0.3730152\ttotal: 5.34s\tremaining: 11.9s\n",
      "310:\tlearn: 0.3727992\ttotal: 5.35s\tremaining: 11.9s\n",
      "311:\tlearn: 0.3723716\ttotal: 5.37s\tremaining: 11.8s\n",
      "312:\tlearn: 0.3719960\ttotal: 5.39s\tremaining: 11.8s\n",
      "313:\tlearn: 0.3718000\ttotal: 5.4s\tremaining: 11.8s\n",
      "314:\tlearn: 0.3716073\ttotal: 5.42s\tremaining: 11.8s\n",
      "315:\tlearn: 0.3712835\ttotal: 5.43s\tremaining: 11.8s\n",
      "316:\tlearn: 0.3707119\ttotal: 5.45s\tremaining: 11.7s\n",
      "317:\tlearn: 0.3703875\ttotal: 5.47s\tremaining: 11.7s\n",
      "318:\tlearn: 0.3701491\ttotal: 5.49s\tremaining: 11.7s\n",
      "319:\tlearn: 0.3698242\ttotal: 5.5s\tremaining: 11.7s\n",
      "320:\tlearn: 0.3696873\ttotal: 5.52s\tremaining: 11.7s\n",
      "321:\tlearn: 0.3694641\ttotal: 5.53s\tremaining: 11.7s\n",
      "322:\tlearn: 0.3691278\ttotal: 5.55s\tremaining: 11.6s\n",
      "323:\tlearn: 0.3686473\ttotal: 5.57s\tremaining: 11.6s\n",
      "324:\tlearn: 0.3683526\ttotal: 5.58s\tremaining: 11.6s\n",
      "325:\tlearn: 0.3679744\ttotal: 5.6s\tremaining: 11.6s\n",
      "326:\tlearn: 0.3676295\ttotal: 5.61s\tremaining: 11.5s\n",
      "327:\tlearn: 0.3673625\ttotal: 5.63s\tremaining: 11.5s\n",
      "328:\tlearn: 0.3670138\ttotal: 5.64s\tremaining: 11.5s\n",
      "329:\tlearn: 0.3665581\ttotal: 5.66s\tremaining: 11.5s\n",
      "330:\tlearn: 0.3661253\ttotal: 5.67s\tremaining: 11.5s\n",
      "331:\tlearn: 0.3655539\ttotal: 5.69s\tremaining: 11.4s\n",
      "332:\tlearn: 0.3653401\ttotal: 5.71s\tremaining: 11.4s\n",
      "333:\tlearn: 0.3651389\ttotal: 5.73s\tremaining: 11.4s\n",
      "334:\tlearn: 0.3650027\ttotal: 5.74s\tremaining: 11.4s\n",
      "335:\tlearn: 0.3647750\ttotal: 5.75s\tremaining: 11.4s\n",
      "336:\tlearn: 0.3643238\ttotal: 5.77s\tremaining: 11.4s\n",
      "337:\tlearn: 0.3639744\ttotal: 5.78s\tremaining: 11.3s\n",
      "338:\tlearn: 0.3638260\ttotal: 5.8s\tremaining: 11.3s\n",
      "339:\tlearn: 0.3633246\ttotal: 5.81s\tremaining: 11.3s\n",
      "340:\tlearn: 0.3629237\ttotal: 5.83s\tremaining: 11.3s\n",
      "341:\tlearn: 0.3627663\ttotal: 5.84s\tremaining: 11.2s\n",
      "342:\tlearn: 0.3624760\ttotal: 5.86s\tremaining: 11.2s\n",
      "343:\tlearn: 0.3623345\ttotal: 5.88s\tremaining: 11.2s\n",
      "344:\tlearn: 0.3619471\ttotal: 5.89s\tremaining: 11.2s\n",
      "345:\tlearn: 0.3617762\ttotal: 5.91s\tremaining: 11.2s\n",
      "346:\tlearn: 0.3616417\ttotal: 5.92s\tremaining: 11.1s\n",
      "347:\tlearn: 0.3614874\ttotal: 5.94s\tremaining: 11.1s\n",
      "348:\tlearn: 0.3612425\ttotal: 5.97s\tremaining: 11.1s\n",
      "349:\tlearn: 0.3609307\ttotal: 6s\tremaining: 11.1s\n",
      "350:\tlearn: 0.3604163\ttotal: 6.02s\tremaining: 11.1s\n",
      "351:\tlearn: 0.3601362\ttotal: 6.04s\tremaining: 11.1s\n",
      "352:\tlearn: 0.3598252\ttotal: 6.05s\tremaining: 11.1s\n",
      "353:\tlearn: 0.3594970\ttotal: 6.07s\tremaining: 11.1s\n",
      "354:\tlearn: 0.3593374\ttotal: 6.08s\tremaining: 11.1s\n",
      "355:\tlearn: 0.3588833\ttotal: 6.1s\tremaining: 11s\n",
      "356:\tlearn: 0.3586842\ttotal: 6.11s\tremaining: 11s\n",
      "357:\tlearn: 0.3584101\ttotal: 6.13s\tremaining: 11s\n",
      "358:\tlearn: 0.3581428\ttotal: 6.14s\tremaining: 11s\n",
      "359:\tlearn: 0.3578628\ttotal: 6.16s\tremaining: 10.9s\n",
      "360:\tlearn: 0.3576265\ttotal: 6.17s\tremaining: 10.9s\n",
      "361:\tlearn: 0.3573088\ttotal: 6.18s\tremaining: 10.9s\n",
      "362:\tlearn: 0.3570659\ttotal: 6.21s\tremaining: 10.9s\n",
      "363:\tlearn: 0.3567315\ttotal: 6.23s\tremaining: 10.9s\n",
      "364:\tlearn: 0.3563763\ttotal: 6.24s\tremaining: 10.9s\n",
      "365:\tlearn: 0.3558861\ttotal: 6.26s\tremaining: 10.8s\n",
      "366:\tlearn: 0.3554829\ttotal: 6.27s\tremaining: 10.8s\n",
      "367:\tlearn: 0.3550766\ttotal: 6.29s\tremaining: 10.8s\n",
      "368:\tlearn: 0.3548576\ttotal: 6.31s\tremaining: 10.8s\n",
      "369:\tlearn: 0.3545047\ttotal: 6.32s\tremaining: 10.8s\n",
      "370:\tlearn: 0.3542014\ttotal: 6.34s\tremaining: 10.7s\n",
      "371:\tlearn: 0.3538942\ttotal: 6.35s\tremaining: 10.7s\n",
      "372:\tlearn: 0.3535999\ttotal: 6.37s\tremaining: 10.7s\n",
      "373:\tlearn: 0.3534287\ttotal: 6.38s\tremaining: 10.7s\n",
      "374:\tlearn: 0.3531882\ttotal: 6.39s\tremaining: 10.7s\n",
      "375:\tlearn: 0.3527884\ttotal: 6.41s\tremaining: 10.6s\n",
      "376:\tlearn: 0.3525620\ttotal: 6.42s\tremaining: 10.6s\n",
      "377:\tlearn: 0.3523800\ttotal: 6.45s\tremaining: 10.6s\n",
      "378:\tlearn: 0.3519599\ttotal: 6.46s\tremaining: 10.6s\n",
      "379:\tlearn: 0.3515643\ttotal: 6.48s\tremaining: 10.6s\n",
      "380:\tlearn: 0.3512117\ttotal: 6.5s\tremaining: 10.6s\n",
      "381:\tlearn: 0.3510686\ttotal: 6.51s\tremaining: 10.5s\n",
      "382:\tlearn: 0.3507294\ttotal: 6.53s\tremaining: 10.5s\n",
      "383:\tlearn: 0.3505245\ttotal: 6.55s\tremaining: 10.5s\n",
      "384:\tlearn: 0.3502006\ttotal: 6.57s\tremaining: 10.5s\n",
      "385:\tlearn: 0.3499538\ttotal: 6.59s\tremaining: 10.5s\n",
      "386:\tlearn: 0.3497019\ttotal: 6.6s\tremaining: 10.5s\n",
      "387:\tlearn: 0.3494476\ttotal: 6.62s\tremaining: 10.4s\n",
      "388:\tlearn: 0.3493376\ttotal: 6.63s\tremaining: 10.4s\n",
      "389:\tlearn: 0.3491302\ttotal: 6.64s\tremaining: 10.4s\n",
      "390:\tlearn: 0.3487278\ttotal: 6.66s\tremaining: 10.4s\n",
      "391:\tlearn: 0.3482855\ttotal: 6.67s\tremaining: 10.4s\n",
      "392:\tlearn: 0.3479633\ttotal: 6.7s\tremaining: 10.3s\n",
      "393:\tlearn: 0.3476839\ttotal: 6.72s\tremaining: 10.3s\n",
      "394:\tlearn: 0.3473020\ttotal: 6.73s\tremaining: 10.3s\n",
      "395:\tlearn: 0.3470353\ttotal: 6.75s\tremaining: 10.3s\n",
      "396:\tlearn: 0.3468275\ttotal: 6.76s\tremaining: 10.3s\n",
      "397:\tlearn: 0.3464119\ttotal: 6.78s\tremaining: 10.3s\n",
      "398:\tlearn: 0.3460573\ttotal: 6.79s\tremaining: 10.2s\n",
      "399:\tlearn: 0.3459263\ttotal: 6.81s\tremaining: 10.2s\n",
      "400:\tlearn: 0.3455571\ttotal: 6.82s\tremaining: 10.2s\n",
      "401:\tlearn: 0.3451952\ttotal: 6.83s\tremaining: 10.2s\n",
      "402:\tlearn: 0.3448294\ttotal: 6.85s\tremaining: 10.1s\n",
      "403:\tlearn: 0.3446114\ttotal: 6.87s\tremaining: 10.1s\n",
      "404:\tlearn: 0.3442368\ttotal: 6.88s\tremaining: 10.1s\n",
      "405:\tlearn: 0.3440829\ttotal: 6.9s\tremaining: 10.1s\n",
      "406:\tlearn: 0.3436435\ttotal: 6.91s\tremaining: 10.1s\n",
      "407:\tlearn: 0.3434230\ttotal: 6.94s\tremaining: 10.1s\n",
      "408:\tlearn: 0.3432674\ttotal: 6.95s\tremaining: 10s\n",
      "409:\tlearn: 0.3430246\ttotal: 6.97s\tremaining: 10s\n",
      "410:\tlearn: 0.3426978\ttotal: 6.98s\tremaining: 10s\n",
      "411:\tlearn: 0.3424493\ttotal: 7s\tremaining: 9.99s\n",
      "412:\tlearn: 0.3422729\ttotal: 7.01s\tremaining: 9.97s\n",
      "413:\tlearn: 0.3421662\ttotal: 7.04s\tremaining: 9.97s\n",
      "414:\tlearn: 0.3418801\ttotal: 7.07s\tremaining: 9.97s\n",
      "415:\tlearn: 0.3416453\ttotal: 7.09s\tremaining: 9.95s\n",
      "416:\tlearn: 0.3414242\ttotal: 7.1s\tremaining: 9.93s\n",
      "417:\tlearn: 0.3410603\ttotal: 7.12s\tremaining: 9.91s\n",
      "418:\tlearn: 0.3408768\ttotal: 7.13s\tremaining: 9.89s\n",
      "419:\tlearn: 0.3405712\ttotal: 7.15s\tremaining: 9.88s\n",
      "420:\tlearn: 0.3402600\ttotal: 7.16s\tremaining: 9.85s\n",
      "421:\tlearn: 0.3400354\ttotal: 7.19s\tremaining: 9.85s\n",
      "422:\tlearn: 0.3397105\ttotal: 7.21s\tremaining: 9.83s\n",
      "423:\tlearn: 0.3394407\ttotal: 7.22s\tremaining: 9.81s\n",
      "424:\tlearn: 0.3391548\ttotal: 7.23s\tremaining: 9.79s\n",
      "425:\tlearn: 0.3389959\ttotal: 7.25s\tremaining: 9.77s\n",
      "426:\tlearn: 0.3387166\ttotal: 7.26s\tremaining: 9.75s\n",
      "427:\tlearn: 0.3385069\ttotal: 7.28s\tremaining: 9.73s\n",
      "428:\tlearn: 0.3381120\ttotal: 7.29s\tremaining: 9.71s\n",
      "429:\tlearn: 0.3379169\ttotal: 7.31s\tremaining: 9.69s\n",
      "430:\tlearn: 0.3376905\ttotal: 7.33s\tremaining: 9.67s\n",
      "431:\tlearn: 0.3373378\ttotal: 7.34s\tremaining: 9.65s\n",
      "432:\tlearn: 0.3370192\ttotal: 7.36s\tremaining: 9.63s\n",
      "433:\tlearn: 0.3366568\ttotal: 7.37s\tremaining: 9.61s\n",
      "434:\tlearn: 0.3363463\ttotal: 7.38s\tremaining: 9.59s\n",
      "435:\tlearn: 0.3360150\ttotal: 7.4s\tremaining: 9.57s\n",
      "436:\tlearn: 0.3355643\ttotal: 7.42s\tremaining: 9.55s\n",
      "437:\tlearn: 0.3353882\ttotal: 7.44s\tremaining: 9.55s\n",
      "438:\tlearn: 0.3353013\ttotal: 7.46s\tremaining: 9.53s\n",
      "439:\tlearn: 0.3350063\ttotal: 7.48s\tremaining: 9.52s\n",
      "440:\tlearn: 0.3347218\ttotal: 7.49s\tremaining: 9.49s\n",
      "441:\tlearn: 0.3345348\ttotal: 7.51s\tremaining: 9.48s\n",
      "442:\tlearn: 0.3341820\ttotal: 7.52s\tremaining: 9.46s\n",
      "443:\tlearn: 0.3339625\ttotal: 7.54s\tremaining: 9.44s\n",
      "444:\tlearn: 0.3335577\ttotal: 7.55s\tremaining: 9.42s\n",
      "445:\tlearn: 0.3333361\ttotal: 7.57s\tremaining: 9.4s\n",
      "446:\tlearn: 0.3330899\ttotal: 7.58s\tremaining: 9.38s\n",
      "447:\tlearn: 0.3329838\ttotal: 7.6s\tremaining: 9.36s\n",
      "448:\tlearn: 0.3327042\ttotal: 7.61s\tremaining: 9.34s\n",
      "449:\tlearn: 0.3323733\ttotal: 7.63s\tremaining: 9.32s\n",
      "450:\tlearn: 0.3321423\ttotal: 7.64s\tremaining: 9.3s\n",
      "451:\tlearn: 0.3318648\ttotal: 7.66s\tremaining: 9.28s\n",
      "452:\tlearn: 0.3316528\ttotal: 7.68s\tremaining: 9.28s\n",
      "453:\tlearn: 0.3313356\ttotal: 7.7s\tremaining: 9.26s\n",
      "454:\tlearn: 0.3310381\ttotal: 7.71s\tremaining: 9.24s\n",
      "455:\tlearn: 0.3308266\ttotal: 7.73s\tremaining: 9.22s\n",
      "456:\tlearn: 0.3304604\ttotal: 7.74s\tremaining: 9.2s\n",
      "457:\tlearn: 0.3302542\ttotal: 7.76s\tremaining: 9.18s\n",
      "458:\tlearn: 0.3298900\ttotal: 7.77s\tremaining: 9.16s\n",
      "459:\tlearn: 0.3296933\ttotal: 7.79s\tremaining: 9.14s\n",
      "460:\tlearn: 0.3294005\ttotal: 7.8s\tremaining: 9.12s\n",
      "461:\tlearn: 0.3291278\ttotal: 7.82s\tremaining: 9.1s\n",
      "462:\tlearn: 0.3289584\ttotal: 7.83s\tremaining: 9.09s\n",
      "463:\tlearn: 0.3289084\ttotal: 7.85s\tremaining: 9.06s\n",
      "464:\tlearn: 0.3287059\ttotal: 7.86s\tremaining: 9.05s\n",
      "465:\tlearn: 0.3284656\ttotal: 7.88s\tremaining: 9.03s\n",
      "466:\tlearn: 0.3280671\ttotal: 7.89s\tremaining: 9.01s\n",
      "467:\tlearn: 0.3278097\ttotal: 7.91s\tremaining: 8.99s\n",
      "468:\tlearn: 0.3274999\ttotal: 7.94s\tremaining: 8.99s\n",
      "469:\tlearn: 0.3273016\ttotal: 7.95s\tremaining: 8.97s\n",
      "470:\tlearn: 0.3269554\ttotal: 7.97s\tremaining: 8.95s\n",
      "471:\tlearn: 0.3266977\ttotal: 7.98s\tremaining: 8.93s\n",
      "472:\tlearn: 0.3262834\ttotal: 8s\tremaining: 8.91s\n",
      "473:\tlearn: 0.3260656\ttotal: 8.01s\tremaining: 8.89s\n",
      "474:\tlearn: 0.3258073\ttotal: 8.02s\tremaining: 8.87s\n",
      "475:\tlearn: 0.3256615\ttotal: 8.04s\tremaining: 8.85s\n",
      "476:\tlearn: 0.3254936\ttotal: 8.05s\tremaining: 8.83s\n",
      "477:\tlearn: 0.3253903\ttotal: 8.07s\tremaining: 8.81s\n",
      "478:\tlearn: 0.3251609\ttotal: 8.1s\tremaining: 8.81s\n",
      "479:\tlearn: 0.3247234\ttotal: 8.13s\tremaining: 8.81s\n",
      "480:\tlearn: 0.3244790\ttotal: 8.14s\tremaining: 8.79s\n",
      "481:\tlearn: 0.3242818\ttotal: 8.17s\tremaining: 8.78s\n",
      "482:\tlearn: 0.3240481\ttotal: 8.19s\tremaining: 8.77s\n",
      "483:\tlearn: 0.3236967\ttotal: 8.21s\tremaining: 8.75s\n",
      "484:\tlearn: 0.3234948\ttotal: 8.22s\tremaining: 8.73s\n",
      "485:\tlearn: 0.3233119\ttotal: 8.29s\tremaining: 8.76s\n",
      "486:\tlearn: 0.3231253\ttotal: 8.32s\tremaining: 8.77s\n",
      "487:\tlearn: 0.3226974\ttotal: 8.34s\tremaining: 8.75s\n",
      "488:\tlearn: 0.3225266\ttotal: 8.36s\tremaining: 8.73s\n",
      "489:\tlearn: 0.3221740\ttotal: 8.37s\tremaining: 8.71s\n",
      "490:\tlearn: 0.3220066\ttotal: 8.39s\tremaining: 8.7s\n",
      "491:\tlearn: 0.3217360\ttotal: 8.42s\tremaining: 8.69s\n",
      "492:\tlearn: 0.3215370\ttotal: 8.43s\tremaining: 8.67s\n",
      "493:\tlearn: 0.3212270\ttotal: 8.45s\tremaining: 8.65s\n",
      "494:\tlearn: 0.3211487\ttotal: 8.46s\tremaining: 8.64s\n",
      "495:\tlearn: 0.3209406\ttotal: 8.48s\tremaining: 8.62s\n",
      "496:\tlearn: 0.3209137\ttotal: 8.48s\tremaining: 8.59s\n",
      "497:\tlearn: 0.3207225\ttotal: 8.5s\tremaining: 8.57s\n",
      "498:\tlearn: 0.3203803\ttotal: 8.52s\tremaining: 8.55s\n",
      "499:\tlearn: 0.3200901\ttotal: 8.53s\tremaining: 8.53s\n",
      "500:\tlearn: 0.3198193\ttotal: 8.55s\tremaining: 8.51s\n",
      "501:\tlearn: 0.3196520\ttotal: 8.56s\tremaining: 8.49s\n",
      "502:\tlearn: 0.3193139\ttotal: 8.58s\tremaining: 8.47s\n",
      "503:\tlearn: 0.3190693\ttotal: 8.59s\tremaining: 8.45s\n",
      "504:\tlearn: 0.3187627\ttotal: 8.6s\tremaining: 8.43s\n",
      "505:\tlearn: 0.3186029\ttotal: 8.62s\tremaining: 8.41s\n",
      "506:\tlearn: 0.3183779\ttotal: 8.63s\tremaining: 8.39s\n",
      "507:\tlearn: 0.3180735\ttotal: 8.65s\tremaining: 8.38s\n",
      "508:\tlearn: 0.3178902\ttotal: 8.67s\tremaining: 8.37s\n",
      "509:\tlearn: 0.3176925\ttotal: 8.69s\tremaining: 8.35s\n",
      "510:\tlearn: 0.3173528\ttotal: 8.7s\tremaining: 8.33s\n",
      "511:\tlearn: 0.3171409\ttotal: 8.72s\tremaining: 8.31s\n",
      "512:\tlearn: 0.3170128\ttotal: 8.73s\tremaining: 8.29s\n",
      "513:\tlearn: 0.3167008\ttotal: 8.75s\tremaining: 8.27s\n",
      "514:\tlearn: 0.3164701\ttotal: 8.77s\tremaining: 8.25s\n",
      "515:\tlearn: 0.3162973\ttotal: 8.78s\tremaining: 8.23s\n",
      "516:\tlearn: 0.3160724\ttotal: 8.79s\tremaining: 8.21s\n",
      "517:\tlearn: 0.3159686\ttotal: 8.81s\tremaining: 8.2s\n",
      "518:\tlearn: 0.3155272\ttotal: 8.83s\tremaining: 8.18s\n",
      "519:\tlearn: 0.3151137\ttotal: 8.84s\tremaining: 8.16s\n",
      "520:\tlearn: 0.3148858\ttotal: 8.86s\tremaining: 8.14s\n",
      "521:\tlearn: 0.3147085\ttotal: 8.87s\tremaining: 8.12s\n",
      "522:\tlearn: 0.3144627\ttotal: 8.88s\tremaining: 8.1s\n",
      "523:\tlearn: 0.3141928\ttotal: 8.91s\tremaining: 8.1s\n",
      "524:\tlearn: 0.3139419\ttotal: 8.93s\tremaining: 8.08s\n",
      "525:\tlearn: 0.3135996\ttotal: 8.94s\tremaining: 8.06s\n",
      "526:\tlearn: 0.3132953\ttotal: 8.96s\tremaining: 8.04s\n",
      "527:\tlearn: 0.3131274\ttotal: 8.97s\tremaining: 8.02s\n",
      "528:\tlearn: 0.3130354\ttotal: 8.99s\tremaining: 8s\n",
      "529:\tlearn: 0.3128636\ttotal: 9s\tremaining: 7.98s\n",
      "530:\tlearn: 0.3127068\ttotal: 9.02s\tremaining: 7.96s\n",
      "531:\tlearn: 0.3126290\ttotal: 9.03s\tremaining: 7.94s\n",
      "532:\tlearn: 0.3124994\ttotal: 9.04s\tremaining: 7.92s\n",
      "533:\tlearn: 0.3123025\ttotal: 9.06s\tremaining: 7.91s\n",
      "534:\tlearn: 0.3120472\ttotal: 9.07s\tremaining: 7.88s\n",
      "535:\tlearn: 0.3118697\ttotal: 9.09s\tremaining: 7.87s\n",
      "536:\tlearn: 0.3117220\ttotal: 9.1s\tremaining: 7.85s\n",
      "537:\tlearn: 0.3115654\ttotal: 9.12s\tremaining: 7.83s\n",
      "538:\tlearn: 0.3112944\ttotal: 9.16s\tremaining: 7.84s\n",
      "539:\tlearn: 0.3110159\ttotal: 9.19s\tremaining: 7.83s\n",
      "540:\tlearn: 0.3108734\ttotal: 9.21s\tremaining: 7.81s\n",
      "541:\tlearn: 0.3108478\ttotal: 9.22s\tremaining: 7.79s\n",
      "542:\tlearn: 0.3106627\ttotal: 9.24s\tremaining: 7.78s\n",
      "543:\tlearn: 0.3105020\ttotal: 9.25s\tremaining: 7.76s\n",
      "544:\tlearn: 0.3102883\ttotal: 9.27s\tremaining: 7.74s\n",
      "545:\tlearn: 0.3100737\ttotal: 9.28s\tremaining: 7.72s\n",
      "546:\tlearn: 0.3099732\ttotal: 9.3s\tremaining: 7.7s\n",
      "547:\tlearn: 0.3097071\ttotal: 9.31s\tremaining: 7.68s\n",
      "548:\tlearn: 0.3093185\ttotal: 9.33s\tremaining: 7.67s\n",
      "549:\tlearn: 0.3090060\ttotal: 9.35s\tremaining: 7.65s\n",
      "550:\tlearn: 0.3087877\ttotal: 9.37s\tremaining: 7.63s\n",
      "551:\tlearn: 0.3085823\ttotal: 9.38s\tremaining: 7.62s\n",
      "552:\tlearn: 0.3082530\ttotal: 9.41s\tremaining: 7.61s\n",
      "553:\tlearn: 0.3078512\ttotal: 9.43s\tremaining: 7.59s\n",
      "554:\tlearn: 0.3075205\ttotal: 9.44s\tremaining: 7.57s\n",
      "555:\tlearn: 0.3072393\ttotal: 9.46s\tremaining: 7.55s\n",
      "556:\tlearn: 0.3069491\ttotal: 9.47s\tremaining: 7.53s\n",
      "557:\tlearn: 0.3066680\ttotal: 9.49s\tremaining: 7.51s\n",
      "558:\tlearn: 0.3065125\ttotal: 9.5s\tremaining: 7.5s\n",
      "559:\tlearn: 0.3062841\ttotal: 9.52s\tremaining: 7.48s\n",
      "560:\tlearn: 0.3061265\ttotal: 9.53s\tremaining: 7.46s\n",
      "561:\tlearn: 0.3058966\ttotal: 9.55s\tremaining: 7.44s\n",
      "562:\tlearn: 0.3055645\ttotal: 9.57s\tremaining: 7.43s\n",
      "563:\tlearn: 0.3051549\ttotal: 9.59s\tremaining: 7.41s\n",
      "564:\tlearn: 0.3050321\ttotal: 9.6s\tremaining: 7.39s\n",
      "565:\tlearn: 0.3048516\ttotal: 9.62s\tremaining: 7.38s\n",
      "566:\tlearn: 0.3046772\ttotal: 9.64s\tremaining: 7.36s\n",
      "567:\tlearn: 0.3044526\ttotal: 9.66s\tremaining: 7.35s\n",
      "568:\tlearn: 0.3042193\ttotal: 9.67s\tremaining: 7.33s\n",
      "569:\tlearn: 0.3040150\ttotal: 9.69s\tremaining: 7.31s\n",
      "570:\tlearn: 0.3037930\ttotal: 9.71s\tremaining: 7.29s\n",
      "571:\tlearn: 0.3034473\ttotal: 9.72s\tremaining: 7.27s\n",
      "572:\tlearn: 0.3032145\ttotal: 9.74s\tremaining: 7.26s\n",
      "573:\tlearn: 0.3028793\ttotal: 9.75s\tremaining: 7.24s\n",
      "574:\tlearn: 0.3027536\ttotal: 9.77s\tremaining: 7.22s\n",
      "575:\tlearn: 0.3023656\ttotal: 9.78s\tremaining: 7.2s\n",
      "576:\tlearn: 0.3022043\ttotal: 9.8s\tremaining: 7.18s\n",
      "577:\tlearn: 0.3020060\ttotal: 9.81s\tremaining: 7.16s\n",
      "578:\tlearn: 0.3017663\ttotal: 9.83s\tremaining: 7.14s\n",
      "579:\tlearn: 0.3014303\ttotal: 9.84s\tremaining: 7.13s\n",
      "580:\tlearn: 0.3012022\ttotal: 9.86s\tremaining: 7.11s\n",
      "581:\tlearn: 0.3009553\ttotal: 9.87s\tremaining: 7.09s\n",
      "582:\tlearn: 0.3005404\ttotal: 9.9s\tremaining: 7.08s\n",
      "583:\tlearn: 0.3003447\ttotal: 9.92s\tremaining: 7.07s\n",
      "584:\tlearn: 0.3002079\ttotal: 9.94s\tremaining: 7.05s\n",
      "585:\tlearn: 0.3000231\ttotal: 9.96s\tremaining: 7.03s\n",
      "586:\tlearn: 0.2997669\ttotal: 9.98s\tremaining: 7.02s\n",
      "587:\tlearn: 0.2992765\ttotal: 10s\tremaining: 7s\n",
      "588:\tlearn: 0.2989334\ttotal: 10s\tremaining: 6.99s\n",
      "589:\tlearn: 0.2986041\ttotal: 10s\tremaining: 6.97s\n",
      "590:\tlearn: 0.2984604\ttotal: 10.1s\tremaining: 6.96s\n",
      "591:\tlearn: 0.2982096\ttotal: 10.1s\tremaining: 6.94s\n",
      "592:\tlearn: 0.2979867\ttotal: 10.1s\tremaining: 6.92s\n",
      "593:\tlearn: 0.2977941\ttotal: 10.1s\tremaining: 6.91s\n",
      "594:\tlearn: 0.2974641\ttotal: 10.1s\tremaining: 6.9s\n",
      "595:\tlearn: 0.2972071\ttotal: 10.2s\tremaining: 6.89s\n",
      "596:\tlearn: 0.2970199\ttotal: 10.2s\tremaining: 6.88s\n",
      "597:\tlearn: 0.2965970\ttotal: 10.2s\tremaining: 6.88s\n",
      "598:\tlearn: 0.2964244\ttotal: 10.2s\tremaining: 6.86s\n",
      "599:\tlearn: 0.2962068\ttotal: 10.3s\tremaining: 6.84s\n",
      "600:\tlearn: 0.2959698\ttotal: 10.3s\tremaining: 6.83s\n",
      "601:\tlearn: 0.2956859\ttotal: 10.3s\tremaining: 6.81s\n",
      "602:\tlearn: 0.2954981\ttotal: 10.3s\tremaining: 6.8s\n",
      "603:\tlearn: 0.2952598\ttotal: 10.4s\tremaining: 6.8s\n",
      "604:\tlearn: 0.2949429\ttotal: 10.4s\tremaining: 6.79s\n",
      "605:\tlearn: 0.2946469\ttotal: 10.4s\tremaining: 6.78s\n",
      "606:\tlearn: 0.2943103\ttotal: 10.5s\tremaining: 6.77s\n",
      "607:\tlearn: 0.2941243\ttotal: 10.5s\tremaining: 6.76s\n",
      "608:\tlearn: 0.2939145\ttotal: 10.5s\tremaining: 6.74s\n",
      "609:\tlearn: 0.2937165\ttotal: 10.5s\tremaining: 6.74s\n",
      "610:\tlearn: 0.2934762\ttotal: 10.6s\tremaining: 6.72s\n",
      "611:\tlearn: 0.2932206\ttotal: 10.6s\tremaining: 6.71s\n",
      "612:\tlearn: 0.2929422\ttotal: 10.6s\tremaining: 6.71s\n",
      "613:\tlearn: 0.2927050\ttotal: 10.6s\tremaining: 6.69s\n",
      "614:\tlearn: 0.2925534\ttotal: 10.7s\tremaining: 6.68s\n",
      "615:\tlearn: 0.2923999\ttotal: 10.7s\tremaining: 6.66s\n",
      "616:\tlearn: 0.2921995\ttotal: 10.7s\tremaining: 6.64s\n",
      "617:\tlearn: 0.2919810\ttotal: 10.7s\tremaining: 6.63s\n",
      "618:\tlearn: 0.2916429\ttotal: 10.7s\tremaining: 6.61s\n",
      "619:\tlearn: 0.2913425\ttotal: 10.8s\tremaining: 6.6s\n",
      "620:\tlearn: 0.2913250\ttotal: 10.8s\tremaining: 6.57s\n",
      "621:\tlearn: 0.2910881\ttotal: 10.8s\tremaining: 6.56s\n",
      "622:\tlearn: 0.2909068\ttotal: 10.8s\tremaining: 6.54s\n",
      "623:\tlearn: 0.2907048\ttotal: 10.8s\tremaining: 6.52s\n",
      "624:\tlearn: 0.2904720\ttotal: 10.8s\tremaining: 6.5s\n",
      "625:\tlearn: 0.2901386\ttotal: 10.9s\tremaining: 6.49s\n",
      "626:\tlearn: 0.2898736\ttotal: 10.9s\tremaining: 6.47s\n",
      "627:\tlearn: 0.2896853\ttotal: 10.9s\tremaining: 6.46s\n",
      "628:\tlearn: 0.2894653\ttotal: 10.9s\tremaining: 6.44s\n",
      "629:\tlearn: 0.2892799\ttotal: 10.9s\tremaining: 6.42s\n",
      "630:\tlearn: 0.2890183\ttotal: 10.9s\tremaining: 6.4s\n",
      "631:\tlearn: 0.2888392\ttotal: 11s\tremaining: 6.38s\n",
      "632:\tlearn: 0.2884760\ttotal: 11s\tremaining: 6.37s\n",
      "633:\tlearn: 0.2882041\ttotal: 11s\tremaining: 6.35s\n",
      "634:\tlearn: 0.2880815\ttotal: 11s\tremaining: 6.33s\n",
      "635:\tlearn: 0.2878518\ttotal: 11s\tremaining: 6.31s\n",
      "636:\tlearn: 0.2876996\ttotal: 11s\tremaining: 6.29s\n",
      "637:\tlearn: 0.2872891\ttotal: 11.1s\tremaining: 6.28s\n",
      "638:\tlearn: 0.2869765\ttotal: 11.1s\tremaining: 6.26s\n",
      "639:\tlearn: 0.2867096\ttotal: 11.1s\tremaining: 6.24s\n",
      "640:\tlearn: 0.2864788\ttotal: 11.1s\tremaining: 6.23s\n",
      "641:\tlearn: 0.2863218\ttotal: 11.1s\tremaining: 6.21s\n",
      "642:\tlearn: 0.2858545\ttotal: 11.1s\tremaining: 6.19s\n",
      "643:\tlearn: 0.2855940\ttotal: 11.2s\tremaining: 6.17s\n",
      "644:\tlearn: 0.2854682\ttotal: 11.2s\tremaining: 6.15s\n",
      "645:\tlearn: 0.2852632\ttotal: 11.2s\tremaining: 6.13s\n",
      "646:\tlearn: 0.2848369\ttotal: 11.2s\tremaining: 6.12s\n",
      "647:\tlearn: 0.2847067\ttotal: 11.2s\tremaining: 6.1s\n",
      "648:\tlearn: 0.2845796\ttotal: 11.3s\tremaining: 6.09s\n",
      "649:\tlearn: 0.2842565\ttotal: 11.3s\tremaining: 6.08s\n",
      "650:\tlearn: 0.2841220\ttotal: 11.3s\tremaining: 6.07s\n",
      "651:\tlearn: 0.2839463\ttotal: 11.3s\tremaining: 6.05s\n",
      "652:\tlearn: 0.2836881\ttotal: 11.4s\tremaining: 6.04s\n",
      "653:\tlearn: 0.2834817\ttotal: 11.4s\tremaining: 6.02s\n",
      "654:\tlearn: 0.2832702\ttotal: 11.4s\tremaining: 6s\n",
      "655:\tlearn: 0.2831395\ttotal: 11.5s\tremaining: 6.01s\n",
      "656:\tlearn: 0.2830052\ttotal: 11.5s\tremaining: 6s\n",
      "657:\tlearn: 0.2828398\ttotal: 11.5s\tremaining: 5.99s\n",
      "658:\tlearn: 0.2827571\ttotal: 11.5s\tremaining: 5.97s\n",
      "659:\tlearn: 0.2826354\ttotal: 11.6s\tremaining: 5.95s\n",
      "660:\tlearn: 0.2825088\ttotal: 11.6s\tremaining: 5.94s\n",
      "661:\tlearn: 0.2823063\ttotal: 11.6s\tremaining: 5.92s\n",
      "662:\tlearn: 0.2821185\ttotal: 11.6s\tremaining: 5.91s\n",
      "663:\tlearn: 0.2817464\ttotal: 11.6s\tremaining: 5.89s\n",
      "664:\tlearn: 0.2815658\ttotal: 11.7s\tremaining: 5.87s\n",
      "665:\tlearn: 0.2812887\ttotal: 11.7s\tremaining: 5.85s\n",
      "666:\tlearn: 0.2810229\ttotal: 11.7s\tremaining: 5.83s\n",
      "667:\tlearn: 0.2807976\ttotal: 11.7s\tremaining: 5.81s\n",
      "668:\tlearn: 0.2804497\ttotal: 11.7s\tremaining: 5.79s\n",
      "669:\tlearn: 0.2802566\ttotal: 11.7s\tremaining: 5.78s\n",
      "670:\tlearn: 0.2800876\ttotal: 11.7s\tremaining: 5.76s\n",
      "671:\tlearn: 0.2799425\ttotal: 11.8s\tremaining: 5.74s\n",
      "672:\tlearn: 0.2796184\ttotal: 11.8s\tremaining: 5.72s\n",
      "673:\tlearn: 0.2793916\ttotal: 11.8s\tremaining: 5.7s\n",
      "674:\tlearn: 0.2791227\ttotal: 11.8s\tremaining: 5.68s\n",
      "675:\tlearn: 0.2789590\ttotal: 11.8s\tremaining: 5.67s\n",
      "676:\tlearn: 0.2787812\ttotal: 11.8s\tremaining: 5.65s\n",
      "677:\tlearn: 0.2785945\ttotal: 11.9s\tremaining: 5.63s\n",
      "678:\tlearn: 0.2784304\ttotal: 11.9s\tremaining: 5.62s\n",
      "679:\tlearn: 0.2782102\ttotal: 11.9s\tremaining: 5.6s\n",
      "680:\tlearn: 0.2781148\ttotal: 11.9s\tremaining: 5.58s\n",
      "681:\tlearn: 0.2779869\ttotal: 11.9s\tremaining: 5.56s\n",
      "682:\tlearn: 0.2778063\ttotal: 11.9s\tremaining: 5.54s\n",
      "683:\tlearn: 0.2775828\ttotal: 11.9s\tremaining: 5.52s\n",
      "684:\tlearn: 0.2773465\ttotal: 12s\tremaining: 5.5s\n",
      "685:\tlearn: 0.2770333\ttotal: 12s\tremaining: 5.48s\n",
      "686:\tlearn: 0.2768244\ttotal: 12s\tremaining: 5.46s\n",
      "687:\tlearn: 0.2766735\ttotal: 12s\tremaining: 5.45s\n",
      "688:\tlearn: 0.2763059\ttotal: 12s\tremaining: 5.43s\n",
      "689:\tlearn: 0.2761490\ttotal: 12.1s\tremaining: 5.42s\n",
      "690:\tlearn: 0.2759124\ttotal: 12.1s\tremaining: 5.4s\n",
      "691:\tlearn: 0.2756355\ttotal: 12.1s\tremaining: 5.38s\n",
      "692:\tlearn: 0.2754326\ttotal: 12.1s\tremaining: 5.37s\n",
      "693:\tlearn: 0.2752642\ttotal: 12.1s\tremaining: 5.34s\n",
      "694:\tlearn: 0.2751563\ttotal: 12.1s\tremaining: 5.33s\n",
      "695:\tlearn: 0.2748204\ttotal: 12.2s\tremaining: 5.31s\n",
      "696:\tlearn: 0.2745657\ttotal: 12.2s\tremaining: 5.29s\n",
      "697:\tlearn: 0.2743183\ttotal: 12.2s\tremaining: 5.27s\n",
      "698:\tlearn: 0.2738943\ttotal: 12.2s\tremaining: 5.25s\n",
      "699:\tlearn: 0.2736749\ttotal: 12.2s\tremaining: 5.24s\n",
      "700:\tlearn: 0.2733829\ttotal: 12.2s\tremaining: 5.22s\n",
      "701:\tlearn: 0.2732049\ttotal: 12.2s\tremaining: 5.2s\n",
      "702:\tlearn: 0.2730267\ttotal: 12.3s\tremaining: 5.18s\n",
      "703:\tlearn: 0.2728657\ttotal: 12.3s\tremaining: 5.16s\n",
      "704:\tlearn: 0.2725826\ttotal: 12.3s\tremaining: 5.14s\n",
      "705:\tlearn: 0.2723766\ttotal: 12.3s\tremaining: 5.14s\n",
      "706:\tlearn: 0.2721512\ttotal: 12.4s\tremaining: 5.12s\n",
      "707:\tlearn: 0.2717676\ttotal: 12.4s\tremaining: 5.11s\n",
      "708:\tlearn: 0.2716036\ttotal: 12.4s\tremaining: 5.09s\n",
      "709:\tlearn: 0.2713677\ttotal: 12.4s\tremaining: 5.07s\n",
      "710:\tlearn: 0.2711198\ttotal: 12.4s\tremaining: 5.05s\n",
      "711:\tlearn: 0.2710363\ttotal: 12.4s\tremaining: 5.03s\n",
      "712:\tlearn: 0.2707641\ttotal: 12.5s\tremaining: 5.01s\n",
      "713:\tlearn: 0.2705531\ttotal: 12.5s\tremaining: 5s\n",
      "714:\tlearn: 0.2703529\ttotal: 12.5s\tremaining: 4.98s\n",
      "715:\tlearn: 0.2701156\ttotal: 12.5s\tremaining: 4.96s\n",
      "716:\tlearn: 0.2698484\ttotal: 12.5s\tremaining: 4.94s\n",
      "717:\tlearn: 0.2695724\ttotal: 12.5s\tremaining: 4.92s\n",
      "718:\tlearn: 0.2695189\ttotal: 12.5s\tremaining: 4.9s\n",
      "719:\tlearn: 0.2693239\ttotal: 12.6s\tremaining: 4.88s\n",
      "720:\tlearn: 0.2692129\ttotal: 12.6s\tremaining: 4.87s\n",
      "721:\tlearn: 0.2690300\ttotal: 12.6s\tremaining: 4.85s\n",
      "722:\tlearn: 0.2689109\ttotal: 12.6s\tremaining: 4.83s\n",
      "723:\tlearn: 0.2687014\ttotal: 12.6s\tremaining: 4.82s\n",
      "724:\tlearn: 0.2685688\ttotal: 12.6s\tremaining: 4.8s\n",
      "725:\tlearn: 0.2683603\ttotal: 12.7s\tremaining: 4.78s\n",
      "726:\tlearn: 0.2681500\ttotal: 12.7s\tremaining: 4.76s\n",
      "727:\tlearn: 0.2678293\ttotal: 12.7s\tremaining: 4.74s\n",
      "728:\tlearn: 0.2677104\ttotal: 12.7s\tremaining: 4.72s\n",
      "729:\tlearn: 0.2675133\ttotal: 12.7s\tremaining: 4.71s\n",
      "730:\tlearn: 0.2671993\ttotal: 12.7s\tremaining: 4.69s\n",
      "731:\tlearn: 0.2670350\ttotal: 12.8s\tremaining: 4.67s\n",
      "732:\tlearn: 0.2668263\ttotal: 12.8s\tremaining: 4.65s\n",
      "733:\tlearn: 0.2667525\ttotal: 12.8s\tremaining: 4.63s\n",
      "734:\tlearn: 0.2664699\ttotal: 12.8s\tremaining: 4.61s\n",
      "735:\tlearn: 0.2660289\ttotal: 12.8s\tremaining: 4.6s\n",
      "736:\tlearn: 0.2658048\ttotal: 12.8s\tremaining: 4.58s\n",
      "737:\tlearn: 0.2655954\ttotal: 12.9s\tremaining: 4.56s\n",
      "738:\tlearn: 0.2655080\ttotal: 12.9s\tremaining: 4.54s\n",
      "739:\tlearn: 0.2653034\ttotal: 12.9s\tremaining: 4.53s\n",
      "740:\tlearn: 0.2651459\ttotal: 12.9s\tremaining: 4.51s\n",
      "741:\tlearn: 0.2650287\ttotal: 12.9s\tremaining: 4.49s\n",
      "742:\tlearn: 0.2647898\ttotal: 12.9s\tremaining: 4.47s\n",
      "743:\tlearn: 0.2644466\ttotal: 12.9s\tremaining: 4.45s\n",
      "744:\tlearn: 0.2642813\ttotal: 13s\tremaining: 4.43s\n",
      "745:\tlearn: 0.2639579\ttotal: 13s\tremaining: 4.42s\n",
      "746:\tlearn: 0.2637847\ttotal: 13s\tremaining: 4.4s\n",
      "747:\tlearn: 0.2635698\ttotal: 13s\tremaining: 4.38s\n",
      "748:\tlearn: 0.2633970\ttotal: 13s\tremaining: 4.36s\n",
      "749:\tlearn: 0.2632239\ttotal: 13s\tremaining: 4.34s\n",
      "750:\tlearn: 0.2629904\ttotal: 13.1s\tremaining: 4.33s\n",
      "751:\tlearn: 0.2626921\ttotal: 13.1s\tremaining: 4.31s\n",
      "752:\tlearn: 0.2624853\ttotal: 13.1s\tremaining: 4.29s\n",
      "753:\tlearn: 0.2623077\ttotal: 13.1s\tremaining: 4.28s\n",
      "754:\tlearn: 0.2620806\ttotal: 13.1s\tremaining: 4.26s\n",
      "755:\tlearn: 0.2619545\ttotal: 13.1s\tremaining: 4.24s\n",
      "756:\tlearn: 0.2617373\ttotal: 13.1s\tremaining: 4.22s\n",
      "757:\tlearn: 0.2616047\ttotal: 13.2s\tremaining: 4.2s\n",
      "758:\tlearn: 0.2614466\ttotal: 13.2s\tremaining: 4.18s\n",
      "759:\tlearn: 0.2612058\ttotal: 13.2s\tremaining: 4.17s\n",
      "760:\tlearn: 0.2610073\ttotal: 13.2s\tremaining: 4.15s\n",
      "761:\tlearn: 0.2608964\ttotal: 13.2s\tremaining: 4.13s\n",
      "762:\tlearn: 0.2605380\ttotal: 13.2s\tremaining: 4.11s\n",
      "763:\tlearn: 0.2601728\ttotal: 13.3s\tremaining: 4.09s\n",
      "764:\tlearn: 0.2599064\ttotal: 13.3s\tremaining: 4.08s\n",
      "765:\tlearn: 0.2597241\ttotal: 13.3s\tremaining: 4.06s\n",
      "766:\tlearn: 0.2595363\ttotal: 13.3s\tremaining: 4.04s\n",
      "767:\tlearn: 0.2592840\ttotal: 13.3s\tremaining: 4.02s\n",
      "768:\tlearn: 0.2589998\ttotal: 13.3s\tremaining: 4.01s\n",
      "769:\tlearn: 0.2587616\ttotal: 13.4s\tremaining: 3.99s\n",
      "770:\tlearn: 0.2584570\ttotal: 13.4s\tremaining: 3.98s\n",
      "771:\tlearn: 0.2582389\ttotal: 13.4s\tremaining: 3.96s\n",
      "772:\tlearn: 0.2579284\ttotal: 13.4s\tremaining: 3.94s\n",
      "773:\tlearn: 0.2577389\ttotal: 13.4s\tremaining: 3.93s\n",
      "774:\tlearn: 0.2575305\ttotal: 13.5s\tremaining: 3.91s\n",
      "775:\tlearn: 0.2574270\ttotal: 13.5s\tremaining: 3.89s\n",
      "776:\tlearn: 0.2573438\ttotal: 13.5s\tremaining: 3.88s\n",
      "777:\tlearn: 0.2570941\ttotal: 13.5s\tremaining: 3.86s\n",
      "778:\tlearn: 0.2568890\ttotal: 13.5s\tremaining: 3.84s\n",
      "779:\tlearn: 0.2565678\ttotal: 13.6s\tremaining: 3.82s\n",
      "780:\tlearn: 0.2563848\ttotal: 13.6s\tremaining: 3.81s\n",
      "781:\tlearn: 0.2561104\ttotal: 13.6s\tremaining: 3.79s\n",
      "782:\tlearn: 0.2559224\ttotal: 13.7s\tremaining: 3.79s\n",
      "783:\tlearn: 0.2557538\ttotal: 13.7s\tremaining: 3.77s\n",
      "784:\tlearn: 0.2555505\ttotal: 13.7s\tremaining: 3.76s\n",
      "785:\tlearn: 0.2554120\ttotal: 13.7s\tremaining: 3.74s\n",
      "786:\tlearn: 0.2553056\ttotal: 13.8s\tremaining: 3.72s\n",
      "787:\tlearn: 0.2550444\ttotal: 13.8s\tremaining: 3.7s\n",
      "788:\tlearn: 0.2547742\ttotal: 13.8s\tremaining: 3.69s\n",
      "789:\tlearn: 0.2546617\ttotal: 13.8s\tremaining: 3.67s\n",
      "790:\tlearn: 0.2544095\ttotal: 13.8s\tremaining: 3.65s\n",
      "791:\tlearn: 0.2542712\ttotal: 13.8s\tremaining: 3.63s\n",
      "792:\tlearn: 0.2542194\ttotal: 13.9s\tremaining: 3.62s\n",
      "793:\tlearn: 0.2541120\ttotal: 13.9s\tremaining: 3.6s\n",
      "794:\tlearn: 0.2539574\ttotal: 13.9s\tremaining: 3.58s\n",
      "795:\tlearn: 0.2536857\ttotal: 13.9s\tremaining: 3.56s\n",
      "796:\tlearn: 0.2535615\ttotal: 13.9s\tremaining: 3.54s\n",
      "797:\tlearn: 0.2532298\ttotal: 13.9s\tremaining: 3.52s\n",
      "798:\tlearn: 0.2529328\ttotal: 13.9s\tremaining: 3.51s\n",
      "799:\tlearn: 0.2527391\ttotal: 14s\tremaining: 3.49s\n",
      "800:\tlearn: 0.2525280\ttotal: 14s\tremaining: 3.47s\n",
      "801:\tlearn: 0.2522507\ttotal: 14s\tremaining: 3.45s\n",
      "802:\tlearn: 0.2520174\ttotal: 14s\tremaining: 3.43s\n",
      "803:\tlearn: 0.2517676\ttotal: 14s\tremaining: 3.42s\n",
      "804:\tlearn: 0.2516463\ttotal: 14s\tremaining: 3.4s\n",
      "805:\tlearn: 0.2515253\ttotal: 14s\tremaining: 3.38s\n",
      "806:\tlearn: 0.2513150\ttotal: 14.1s\tremaining: 3.36s\n",
      "807:\tlearn: 0.2511319\ttotal: 14.1s\tremaining: 3.35s\n",
      "808:\tlearn: 0.2508726\ttotal: 14.1s\tremaining: 3.33s\n",
      "809:\tlearn: 0.2506881\ttotal: 14.1s\tremaining: 3.31s\n",
      "810:\tlearn: 0.2503499\ttotal: 14.1s\tremaining: 3.29s\n",
      "811:\tlearn: 0.2502137\ttotal: 14.2s\tremaining: 3.28s\n",
      "812:\tlearn: 0.2499579\ttotal: 14.2s\tremaining: 3.26s\n",
      "813:\tlearn: 0.2497075\ttotal: 14.2s\tremaining: 3.24s\n",
      "814:\tlearn: 0.2494965\ttotal: 14.2s\tremaining: 3.22s\n",
      "815:\tlearn: 0.2493779\ttotal: 14.2s\tremaining: 3.21s\n",
      "816:\tlearn: 0.2491947\ttotal: 14.2s\tremaining: 3.19s\n",
      "817:\tlearn: 0.2489627\ttotal: 14.3s\tremaining: 3.17s\n",
      "818:\tlearn: 0.2487715\ttotal: 14.3s\tremaining: 3.15s\n",
      "819:\tlearn: 0.2483953\ttotal: 14.3s\tremaining: 3.13s\n",
      "820:\tlearn: 0.2481218\ttotal: 14.3s\tremaining: 3.12s\n",
      "821:\tlearn: 0.2478638\ttotal: 14.3s\tremaining: 3.1s\n",
      "822:\tlearn: 0.2477588\ttotal: 14.3s\tremaining: 3.08s\n",
      "823:\tlearn: 0.2476141\ttotal: 14.4s\tremaining: 3.07s\n",
      "824:\tlearn: 0.2475034\ttotal: 14.4s\tremaining: 3.05s\n",
      "825:\tlearn: 0.2472754\ttotal: 14.4s\tremaining: 3.03s\n",
      "826:\tlearn: 0.2470065\ttotal: 14.4s\tremaining: 3.01s\n",
      "827:\tlearn: 0.2468254\ttotal: 14.4s\tremaining: 3s\n",
      "828:\tlearn: 0.2465937\ttotal: 14.5s\tremaining: 2.98s\n",
      "829:\tlearn: 0.2462661\ttotal: 14.5s\tremaining: 2.97s\n",
      "830:\tlearn: 0.2460903\ttotal: 14.5s\tremaining: 2.95s\n",
      "831:\tlearn: 0.2459585\ttotal: 14.5s\tremaining: 2.93s\n",
      "832:\tlearn: 0.2456912\ttotal: 14.5s\tremaining: 2.91s\n",
      "833:\tlearn: 0.2454485\ttotal: 14.6s\tremaining: 2.9s\n",
      "834:\tlearn: 0.2452364\ttotal: 14.6s\tremaining: 2.88s\n",
      "835:\tlearn: 0.2450736\ttotal: 14.6s\tremaining: 2.86s\n",
      "836:\tlearn: 0.2448719\ttotal: 14.6s\tremaining: 2.84s\n",
      "837:\tlearn: 0.2446642\ttotal: 14.6s\tremaining: 2.83s\n",
      "838:\tlearn: 0.2444137\ttotal: 14.6s\tremaining: 2.81s\n",
      "839:\tlearn: 0.2442289\ttotal: 14.6s\tremaining: 2.79s\n",
      "840:\tlearn: 0.2440833\ttotal: 14.7s\tremaining: 2.77s\n",
      "841:\tlearn: 0.2437903\ttotal: 14.7s\tremaining: 2.75s\n",
      "842:\tlearn: 0.2435301\ttotal: 14.7s\tremaining: 2.74s\n",
      "843:\tlearn: 0.2433323\ttotal: 14.7s\tremaining: 2.72s\n",
      "844:\tlearn: 0.2430818\ttotal: 14.7s\tremaining: 2.7s\n",
      "845:\tlearn: 0.2428975\ttotal: 14.7s\tremaining: 2.68s\n",
      "846:\tlearn: 0.2427622\ttotal: 14.7s\tremaining: 2.66s\n",
      "847:\tlearn: 0.2425965\ttotal: 14.8s\tremaining: 2.65s\n",
      "848:\tlearn: 0.2423453\ttotal: 14.8s\tremaining: 2.63s\n",
      "849:\tlearn: 0.2421684\ttotal: 14.8s\tremaining: 2.61s\n",
      "850:\tlearn: 0.2419848\ttotal: 14.8s\tremaining: 2.6s\n",
      "851:\tlearn: 0.2418328\ttotal: 14.8s\tremaining: 2.58s\n",
      "852:\tlearn: 0.2416095\ttotal: 14.9s\tremaining: 2.56s\n",
      "853:\tlearn: 0.2415253\ttotal: 14.9s\tremaining: 2.54s\n",
      "854:\tlearn: 0.2413630\ttotal: 14.9s\tremaining: 2.52s\n",
      "855:\tlearn: 0.2411053\ttotal: 14.9s\tremaining: 2.51s\n",
      "856:\tlearn: 0.2409471\ttotal: 14.9s\tremaining: 2.49s\n",
      "857:\tlearn: 0.2408686\ttotal: 14.9s\tremaining: 2.47s\n",
      "858:\tlearn: 0.2408053\ttotal: 14.9s\tremaining: 2.45s\n",
      "859:\tlearn: 0.2405698\ttotal: 15s\tremaining: 2.44s\n",
      "860:\tlearn: 0.2404075\ttotal: 15s\tremaining: 2.42s\n",
      "861:\tlearn: 0.2402847\ttotal: 15s\tremaining: 2.4s\n",
      "862:\tlearn: 0.2401830\ttotal: 15s\tremaining: 2.38s\n",
      "863:\tlearn: 0.2399725\ttotal: 15s\tremaining: 2.36s\n",
      "864:\tlearn: 0.2398434\ttotal: 15s\tremaining: 2.35s\n",
      "865:\tlearn: 0.2396181\ttotal: 15.1s\tremaining: 2.33s\n",
      "866:\tlearn: 0.2394294\ttotal: 15.1s\tremaining: 2.31s\n",
      "867:\tlearn: 0.2393126\ttotal: 15.1s\tremaining: 2.29s\n",
      "868:\tlearn: 0.2391593\ttotal: 15.1s\tremaining: 2.28s\n",
      "869:\tlearn: 0.2390591\ttotal: 15.1s\tremaining: 2.26s\n",
      "870:\tlearn: 0.2388615\ttotal: 15.1s\tremaining: 2.24s\n",
      "871:\tlearn: 0.2385646\ttotal: 15.2s\tremaining: 2.22s\n",
      "872:\tlearn: 0.2383468\ttotal: 15.2s\tremaining: 2.21s\n",
      "873:\tlearn: 0.2380812\ttotal: 15.2s\tremaining: 2.19s\n",
      "874:\tlearn: 0.2377513\ttotal: 15.2s\tremaining: 2.17s\n",
      "875:\tlearn: 0.2375326\ttotal: 15.2s\tremaining: 2.15s\n",
      "876:\tlearn: 0.2373878\ttotal: 15.2s\tremaining: 2.13s\n",
      "877:\tlearn: 0.2371812\ttotal: 15.3s\tremaining: 2.12s\n",
      "878:\tlearn: 0.2367663\ttotal: 15.3s\tremaining: 2.1s\n",
      "879:\tlearn: 0.2365939\ttotal: 15.3s\tremaining: 2.08s\n",
      "880:\tlearn: 0.2364351\ttotal: 15.3s\tremaining: 2.07s\n",
      "881:\tlearn: 0.2362244\ttotal: 15.3s\tremaining: 2.05s\n",
      "882:\tlearn: 0.2359859\ttotal: 15.3s\tremaining: 2.03s\n",
      "883:\tlearn: 0.2357871\ttotal: 15.4s\tremaining: 2.02s\n",
      "884:\tlearn: 0.2355584\ttotal: 15.4s\tremaining: 2s\n",
      "885:\tlearn: 0.2353665\ttotal: 15.4s\tremaining: 1.98s\n",
      "886:\tlearn: 0.2351782\ttotal: 15.4s\tremaining: 1.96s\n",
      "887:\tlearn: 0.2350530\ttotal: 15.4s\tremaining: 1.95s\n",
      "888:\tlearn: 0.2349957\ttotal: 15.5s\tremaining: 1.93s\n",
      "889:\tlearn: 0.2348718\ttotal: 15.5s\tremaining: 1.91s\n",
      "890:\tlearn: 0.2347126\ttotal: 15.5s\tremaining: 1.9s\n",
      "891:\tlearn: 0.2345276\ttotal: 15.5s\tremaining: 1.88s\n",
      "892:\tlearn: 0.2341736\ttotal: 15.5s\tremaining: 1.86s\n",
      "893:\tlearn: 0.2339828\ttotal: 15.6s\tremaining: 1.84s\n",
      "894:\tlearn: 0.2338299\ttotal: 15.6s\tremaining: 1.83s\n",
      "895:\tlearn: 0.2335845\ttotal: 15.6s\tremaining: 1.81s\n",
      "896:\tlearn: 0.2333421\ttotal: 15.7s\tremaining: 1.8s\n",
      "897:\tlearn: 0.2332137\ttotal: 15.7s\tremaining: 1.78s\n",
      "898:\tlearn: 0.2330308\ttotal: 15.7s\tremaining: 1.77s\n",
      "899:\tlearn: 0.2328265\ttotal: 15.7s\tremaining: 1.75s\n",
      "900:\tlearn: 0.2326965\ttotal: 15.8s\tremaining: 1.73s\n",
      "901:\tlearn: 0.2325805\ttotal: 15.8s\tremaining: 1.71s\n",
      "902:\tlearn: 0.2324085\ttotal: 15.8s\tremaining: 1.7s\n",
      "903:\tlearn: 0.2321130\ttotal: 15.8s\tremaining: 1.68s\n",
      "904:\tlearn: 0.2319151\ttotal: 15.8s\tremaining: 1.66s\n",
      "905:\tlearn: 0.2318469\ttotal: 15.8s\tremaining: 1.64s\n",
      "906:\tlearn: 0.2317135\ttotal: 15.9s\tremaining: 1.63s\n",
      "907:\tlearn: 0.2315827\ttotal: 15.9s\tremaining: 1.61s\n",
      "908:\tlearn: 0.2312996\ttotal: 15.9s\tremaining: 1.59s\n",
      "909:\tlearn: 0.2312324\ttotal: 15.9s\tremaining: 1.57s\n",
      "910:\tlearn: 0.2309682\ttotal: 15.9s\tremaining: 1.55s\n",
      "911:\tlearn: 0.2308211\ttotal: 15.9s\tremaining: 1.54s\n",
      "912:\tlearn: 0.2306217\ttotal: 16s\tremaining: 1.52s\n",
      "913:\tlearn: 0.2303646\ttotal: 16s\tremaining: 1.5s\n",
      "914:\tlearn: 0.2302220\ttotal: 16s\tremaining: 1.48s\n",
      "915:\tlearn: 0.2301139\ttotal: 16s\tremaining: 1.47s\n",
      "916:\tlearn: 0.2297515\ttotal: 16s\tremaining: 1.45s\n",
      "917:\tlearn: 0.2294773\ttotal: 16s\tremaining: 1.43s\n",
      "918:\tlearn: 0.2291699\ttotal: 16.1s\tremaining: 1.41s\n",
      "919:\tlearn: 0.2289384\ttotal: 16.1s\tremaining: 1.4s\n",
      "920:\tlearn: 0.2286761\ttotal: 16.1s\tremaining: 1.38s\n",
      "921:\tlearn: 0.2285304\ttotal: 16.1s\tremaining: 1.36s\n",
      "922:\tlearn: 0.2283561\ttotal: 16.1s\tremaining: 1.34s\n",
      "923:\tlearn: 0.2280995\ttotal: 16.1s\tremaining: 1.33s\n",
      "924:\tlearn: 0.2279095\ttotal: 16.1s\tremaining: 1.31s\n",
      "925:\tlearn: 0.2277247\ttotal: 16.2s\tremaining: 1.29s\n",
      "926:\tlearn: 0.2275005\ttotal: 16.2s\tremaining: 1.27s\n",
      "927:\tlearn: 0.2273535\ttotal: 16.2s\tremaining: 1.26s\n",
      "928:\tlearn: 0.2272213\ttotal: 16.2s\tremaining: 1.24s\n",
      "929:\tlearn: 0.2268804\ttotal: 16.2s\tremaining: 1.22s\n",
      "930:\tlearn: 0.2267588\ttotal: 16.2s\tremaining: 1.2s\n",
      "931:\tlearn: 0.2266319\ttotal: 16.3s\tremaining: 1.19s\n",
      "932:\tlearn: 0.2262656\ttotal: 16.3s\tremaining: 1.17s\n",
      "933:\tlearn: 0.2260132\ttotal: 16.3s\tremaining: 1.15s\n",
      "934:\tlearn: 0.2258633\ttotal: 16.3s\tremaining: 1.13s\n",
      "935:\tlearn: 0.2255908\ttotal: 16.3s\tremaining: 1.12s\n",
      "936:\tlearn: 0.2253220\ttotal: 16.3s\tremaining: 1.1s\n",
      "937:\tlearn: 0.2251881\ttotal: 16.4s\tremaining: 1.08s\n",
      "938:\tlearn: 0.2249838\ttotal: 16.4s\tremaining: 1.06s\n",
      "939:\tlearn: 0.2247224\ttotal: 16.4s\tremaining: 1.04s\n",
      "940:\tlearn: 0.2245546\ttotal: 16.4s\tremaining: 1.03s\n",
      "941:\tlearn: 0.2243725\ttotal: 16.4s\tremaining: 1.01s\n",
      "942:\tlearn: 0.2242291\ttotal: 16.4s\tremaining: 993ms\n",
      "943:\tlearn: 0.2240843\ttotal: 16.4s\tremaining: 976ms\n",
      "944:\tlearn: 0.2239044\ttotal: 16.5s\tremaining: 958ms\n",
      "945:\tlearn: 0.2238000\ttotal: 16.5s\tremaining: 941ms\n",
      "946:\tlearn: 0.2236229\ttotal: 16.5s\tremaining: 924ms\n",
      "947:\tlearn: 0.2234156\ttotal: 16.5s\tremaining: 908ms\n",
      "948:\tlearn: 0.2230915\ttotal: 16.6s\tremaining: 890ms\n",
      "949:\tlearn: 0.2229205\ttotal: 16.6s\tremaining: 873ms\n",
      "950:\tlearn: 0.2227394\ttotal: 16.6s\tremaining: 855ms\n",
      "951:\tlearn: 0.2224239\ttotal: 16.6s\tremaining: 838ms\n",
      "952:\tlearn: 0.2221105\ttotal: 16.6s\tremaining: 820ms\n",
      "953:\tlearn: 0.2218615\ttotal: 16.7s\tremaining: 803ms\n",
      "954:\tlearn: 0.2216869\ttotal: 16.7s\tremaining: 786ms\n",
      "955:\tlearn: 0.2214917\ttotal: 16.7s\tremaining: 768ms\n",
      "956:\tlearn: 0.2212982\ttotal: 16.8s\tremaining: 755ms\n",
      "957:\tlearn: 0.2211275\ttotal: 16.8s\tremaining: 738ms\n",
      "958:\tlearn: 0.2210018\ttotal: 16.8s\tremaining: 720ms\n",
      "959:\tlearn: 0.2208814\ttotal: 16.9s\tremaining: 703ms\n",
      "960:\tlearn: 0.2207425\ttotal: 16.9s\tremaining: 685ms\n",
      "961:\tlearn: 0.2206341\ttotal: 16.9s\tremaining: 667ms\n",
      "962:\tlearn: 0.2203650\ttotal: 16.9s\tremaining: 650ms\n",
      "963:\tlearn: 0.2201434\ttotal: 16.9s\tremaining: 632ms\n",
      "964:\tlearn: 0.2198502\ttotal: 16.9s\tremaining: 614ms\n",
      "965:\tlearn: 0.2196835\ttotal: 17s\tremaining: 597ms\n",
      "966:\tlearn: 0.2195889\ttotal: 17s\tremaining: 579ms\n",
      "967:\tlearn: 0.2194040\ttotal: 17s\tremaining: 561ms\n",
      "968:\tlearn: 0.2192378\ttotal: 17s\tremaining: 544ms\n",
      "969:\tlearn: 0.2190512\ttotal: 17s\tremaining: 526ms\n",
      "970:\tlearn: 0.2188868\ttotal: 17s\tremaining: 509ms\n",
      "971:\tlearn: 0.2186613\ttotal: 17.1s\tremaining: 491ms\n",
      "972:\tlearn: 0.2183439\ttotal: 17.1s\tremaining: 474ms\n",
      "973:\tlearn: 0.2181961\ttotal: 17.1s\tremaining: 456ms\n",
      "974:\tlearn: 0.2180329\ttotal: 17.1s\tremaining: 439ms\n",
      "975:\tlearn: 0.2178196\ttotal: 17.1s\tremaining: 421ms\n",
      "976:\tlearn: 0.2177046\ttotal: 17.1s\tremaining: 403ms\n",
      "977:\tlearn: 0.2175599\ttotal: 17.2s\tremaining: 386ms\n",
      "978:\tlearn: 0.2174887\ttotal: 17.2s\tremaining: 368ms\n",
      "979:\tlearn: 0.2173000\ttotal: 17.2s\tremaining: 351ms\n",
      "980:\tlearn: 0.2171652\ttotal: 17.2s\tremaining: 333ms\n",
      "981:\tlearn: 0.2170053\ttotal: 17.2s\tremaining: 316ms\n",
      "982:\tlearn: 0.2166452\ttotal: 17.2s\tremaining: 298ms\n",
      "983:\tlearn: 0.2165455\ttotal: 17.2s\tremaining: 280ms\n",
      "984:\tlearn: 0.2164006\ttotal: 17.3s\tremaining: 263ms\n",
      "985:\tlearn: 0.2161122\ttotal: 17.3s\tremaining: 246ms\n",
      "986:\tlearn: 0.2158737\ttotal: 17.3s\tremaining: 228ms\n",
      "987:\tlearn: 0.2156918\ttotal: 17.3s\tremaining: 210ms\n",
      "988:\tlearn: 0.2155128\ttotal: 17.3s\tremaining: 193ms\n",
      "989:\tlearn: 0.2153557\ttotal: 17.4s\tremaining: 175ms\n",
      "990:\tlearn: 0.2151612\ttotal: 17.4s\tremaining: 158ms\n",
      "991:\tlearn: 0.2150155\ttotal: 17.4s\tremaining: 140ms\n",
      "992:\tlearn: 0.2147965\ttotal: 17.4s\tremaining: 123ms\n",
      "993:\tlearn: 0.2146557\ttotal: 17.4s\tremaining: 105ms\n",
      "994:\tlearn: 0.2145207\ttotal: 17.4s\tremaining: 87.6ms\n",
      "995:\tlearn: 0.2144153\ttotal: 17.4s\tremaining: 70ms\n",
      "996:\tlearn: 0.2142107\ttotal: 17.5s\tremaining: 52.5ms\n",
      "997:\tlearn: 0.2140652\ttotal: 17.5s\tremaining: 35ms\n",
      "998:\tlearn: 0.2139418\ttotal: 17.5s\tremaining: 17.5ms\n",
      "999:\tlearn: 0.2136172\ttotal: 17.5s\tremaining: 0us\n",
      "Accuracy, fold_4: 0.8536585365853658\n",
      "Learning rate set to 0.00761\n",
      "0:\tlearn: 0.6894451\ttotal: 15.9ms\tremaining: 15.9s\n",
      "1:\tlearn: 0.6850382\ttotal: 32.1ms\tremaining: 16s\n",
      "2:\tlearn: 0.6809527\ttotal: 47.4ms\tremaining: 15.8s\n",
      "3:\tlearn: 0.6771250\ttotal: 61.7ms\tremaining: 15.4s\n",
      "4:\tlearn: 0.6732036\ttotal: 76ms\tremaining: 15.1s\n",
      "5:\tlearn: 0.6692027\ttotal: 90.3ms\tremaining: 15s\n",
      "6:\tlearn: 0.6654243\ttotal: 106ms\tremaining: 15s\n",
      "7:\tlearn: 0.6617559\ttotal: 121ms\tremaining: 15s\n",
      "8:\tlearn: 0.6580801\ttotal: 137ms\tremaining: 15.1s\n",
      "9:\tlearn: 0.6549106\ttotal: 153ms\tremaining: 15.2s\n",
      "10:\tlearn: 0.6512416\ttotal: 169ms\tremaining: 15.2s\n",
      "11:\tlearn: 0.6478647\ttotal: 195ms\tremaining: 16s\n",
      "12:\tlearn: 0.6446151\ttotal: 208ms\tremaining: 15.8s\n",
      "13:\tlearn: 0.6412848\ttotal: 223ms\tremaining: 15.7s\n",
      "14:\tlearn: 0.6381631\ttotal: 238ms\tremaining: 15.6s\n",
      "15:\tlearn: 0.6351853\ttotal: 256ms\tremaining: 15.7s\n",
      "16:\tlearn: 0.6322610\ttotal: 271ms\tremaining: 15.6s\n",
      "17:\tlearn: 0.6288269\ttotal: 285ms\tremaining: 15.5s\n",
      "18:\tlearn: 0.6257415\ttotal: 300ms\tremaining: 15.5s\n",
      "19:\tlearn: 0.6228800\ttotal: 319ms\tremaining: 15.6s\n",
      "20:\tlearn: 0.6198393\ttotal: 335ms\tremaining: 15.6s\n",
      "21:\tlearn: 0.6169555\ttotal: 356ms\tremaining: 15.8s\n",
      "22:\tlearn: 0.6138833\ttotal: 374ms\tremaining: 15.9s\n",
      "23:\tlearn: 0.6108380\ttotal: 389ms\tremaining: 15.8s\n",
      "24:\tlearn: 0.6077692\ttotal: 407ms\tremaining: 15.9s\n",
      "25:\tlearn: 0.6050018\ttotal: 431ms\tremaining: 16.2s\n",
      "26:\tlearn: 0.6023976\ttotal: 447ms\tremaining: 16.1s\n",
      "27:\tlearn: 0.5999183\ttotal: 464ms\tremaining: 16.1s\n",
      "28:\tlearn: 0.5972085\ttotal: 481ms\tremaining: 16.1s\n",
      "29:\tlearn: 0.5940588\ttotal: 496ms\tremaining: 16s\n",
      "30:\tlearn: 0.5913114\ttotal: 513ms\tremaining: 16s\n",
      "31:\tlearn: 0.5884574\ttotal: 529ms\tremaining: 16s\n",
      "32:\tlearn: 0.5858722\ttotal: 546ms\tremaining: 16s\n",
      "33:\tlearn: 0.5839123\ttotal: 550ms\tremaining: 15.6s\n",
      "34:\tlearn: 0.5815894\ttotal: 567ms\tremaining: 15.6s\n",
      "35:\tlearn: 0.5789166\ttotal: 581ms\tremaining: 15.6s\n",
      "36:\tlearn: 0.5765069\ttotal: 596ms\tremaining: 15.5s\n",
      "37:\tlearn: 0.5739087\ttotal: 610ms\tremaining: 15.4s\n",
      "38:\tlearn: 0.5714336\ttotal: 625ms\tremaining: 15.4s\n",
      "39:\tlearn: 0.5688527\ttotal: 639ms\tremaining: 15.3s\n",
      "40:\tlearn: 0.5665732\ttotal: 654ms\tremaining: 15.3s\n",
      "41:\tlearn: 0.5642084\ttotal: 678ms\tremaining: 15.5s\n",
      "42:\tlearn: 0.5621242\ttotal: 698ms\tremaining: 15.5s\n",
      "43:\tlearn: 0.5600185\ttotal: 720ms\tremaining: 15.6s\n",
      "44:\tlearn: 0.5578157\ttotal: 739ms\tremaining: 15.7s\n",
      "45:\tlearn: 0.5557632\ttotal: 758ms\tremaining: 15.7s\n",
      "46:\tlearn: 0.5535195\ttotal: 778ms\tremaining: 15.8s\n",
      "47:\tlearn: 0.5517122\ttotal: 817ms\tremaining: 16.2s\n",
      "48:\tlearn: 0.5500651\ttotal: 851ms\tremaining: 16.5s\n",
      "49:\tlearn: 0.5479905\ttotal: 870ms\tremaining: 16.5s\n",
      "50:\tlearn: 0.5460203\ttotal: 891ms\tremaining: 16.6s\n",
      "51:\tlearn: 0.5440295\ttotal: 910ms\tremaining: 16.6s\n",
      "52:\tlearn: 0.5420630\ttotal: 943ms\tremaining: 16.9s\n",
      "53:\tlearn: 0.5404277\ttotal: 959ms\tremaining: 16.8s\n",
      "54:\tlearn: 0.5386828\ttotal: 974ms\tremaining: 16.7s\n",
      "55:\tlearn: 0.5369386\ttotal: 991ms\tremaining: 16.7s\n",
      "56:\tlearn: 0.5354736\ttotal: 1.01s\tremaining: 16.6s\n",
      "57:\tlearn: 0.5337085\ttotal: 1.02s\tremaining: 16.6s\n",
      "58:\tlearn: 0.5315974\ttotal: 1.03s\tremaining: 16.5s\n",
      "59:\tlearn: 0.5295711\ttotal: 1.05s\tremaining: 16.4s\n",
      "60:\tlearn: 0.5278867\ttotal: 1.06s\tremaining: 16.4s\n",
      "61:\tlearn: 0.5260672\ttotal: 1.08s\tremaining: 16.3s\n",
      "62:\tlearn: 0.5245092\ttotal: 1.09s\tremaining: 16.2s\n",
      "63:\tlearn: 0.5224067\ttotal: 1.11s\tremaining: 16.2s\n",
      "64:\tlearn: 0.5207662\ttotal: 1.12s\tremaining: 16.2s\n",
      "65:\tlearn: 0.5192419\ttotal: 1.14s\tremaining: 16.1s\n",
      "66:\tlearn: 0.5175443\ttotal: 1.16s\tremaining: 16.1s\n",
      "67:\tlearn: 0.5158648\ttotal: 1.18s\tremaining: 16.2s\n",
      "68:\tlearn: 0.5141289\ttotal: 1.2s\tremaining: 16.2s\n",
      "69:\tlearn: 0.5125155\ttotal: 1.22s\tremaining: 16.1s\n",
      "70:\tlearn: 0.5111454\ttotal: 1.23s\tremaining: 16.1s\n",
      "71:\tlearn: 0.5098827\ttotal: 1.25s\tremaining: 16.1s\n",
      "72:\tlearn: 0.5083665\ttotal: 1.27s\tremaining: 16.1s\n",
      "73:\tlearn: 0.5067903\ttotal: 1.28s\tremaining: 16.1s\n",
      "74:\tlearn: 0.5052015\ttotal: 1.3s\tremaining: 16s\n",
      "75:\tlearn: 0.5038104\ttotal: 1.32s\tremaining: 16s\n",
      "76:\tlearn: 0.5023281\ttotal: 1.33s\tremaining: 16s\n",
      "77:\tlearn: 0.5010091\ttotal: 1.35s\tremaining: 15.9s\n",
      "78:\tlearn: 0.4994904\ttotal: 1.36s\tremaining: 15.9s\n",
      "79:\tlearn: 0.4984684\ttotal: 1.38s\tremaining: 15.9s\n",
      "80:\tlearn: 0.4971445\ttotal: 1.4s\tremaining: 15.8s\n",
      "81:\tlearn: 0.4961429\ttotal: 1.42s\tremaining: 15.9s\n",
      "82:\tlearn: 0.4950194\ttotal: 1.43s\tremaining: 15.8s\n",
      "83:\tlearn: 0.4934480\ttotal: 1.45s\tremaining: 15.8s\n",
      "84:\tlearn: 0.4920099\ttotal: 1.46s\tremaining: 15.8s\n",
      "85:\tlearn: 0.4906635\ttotal: 1.48s\tremaining: 15.7s\n",
      "86:\tlearn: 0.4892686\ttotal: 1.5s\tremaining: 15.7s\n",
      "87:\tlearn: 0.4882443\ttotal: 1.51s\tremaining: 15.7s\n",
      "88:\tlearn: 0.4875283\ttotal: 1.53s\tremaining: 15.6s\n",
      "89:\tlearn: 0.4861829\ttotal: 1.55s\tremaining: 15.6s\n",
      "90:\tlearn: 0.4850477\ttotal: 1.56s\tremaining: 15.6s\n",
      "91:\tlearn: 0.4836848\ttotal: 1.58s\tremaining: 15.6s\n",
      "92:\tlearn: 0.4826895\ttotal: 1.59s\tremaining: 15.5s\n",
      "93:\tlearn: 0.4816254\ttotal: 1.6s\tremaining: 15.5s\n",
      "94:\tlearn: 0.4806897\ttotal: 1.62s\tremaining: 15.4s\n",
      "95:\tlearn: 0.4798039\ttotal: 1.63s\tremaining: 15.4s\n",
      "96:\tlearn: 0.4786356\ttotal: 1.65s\tremaining: 15.3s\n",
      "97:\tlearn: 0.4774817\ttotal: 1.67s\tremaining: 15.4s\n",
      "98:\tlearn: 0.4764336\ttotal: 1.69s\tremaining: 15.3s\n",
      "99:\tlearn: 0.4751527\ttotal: 1.7s\tremaining: 15.3s\n",
      "100:\tlearn: 0.4739581\ttotal: 1.72s\tremaining: 15.3s\n",
      "101:\tlearn: 0.4730168\ttotal: 1.73s\tremaining: 15.2s\n",
      "102:\tlearn: 0.4720021\ttotal: 1.75s\tremaining: 15.2s\n",
      "103:\tlearn: 0.4709362\ttotal: 1.76s\tremaining: 15.2s\n",
      "104:\tlearn: 0.4700830\ttotal: 1.78s\tremaining: 15.2s\n",
      "105:\tlearn: 0.4689904\ttotal: 1.79s\tremaining: 15.1s\n",
      "106:\tlearn: 0.4678958\ttotal: 1.81s\tremaining: 15.1s\n",
      "107:\tlearn: 0.4673558\ttotal: 1.82s\tremaining: 15.1s\n",
      "108:\tlearn: 0.4661284\ttotal: 1.84s\tremaining: 15s\n",
      "109:\tlearn: 0.4652012\ttotal: 1.86s\tremaining: 15.1s\n",
      "110:\tlearn: 0.4641728\ttotal: 1.9s\tremaining: 15.2s\n",
      "111:\tlearn: 0.4633809\ttotal: 1.92s\tremaining: 15.3s\n",
      "112:\tlearn: 0.4624605\ttotal: 1.94s\tremaining: 15.2s\n",
      "113:\tlearn: 0.4615372\ttotal: 1.99s\tremaining: 15.5s\n",
      "114:\tlearn: 0.4609160\ttotal: 2.04s\tremaining: 15.7s\n",
      "115:\tlearn: 0.4599958\ttotal: 2.06s\tremaining: 15.7s\n",
      "116:\tlearn: 0.4594005\ttotal: 2.08s\tremaining: 15.7s\n",
      "117:\tlearn: 0.4584021\ttotal: 2.09s\tremaining: 15.6s\n",
      "118:\tlearn: 0.4576757\ttotal: 2.1s\tremaining: 15.6s\n",
      "119:\tlearn: 0.4571220\ttotal: 2.12s\tremaining: 15.5s\n",
      "120:\tlearn: 0.4565080\ttotal: 2.13s\tremaining: 15.5s\n",
      "121:\tlearn: 0.4556343\ttotal: 2.16s\tremaining: 15.5s\n",
      "122:\tlearn: 0.4544520\ttotal: 2.18s\tremaining: 15.5s\n",
      "123:\tlearn: 0.4532932\ttotal: 2.19s\tremaining: 15.5s\n",
      "124:\tlearn: 0.4524986\ttotal: 2.21s\tremaining: 15.5s\n",
      "125:\tlearn: 0.4513249\ttotal: 2.23s\tremaining: 15.4s\n",
      "126:\tlearn: 0.4507846\ttotal: 2.24s\tremaining: 15.4s\n",
      "127:\tlearn: 0.4500759\ttotal: 2.25s\tremaining: 15.4s\n",
      "128:\tlearn: 0.4491956\ttotal: 2.27s\tremaining: 15.3s\n",
      "129:\tlearn: 0.4485695\ttotal: 2.28s\tremaining: 15.3s\n",
      "130:\tlearn: 0.4480257\ttotal: 2.3s\tremaining: 15.3s\n",
      "131:\tlearn: 0.4473307\ttotal: 2.31s\tremaining: 15.2s\n",
      "132:\tlearn: 0.4465704\ttotal: 2.33s\tremaining: 15.2s\n",
      "133:\tlearn: 0.4457947\ttotal: 2.34s\tremaining: 15.2s\n",
      "134:\tlearn: 0.4448601\ttotal: 2.36s\tremaining: 15.1s\n",
      "135:\tlearn: 0.4440246\ttotal: 2.38s\tremaining: 15.1s\n",
      "136:\tlearn: 0.4433991\ttotal: 2.39s\tremaining: 15.1s\n",
      "137:\tlearn: 0.4430045\ttotal: 2.42s\tremaining: 15.1s\n",
      "138:\tlearn: 0.4423431\ttotal: 2.43s\tremaining: 15.1s\n",
      "139:\tlearn: 0.4416352\ttotal: 2.45s\tremaining: 15.1s\n",
      "140:\tlearn: 0.4409175\ttotal: 2.46s\tremaining: 15s\n",
      "141:\tlearn: 0.4403003\ttotal: 2.48s\tremaining: 15s\n",
      "142:\tlearn: 0.4397337\ttotal: 2.5s\tremaining: 15s\n",
      "143:\tlearn: 0.4391015\ttotal: 2.51s\tremaining: 14.9s\n",
      "144:\tlearn: 0.4381789\ttotal: 2.53s\tremaining: 14.9s\n",
      "145:\tlearn: 0.4377630\ttotal: 2.54s\tremaining: 14.9s\n",
      "146:\tlearn: 0.4372241\ttotal: 2.56s\tremaining: 14.8s\n",
      "147:\tlearn: 0.4366022\ttotal: 2.57s\tremaining: 14.8s\n",
      "148:\tlearn: 0.4357246\ttotal: 2.59s\tremaining: 14.8s\n",
      "149:\tlearn: 0.4349241\ttotal: 2.6s\tremaining: 14.8s\n",
      "150:\tlearn: 0.4340978\ttotal: 2.62s\tremaining: 14.7s\n",
      "151:\tlearn: 0.4333557\ttotal: 2.63s\tremaining: 14.7s\n",
      "152:\tlearn: 0.4324864\ttotal: 2.66s\tremaining: 14.7s\n",
      "153:\tlearn: 0.4320191\ttotal: 2.67s\tremaining: 14.7s\n",
      "154:\tlearn: 0.4314435\ttotal: 2.69s\tremaining: 14.6s\n",
      "155:\tlearn: 0.4310036\ttotal: 2.7s\tremaining: 14.6s\n",
      "156:\tlearn: 0.4305477\ttotal: 2.71s\tremaining: 14.6s\n",
      "157:\tlearn: 0.4299617\ttotal: 2.73s\tremaining: 14.6s\n",
      "158:\tlearn: 0.4290431\ttotal: 2.75s\tremaining: 14.5s\n",
      "159:\tlearn: 0.4285661\ttotal: 2.76s\tremaining: 14.5s\n",
      "160:\tlearn: 0.4282528\ttotal: 2.77s\tremaining: 14.4s\n",
      "161:\tlearn: 0.4276233\ttotal: 2.78s\tremaining: 14.4s\n",
      "162:\tlearn: 0.4272007\ttotal: 2.8s\tremaining: 14.4s\n",
      "163:\tlearn: 0.4263716\ttotal: 2.81s\tremaining: 14.3s\n",
      "164:\tlearn: 0.4259148\ttotal: 2.83s\tremaining: 14.3s\n",
      "165:\tlearn: 0.4252427\ttotal: 2.84s\tremaining: 14.3s\n",
      "166:\tlearn: 0.4244202\ttotal: 2.86s\tremaining: 14.3s\n",
      "167:\tlearn: 0.4237888\ttotal: 2.87s\tremaining: 14.2s\n",
      "168:\tlearn: 0.4231831\ttotal: 2.89s\tremaining: 14.2s\n",
      "169:\tlearn: 0.4225092\ttotal: 2.92s\tremaining: 14.3s\n",
      "170:\tlearn: 0.4217199\ttotal: 2.95s\tremaining: 14.3s\n",
      "171:\tlearn: 0.4213495\ttotal: 2.97s\tremaining: 14.3s\n",
      "172:\tlearn: 0.4209617\ttotal: 2.99s\tremaining: 14.3s\n",
      "173:\tlearn: 0.4204143\ttotal: 3.02s\tremaining: 14.3s\n",
      "174:\tlearn: 0.4199557\ttotal: 3.06s\tremaining: 14.4s\n",
      "175:\tlearn: 0.4193281\ttotal: 3.09s\tremaining: 14.5s\n",
      "176:\tlearn: 0.4188349\ttotal: 3.1s\tremaining: 14.4s\n",
      "177:\tlearn: 0.4184005\ttotal: 3.12s\tremaining: 14.4s\n",
      "178:\tlearn: 0.4180542\ttotal: 3.13s\tremaining: 14.4s\n",
      "179:\tlearn: 0.4176934\ttotal: 3.15s\tremaining: 14.4s\n",
      "180:\tlearn: 0.4171350\ttotal: 3.17s\tremaining: 14.3s\n",
      "181:\tlearn: 0.4165779\ttotal: 3.19s\tremaining: 14.3s\n",
      "182:\tlearn: 0.4161682\ttotal: 3.2s\tremaining: 14.3s\n",
      "183:\tlearn: 0.4155583\ttotal: 3.22s\tremaining: 14.3s\n",
      "184:\tlearn: 0.4153998\ttotal: 3.25s\tremaining: 14.3s\n",
      "185:\tlearn: 0.4149778\ttotal: 3.27s\tremaining: 14.3s\n",
      "186:\tlearn: 0.4145454\ttotal: 3.28s\tremaining: 14.3s\n",
      "187:\tlearn: 0.4142183\ttotal: 3.3s\tremaining: 14.3s\n",
      "188:\tlearn: 0.4139326\ttotal: 3.32s\tremaining: 14.2s\n",
      "189:\tlearn: 0.4133801\ttotal: 3.33s\tremaining: 14.2s\n",
      "190:\tlearn: 0.4130297\ttotal: 3.35s\tremaining: 14.2s\n",
      "191:\tlearn: 0.4126631\ttotal: 3.37s\tremaining: 14.2s\n",
      "192:\tlearn: 0.4120839\ttotal: 3.38s\tremaining: 14.1s\n",
      "193:\tlearn: 0.4115152\ttotal: 3.4s\tremaining: 14.1s\n",
      "194:\tlearn: 0.4111211\ttotal: 3.42s\tremaining: 14.1s\n",
      "195:\tlearn: 0.4107966\ttotal: 3.43s\tremaining: 14.1s\n",
      "196:\tlearn: 0.4103698\ttotal: 3.45s\tremaining: 14.1s\n",
      "197:\tlearn: 0.4099136\ttotal: 3.47s\tremaining: 14s\n",
      "198:\tlearn: 0.4092473\ttotal: 3.5s\tremaining: 14.1s\n",
      "199:\tlearn: 0.4088670\ttotal: 3.51s\tremaining: 14s\n",
      "200:\tlearn: 0.4083985\ttotal: 3.52s\tremaining: 14s\n",
      "201:\tlearn: 0.4080180\ttotal: 3.54s\tremaining: 14s\n",
      "202:\tlearn: 0.4074952\ttotal: 3.56s\tremaining: 14s\n",
      "203:\tlearn: 0.4070254\ttotal: 3.57s\tremaining: 13.9s\n",
      "204:\tlearn: 0.4065241\ttotal: 3.59s\tremaining: 13.9s\n",
      "205:\tlearn: 0.4059838\ttotal: 3.6s\tremaining: 13.9s\n",
      "206:\tlearn: 0.4055240\ttotal: 3.62s\tremaining: 13.9s\n",
      "207:\tlearn: 0.4051026\ttotal: 3.64s\tremaining: 13.8s\n",
      "208:\tlearn: 0.4046303\ttotal: 3.65s\tremaining: 13.8s\n",
      "209:\tlearn: 0.4039774\ttotal: 3.66s\tremaining: 13.8s\n",
      "210:\tlearn: 0.4034120\ttotal: 3.68s\tremaining: 13.8s\n",
      "211:\tlearn: 0.4029213\ttotal: 3.69s\tremaining: 13.7s\n",
      "212:\tlearn: 0.4025179\ttotal: 3.71s\tremaining: 13.7s\n",
      "213:\tlearn: 0.4020734\ttotal: 3.72s\tremaining: 13.7s\n",
      "214:\tlearn: 0.4014871\ttotal: 3.75s\tremaining: 13.7s\n",
      "215:\tlearn: 0.4010655\ttotal: 3.77s\tremaining: 13.7s\n",
      "216:\tlearn: 0.4007237\ttotal: 3.78s\tremaining: 13.6s\n",
      "217:\tlearn: 0.4002294\ttotal: 3.8s\tremaining: 13.6s\n",
      "218:\tlearn: 0.3998745\ttotal: 3.81s\tremaining: 13.6s\n",
      "219:\tlearn: 0.3996231\ttotal: 3.83s\tremaining: 13.6s\n",
      "220:\tlearn: 0.3992975\ttotal: 3.84s\tremaining: 13.5s\n",
      "221:\tlearn: 0.3990051\ttotal: 3.86s\tremaining: 13.5s\n",
      "222:\tlearn: 0.3984794\ttotal: 3.87s\tremaining: 13.5s\n",
      "223:\tlearn: 0.3980666\ttotal: 3.89s\tremaining: 13.5s\n",
      "224:\tlearn: 0.3975084\ttotal: 3.9s\tremaining: 13.4s\n",
      "225:\tlearn: 0.3969773\ttotal: 3.92s\tremaining: 13.4s\n",
      "226:\tlearn: 0.3963720\ttotal: 3.93s\tremaining: 13.4s\n",
      "227:\tlearn: 0.3956043\ttotal: 3.95s\tremaining: 13.4s\n",
      "228:\tlearn: 0.3951364\ttotal: 4s\tremaining: 13.5s\n",
      "229:\tlearn: 0.3947047\ttotal: 4.02s\tremaining: 13.5s\n",
      "230:\tlearn: 0.3944325\ttotal: 4.04s\tremaining: 13.4s\n",
      "231:\tlearn: 0.3940940\ttotal: 4.05s\tremaining: 13.4s\n",
      "232:\tlearn: 0.3937684\ttotal: 4.07s\tremaining: 13.4s\n",
      "233:\tlearn: 0.3933710\ttotal: 4.09s\tremaining: 13.4s\n",
      "234:\tlearn: 0.3928916\ttotal: 4.1s\tremaining: 13.4s\n",
      "235:\tlearn: 0.3924185\ttotal: 4.12s\tremaining: 13.3s\n",
      "236:\tlearn: 0.3920220\ttotal: 4.13s\tremaining: 13.3s\n",
      "237:\tlearn: 0.3917004\ttotal: 4.14s\tremaining: 13.3s\n",
      "238:\tlearn: 0.3912232\ttotal: 4.16s\tremaining: 13.2s\n",
      "239:\tlearn: 0.3909833\ttotal: 4.18s\tremaining: 13.2s\n",
      "240:\tlearn: 0.3904656\ttotal: 4.2s\tremaining: 13.2s\n",
      "241:\tlearn: 0.3899664\ttotal: 4.22s\tremaining: 13.2s\n",
      "242:\tlearn: 0.3894768\ttotal: 4.24s\tremaining: 13.2s\n",
      "243:\tlearn: 0.3891033\ttotal: 4.25s\tremaining: 13.2s\n",
      "244:\tlearn: 0.3886664\ttotal: 4.27s\tremaining: 13.2s\n",
      "245:\tlearn: 0.3882671\ttotal: 4.29s\tremaining: 13.1s\n",
      "246:\tlearn: 0.3879060\ttotal: 4.3s\tremaining: 13.1s\n",
      "247:\tlearn: 0.3874025\ttotal: 4.32s\tremaining: 13.1s\n",
      "248:\tlearn: 0.3870310\ttotal: 4.34s\tremaining: 13.1s\n",
      "249:\tlearn: 0.3867457\ttotal: 4.35s\tremaining: 13.1s\n",
      "250:\tlearn: 0.3864830\ttotal: 4.37s\tremaining: 13s\n",
      "251:\tlearn: 0.3861249\ttotal: 4.38s\tremaining: 13s\n",
      "252:\tlearn: 0.3856956\ttotal: 4.4s\tremaining: 13s\n",
      "253:\tlearn: 0.3852185\ttotal: 4.42s\tremaining: 13s\n",
      "254:\tlearn: 0.3848522\ttotal: 4.43s\tremaining: 12.9s\n",
      "255:\tlearn: 0.3844425\ttotal: 4.45s\tremaining: 12.9s\n",
      "256:\tlearn: 0.3839952\ttotal: 4.47s\tremaining: 12.9s\n",
      "257:\tlearn: 0.3834882\ttotal: 4.49s\tremaining: 12.9s\n",
      "258:\tlearn: 0.3831293\ttotal: 4.51s\tremaining: 12.9s\n",
      "259:\tlearn: 0.3828719\ttotal: 4.52s\tremaining: 12.9s\n",
      "260:\tlearn: 0.3822804\ttotal: 4.54s\tremaining: 12.8s\n",
      "261:\tlearn: 0.3818570\ttotal: 4.55s\tremaining: 12.8s\n",
      "262:\tlearn: 0.3815091\ttotal: 4.57s\tremaining: 12.8s\n",
      "263:\tlearn: 0.3809037\ttotal: 4.58s\tremaining: 12.8s\n",
      "264:\tlearn: 0.3804887\ttotal: 4.6s\tremaining: 12.8s\n",
      "265:\tlearn: 0.3800581\ttotal: 4.61s\tremaining: 12.7s\n",
      "266:\tlearn: 0.3794974\ttotal: 4.63s\tremaining: 12.7s\n",
      "267:\tlearn: 0.3791842\ttotal: 4.64s\tremaining: 12.7s\n",
      "268:\tlearn: 0.3789110\ttotal: 4.66s\tremaining: 12.7s\n",
      "269:\tlearn: 0.3786541\ttotal: 4.67s\tremaining: 12.6s\n",
      "270:\tlearn: 0.3780885\ttotal: 4.69s\tremaining: 12.6s\n",
      "271:\tlearn: 0.3777723\ttotal: 4.71s\tremaining: 12.6s\n",
      "272:\tlearn: 0.3774169\ttotal: 4.73s\tremaining: 12.6s\n",
      "273:\tlearn: 0.3770721\ttotal: 4.74s\tremaining: 12.6s\n",
      "274:\tlearn: 0.3769031\ttotal: 4.76s\tremaining: 12.5s\n",
      "275:\tlearn: 0.3765576\ttotal: 4.77s\tremaining: 12.5s\n",
      "276:\tlearn: 0.3760984\ttotal: 4.79s\tremaining: 12.5s\n",
      "277:\tlearn: 0.3756784\ttotal: 4.8s\tremaining: 12.5s\n",
      "278:\tlearn: 0.3753204\ttotal: 4.82s\tremaining: 12.5s\n",
      "279:\tlearn: 0.3749965\ttotal: 4.83s\tremaining: 12.4s\n",
      "280:\tlearn: 0.3744073\ttotal: 4.85s\tremaining: 12.4s\n",
      "281:\tlearn: 0.3740409\ttotal: 4.87s\tremaining: 12.4s\n",
      "282:\tlearn: 0.3737962\ttotal: 4.88s\tremaining: 12.4s\n",
      "283:\tlearn: 0.3735504\ttotal: 4.89s\tremaining: 12.3s\n",
      "284:\tlearn: 0.3731457\ttotal: 4.91s\tremaining: 12.3s\n",
      "285:\tlearn: 0.3728185\ttotal: 4.92s\tremaining: 12.3s\n",
      "286:\tlearn: 0.3725043\ttotal: 4.94s\tremaining: 12.3s\n",
      "287:\tlearn: 0.3722166\ttotal: 4.97s\tremaining: 12.3s\n",
      "288:\tlearn: 0.3718805\ttotal: 4.98s\tremaining: 12.3s\n",
      "289:\tlearn: 0.3715730\ttotal: 5s\tremaining: 12.2s\n",
      "290:\tlearn: 0.3712952\ttotal: 5.02s\tremaining: 12.2s\n",
      "291:\tlearn: 0.3708629\ttotal: 5.05s\tremaining: 12.3s\n",
      "292:\tlearn: 0.3704697\ttotal: 5.07s\tremaining: 12.2s\n",
      "293:\tlearn: 0.3700992\ttotal: 5.09s\tremaining: 12.2s\n",
      "294:\tlearn: 0.3697238\ttotal: 5.11s\tremaining: 12.2s\n",
      "295:\tlearn: 0.3693759\ttotal: 5.12s\tremaining: 12.2s\n",
      "296:\tlearn: 0.3690239\ttotal: 5.14s\tremaining: 12.2s\n",
      "297:\tlearn: 0.3686215\ttotal: 5.15s\tremaining: 12.1s\n",
      "298:\tlearn: 0.3682197\ttotal: 5.16s\tremaining: 12.1s\n",
      "299:\tlearn: 0.3679640\ttotal: 5.18s\tremaining: 12.1s\n",
      "300:\tlearn: 0.3675989\ttotal: 5.21s\tremaining: 12.1s\n",
      "301:\tlearn: 0.3672568\ttotal: 5.22s\tremaining: 12.1s\n",
      "302:\tlearn: 0.3667249\ttotal: 5.24s\tremaining: 12.1s\n",
      "303:\tlearn: 0.3662396\ttotal: 5.26s\tremaining: 12s\n",
      "304:\tlearn: 0.3658787\ttotal: 5.28s\tremaining: 12s\n",
      "305:\tlearn: 0.3656071\ttotal: 5.37s\tremaining: 12.2s\n",
      "306:\tlearn: 0.3651532\ttotal: 5.39s\tremaining: 12.2s\n",
      "307:\tlearn: 0.3648025\ttotal: 5.41s\tremaining: 12.2s\n",
      "308:\tlearn: 0.3643867\ttotal: 5.43s\tremaining: 12.1s\n",
      "309:\tlearn: 0.3641335\ttotal: 5.45s\tremaining: 12.1s\n",
      "310:\tlearn: 0.3638036\ttotal: 5.47s\tremaining: 12.1s\n",
      "311:\tlearn: 0.3635079\ttotal: 5.49s\tremaining: 12.1s\n",
      "312:\tlearn: 0.3632823\ttotal: 5.51s\tremaining: 12.1s\n",
      "313:\tlearn: 0.3628242\ttotal: 5.52s\tremaining: 12.1s\n",
      "314:\tlearn: 0.3625174\ttotal: 5.54s\tremaining: 12s\n",
      "315:\tlearn: 0.3620964\ttotal: 5.55s\tremaining: 12s\n",
      "316:\tlearn: 0.3615993\ttotal: 5.57s\tremaining: 12s\n",
      "317:\tlearn: 0.3612831\ttotal: 5.58s\tremaining: 12s\n",
      "318:\tlearn: 0.3611044\ttotal: 5.6s\tremaining: 11.9s\n",
      "319:\tlearn: 0.3608403\ttotal: 5.61s\tremaining: 11.9s\n",
      "320:\tlearn: 0.3604168\ttotal: 5.63s\tremaining: 11.9s\n",
      "321:\tlearn: 0.3599909\ttotal: 5.64s\tremaining: 11.9s\n",
      "322:\tlearn: 0.3596447\ttotal: 5.66s\tremaining: 11.9s\n",
      "323:\tlearn: 0.3593748\ttotal: 5.67s\tremaining: 11.8s\n",
      "324:\tlearn: 0.3590427\ttotal: 5.69s\tremaining: 11.8s\n",
      "325:\tlearn: 0.3587716\ttotal: 5.71s\tremaining: 11.8s\n",
      "326:\tlearn: 0.3583942\ttotal: 5.72s\tremaining: 11.8s\n",
      "327:\tlearn: 0.3581283\ttotal: 5.74s\tremaining: 11.8s\n",
      "328:\tlearn: 0.3577324\ttotal: 5.76s\tremaining: 11.7s\n",
      "329:\tlearn: 0.3573211\ttotal: 5.77s\tremaining: 11.7s\n",
      "330:\tlearn: 0.3568976\ttotal: 5.79s\tremaining: 11.7s\n",
      "331:\tlearn: 0.3563966\ttotal: 5.8s\tremaining: 11.7s\n",
      "332:\tlearn: 0.3561798\ttotal: 5.82s\tremaining: 11.7s\n",
      "333:\tlearn: 0.3557123\ttotal: 5.83s\tremaining: 11.6s\n",
      "334:\tlearn: 0.3554127\ttotal: 5.85s\tremaining: 11.6s\n",
      "335:\tlearn: 0.3551088\ttotal: 5.87s\tremaining: 11.6s\n",
      "336:\tlearn: 0.3548276\ttotal: 5.88s\tremaining: 11.6s\n",
      "337:\tlearn: 0.3543211\ttotal: 5.9s\tremaining: 11.6s\n",
      "338:\tlearn: 0.3542377\ttotal: 5.91s\tremaining: 11.5s\n",
      "339:\tlearn: 0.3538477\ttotal: 5.92s\tremaining: 11.5s\n",
      "340:\tlearn: 0.3533541\ttotal: 5.95s\tremaining: 11.5s\n",
      "341:\tlearn: 0.3531142\ttotal: 5.97s\tremaining: 11.5s\n",
      "342:\tlearn: 0.3527239\ttotal: 5.98s\tremaining: 11.5s\n",
      "343:\tlearn: 0.3524582\ttotal: 6s\tremaining: 11.4s\n",
      "344:\tlearn: 0.3520899\ttotal: 6.01s\tremaining: 11.4s\n",
      "345:\tlearn: 0.3517434\ttotal: 6.03s\tremaining: 11.4s\n",
      "346:\tlearn: 0.3513637\ttotal: 6.04s\tremaining: 11.4s\n",
      "347:\tlearn: 0.3510339\ttotal: 6.06s\tremaining: 11.4s\n",
      "348:\tlearn: 0.3508192\ttotal: 6.09s\tremaining: 11.4s\n",
      "349:\tlearn: 0.3504974\ttotal: 6.12s\tremaining: 11.4s\n",
      "350:\tlearn: 0.3500652\ttotal: 6.13s\tremaining: 11.3s\n",
      "351:\tlearn: 0.3497254\ttotal: 6.16s\tremaining: 11.3s\n",
      "352:\tlearn: 0.3494153\ttotal: 6.17s\tremaining: 11.3s\n",
      "353:\tlearn: 0.3490838\ttotal: 6.19s\tremaining: 11.3s\n",
      "354:\tlearn: 0.3487413\ttotal: 6.21s\tremaining: 11.3s\n",
      "355:\tlearn: 0.3483598\ttotal: 6.22s\tremaining: 11.3s\n",
      "356:\tlearn: 0.3481359\ttotal: 6.24s\tremaining: 11.2s\n",
      "357:\tlearn: 0.3479568\ttotal: 6.26s\tremaining: 11.2s\n",
      "358:\tlearn: 0.3476881\ttotal: 6.27s\tremaining: 11.2s\n",
      "359:\tlearn: 0.3473687\ttotal: 6.29s\tremaining: 11.2s\n",
      "360:\tlearn: 0.3472103\ttotal: 6.3s\tremaining: 11.2s\n",
      "361:\tlearn: 0.3469601\ttotal: 6.31s\tremaining: 11.1s\n",
      "362:\tlearn: 0.3466807\ttotal: 6.33s\tremaining: 11.1s\n",
      "363:\tlearn: 0.3462964\ttotal: 6.34s\tremaining: 11.1s\n",
      "364:\tlearn: 0.3460105\ttotal: 6.36s\tremaining: 11.1s\n",
      "365:\tlearn: 0.3454815\ttotal: 6.38s\tremaining: 11s\n",
      "366:\tlearn: 0.3451810\ttotal: 6.39s\tremaining: 11s\n",
      "367:\tlearn: 0.3449268\ttotal: 6.41s\tremaining: 11s\n",
      "368:\tlearn: 0.3445414\ttotal: 6.43s\tremaining: 11s\n",
      "369:\tlearn: 0.3442932\ttotal: 6.45s\tremaining: 11s\n",
      "370:\tlearn: 0.3438496\ttotal: 6.47s\tremaining: 11s\n",
      "371:\tlearn: 0.3437016\ttotal: 6.48s\tremaining: 10.9s\n",
      "372:\tlearn: 0.3433846\ttotal: 6.5s\tremaining: 10.9s\n",
      "373:\tlearn: 0.3430122\ttotal: 6.51s\tremaining: 10.9s\n",
      "374:\tlearn: 0.3427165\ttotal: 6.53s\tremaining: 10.9s\n",
      "375:\tlearn: 0.3424400\ttotal: 6.54s\tremaining: 10.9s\n",
      "376:\tlearn: 0.3421754\ttotal: 6.55s\tremaining: 10.8s\n",
      "377:\tlearn: 0.3418673\ttotal: 6.57s\tremaining: 10.8s\n",
      "378:\tlearn: 0.3415438\ttotal: 6.58s\tremaining: 10.8s\n",
      "379:\tlearn: 0.3412413\ttotal: 6.6s\tremaining: 10.8s\n",
      "380:\tlearn: 0.3409022\ttotal: 6.61s\tremaining: 10.7s\n",
      "381:\tlearn: 0.3406069\ttotal: 6.63s\tremaining: 10.7s\n",
      "382:\tlearn: 0.3403499\ttotal: 6.64s\tremaining: 10.7s\n",
      "383:\tlearn: 0.3400483\ttotal: 6.66s\tremaining: 10.7s\n",
      "384:\tlearn: 0.3397756\ttotal: 6.69s\tremaining: 10.7s\n",
      "385:\tlearn: 0.3395347\ttotal: 6.7s\tremaining: 10.7s\n",
      "386:\tlearn: 0.3394260\ttotal: 6.72s\tremaining: 10.6s\n",
      "387:\tlearn: 0.3390768\ttotal: 6.73s\tremaining: 10.6s\n",
      "388:\tlearn: 0.3387434\ttotal: 6.75s\tremaining: 10.6s\n",
      "389:\tlearn: 0.3385760\ttotal: 6.76s\tremaining: 10.6s\n",
      "390:\tlearn: 0.3383242\ttotal: 6.77s\tremaining: 10.6s\n",
      "391:\tlearn: 0.3380718\ttotal: 6.79s\tremaining: 10.5s\n",
      "392:\tlearn: 0.3378776\ttotal: 6.81s\tremaining: 10.5s\n",
      "393:\tlearn: 0.3375106\ttotal: 6.82s\tremaining: 10.5s\n",
      "394:\tlearn: 0.3372538\ttotal: 6.84s\tremaining: 10.5s\n",
      "395:\tlearn: 0.3369420\ttotal: 6.86s\tremaining: 10.5s\n",
      "396:\tlearn: 0.3368236\ttotal: 6.87s\tremaining: 10.4s\n",
      "397:\tlearn: 0.3366037\ttotal: 6.89s\tremaining: 10.4s\n",
      "398:\tlearn: 0.3363400\ttotal: 6.9s\tremaining: 10.4s\n",
      "399:\tlearn: 0.3361281\ttotal: 6.93s\tremaining: 10.4s\n",
      "400:\tlearn: 0.3358054\ttotal: 6.95s\tremaining: 10.4s\n",
      "401:\tlearn: 0.3355615\ttotal: 6.96s\tremaining: 10.4s\n",
      "402:\tlearn: 0.3353372\ttotal: 6.97s\tremaining: 10.3s\n",
      "403:\tlearn: 0.3349421\ttotal: 6.99s\tremaining: 10.3s\n",
      "404:\tlearn: 0.3347793\ttotal: 7s\tremaining: 10.3s\n",
      "405:\tlearn: 0.3344750\ttotal: 7.02s\tremaining: 10.3s\n",
      "406:\tlearn: 0.3341382\ttotal: 7.04s\tremaining: 10.3s\n",
      "407:\tlearn: 0.3339499\ttotal: 7.05s\tremaining: 10.2s\n",
      "408:\tlearn: 0.3335994\ttotal: 7.07s\tremaining: 10.2s\n",
      "409:\tlearn: 0.3333146\ttotal: 7.08s\tremaining: 10.2s\n",
      "410:\tlearn: 0.3331205\ttotal: 7.1s\tremaining: 10.2s\n",
      "411:\tlearn: 0.3328693\ttotal: 7.12s\tremaining: 10.2s\n",
      "412:\tlearn: 0.3327264\ttotal: 7.15s\tremaining: 10.2s\n",
      "413:\tlearn: 0.3325770\ttotal: 7.18s\tremaining: 10.2s\n",
      "414:\tlearn: 0.3322337\ttotal: 7.2s\tremaining: 10.2s\n",
      "415:\tlearn: 0.3319957\ttotal: 7.22s\tremaining: 10.1s\n",
      "416:\tlearn: 0.3317647\ttotal: 7.23s\tremaining: 10.1s\n",
      "417:\tlearn: 0.3315633\ttotal: 7.25s\tremaining: 10.1s\n",
      "418:\tlearn: 0.3313209\ttotal: 7.27s\tremaining: 10.1s\n",
      "419:\tlearn: 0.3309937\ttotal: 7.28s\tremaining: 10.1s\n",
      "420:\tlearn: 0.3308764\ttotal: 7.3s\tremaining: 10s\n",
      "421:\tlearn: 0.3305303\ttotal: 7.31s\tremaining: 10s\n",
      "422:\tlearn: 0.3302419\ttotal: 7.33s\tremaining: 9.99s\n",
      "423:\tlearn: 0.3296872\ttotal: 7.34s\tremaining: 9.97s\n",
      "424:\tlearn: 0.3294761\ttotal: 7.36s\tremaining: 9.96s\n",
      "425:\tlearn: 0.3291811\ttotal: 7.37s\tremaining: 9.94s\n",
      "426:\tlearn: 0.3290430\ttotal: 7.39s\tremaining: 9.91s\n",
      "427:\tlearn: 0.3284742\ttotal: 7.4s\tremaining: 9.89s\n",
      "428:\tlearn: 0.3282516\ttotal: 7.43s\tremaining: 9.89s\n",
      "429:\tlearn: 0.3279562\ttotal: 7.44s\tremaining: 9.87s\n",
      "430:\tlearn: 0.3277277\ttotal: 7.46s\tremaining: 9.85s\n",
      "431:\tlearn: 0.3274184\ttotal: 7.48s\tremaining: 9.83s\n",
      "432:\tlearn: 0.3271749\ttotal: 7.5s\tremaining: 9.81s\n",
      "433:\tlearn: 0.3268996\ttotal: 7.51s\tremaining: 9.8s\n",
      "434:\tlearn: 0.3267724\ttotal: 7.53s\tremaining: 9.78s\n",
      "435:\tlearn: 0.3264998\ttotal: 7.54s\tremaining: 9.76s\n",
      "436:\tlearn: 0.3261990\ttotal: 7.56s\tremaining: 9.74s\n",
      "437:\tlearn: 0.3258766\ttotal: 7.58s\tremaining: 9.72s\n",
      "438:\tlearn: 0.3254701\ttotal: 7.59s\tremaining: 9.7s\n",
      "439:\tlearn: 0.3250924\ttotal: 7.61s\tremaining: 9.68s\n",
      "440:\tlearn: 0.3249171\ttotal: 7.62s\tremaining: 9.66s\n",
      "441:\tlearn: 0.3246935\ttotal: 7.64s\tremaining: 9.64s\n",
      "442:\tlearn: 0.3244695\ttotal: 7.66s\tremaining: 9.63s\n",
      "443:\tlearn: 0.3241645\ttotal: 7.68s\tremaining: 9.61s\n",
      "444:\tlearn: 0.3239215\ttotal: 7.69s\tremaining: 9.6s\n",
      "445:\tlearn: 0.3236291\ttotal: 7.71s\tremaining: 9.57s\n",
      "446:\tlearn: 0.3234021\ttotal: 7.72s\tremaining: 9.55s\n",
      "447:\tlearn: 0.3230980\ttotal: 7.74s\tremaining: 9.53s\n",
      "448:\tlearn: 0.3227638\ttotal: 7.75s\tremaining: 9.51s\n",
      "449:\tlearn: 0.3223997\ttotal: 7.77s\tremaining: 9.49s\n",
      "450:\tlearn: 0.3221541\ttotal: 7.78s\tremaining: 9.48s\n",
      "451:\tlearn: 0.3217885\ttotal: 7.8s\tremaining: 9.45s\n",
      "452:\tlearn: 0.3215320\ttotal: 7.81s\tremaining: 9.44s\n",
      "453:\tlearn: 0.3213080\ttotal: 7.83s\tremaining: 9.42s\n",
      "454:\tlearn: 0.3211996\ttotal: 7.85s\tremaining: 9.4s\n",
      "455:\tlearn: 0.3210313\ttotal: 7.86s\tremaining: 9.38s\n",
      "456:\tlearn: 0.3206767\ttotal: 7.88s\tremaining: 9.36s\n",
      "457:\tlearn: 0.3204077\ttotal: 7.89s\tremaining: 9.34s\n",
      "458:\tlearn: 0.3199473\ttotal: 7.92s\tremaining: 9.33s\n",
      "459:\tlearn: 0.3197589\ttotal: 7.93s\tremaining: 9.31s\n",
      "460:\tlearn: 0.3194741\ttotal: 7.95s\tremaining: 9.29s\n",
      "461:\tlearn: 0.3191776\ttotal: 7.96s\tremaining: 9.27s\n",
      "462:\tlearn: 0.3189347\ttotal: 7.97s\tremaining: 9.25s\n",
      "463:\tlearn: 0.3185269\ttotal: 7.99s\tremaining: 9.23s\n",
      "464:\tlearn: 0.3182503\ttotal: 8s\tremaining: 9.21s\n",
      "465:\tlearn: 0.3179880\ttotal: 8.02s\tremaining: 9.19s\n",
      "466:\tlearn: 0.3175978\ttotal: 8.04s\tremaining: 9.17s\n",
      "467:\tlearn: 0.3174054\ttotal: 8.05s\tremaining: 9.15s\n",
      "468:\tlearn: 0.3171205\ttotal: 8.07s\tremaining: 9.13s\n",
      "469:\tlearn: 0.3168481\ttotal: 8.08s\tremaining: 9.12s\n",
      "470:\tlearn: 0.3165455\ttotal: 8.1s\tremaining: 9.1s\n",
      "471:\tlearn: 0.3161800\ttotal: 8.12s\tremaining: 9.08s\n",
      "472:\tlearn: 0.3159343\ttotal: 8.13s\tremaining: 9.06s\n",
      "473:\tlearn: 0.3157199\ttotal: 8.16s\tremaining: 9.05s\n",
      "474:\tlearn: 0.3155031\ttotal: 8.17s\tremaining: 9.03s\n",
      "475:\tlearn: 0.3151075\ttotal: 8.19s\tremaining: 9.02s\n",
      "476:\tlearn: 0.3147633\ttotal: 8.22s\tremaining: 9.02s\n",
      "477:\tlearn: 0.3144794\ttotal: 8.24s\tremaining: 9s\n",
      "478:\tlearn: 0.3142424\ttotal: 8.26s\tremaining: 8.98s\n",
      "479:\tlearn: 0.3140764\ttotal: 8.28s\tremaining: 8.96s\n",
      "480:\tlearn: 0.3139030\ttotal: 8.29s\tremaining: 8.95s\n",
      "481:\tlearn: 0.3136938\ttotal: 8.37s\tremaining: 8.99s\n",
      "482:\tlearn: 0.3135070\ttotal: 8.41s\tremaining: 9.01s\n",
      "483:\tlearn: 0.3132998\ttotal: 8.43s\tremaining: 8.99s\n",
      "484:\tlearn: 0.3131095\ttotal: 8.45s\tremaining: 8.97s\n",
      "485:\tlearn: 0.3127934\ttotal: 8.46s\tremaining: 8.95s\n",
      "486:\tlearn: 0.3124170\ttotal: 8.48s\tremaining: 8.93s\n",
      "487:\tlearn: 0.3122095\ttotal: 8.49s\tremaining: 8.91s\n",
      "488:\tlearn: 0.3119027\ttotal: 8.51s\tremaining: 8.89s\n",
      "489:\tlearn: 0.3115887\ttotal: 8.52s\tremaining: 8.87s\n",
      "490:\tlearn: 0.3114301\ttotal: 8.54s\tremaining: 8.85s\n",
      "491:\tlearn: 0.3113053\ttotal: 8.55s\tremaining: 8.83s\n",
      "492:\tlearn: 0.3109836\ttotal: 8.57s\tremaining: 8.81s\n",
      "493:\tlearn: 0.3106639\ttotal: 8.58s\tremaining: 8.79s\n",
      "494:\tlearn: 0.3104933\ttotal: 8.6s\tremaining: 8.77s\n",
      "495:\tlearn: 0.3101293\ttotal: 8.61s\tremaining: 8.75s\n",
      "496:\tlearn: 0.3099378\ttotal: 8.63s\tremaining: 8.73s\n",
      "497:\tlearn: 0.3096401\ttotal: 8.65s\tremaining: 8.72s\n",
      "498:\tlearn: 0.3093940\ttotal: 8.66s\tremaining: 8.7s\n",
      "499:\tlearn: 0.3091330\ttotal: 8.68s\tremaining: 8.68s\n",
      "500:\tlearn: 0.3088439\ttotal: 8.7s\tremaining: 8.66s\n",
      "501:\tlearn: 0.3087238\ttotal: 8.71s\tremaining: 8.64s\n",
      "502:\tlearn: 0.3084807\ttotal: 8.73s\tremaining: 8.63s\n",
      "503:\tlearn: 0.3081811\ttotal: 8.75s\tremaining: 8.61s\n",
      "504:\tlearn: 0.3080755\ttotal: 8.77s\tremaining: 8.6s\n",
      "505:\tlearn: 0.3078160\ttotal: 8.79s\tremaining: 8.58s\n",
      "506:\tlearn: 0.3075687\ttotal: 8.8s\tremaining: 8.56s\n",
      "507:\tlearn: 0.3072568\ttotal: 8.82s\tremaining: 8.54s\n",
      "508:\tlearn: 0.3070490\ttotal: 8.84s\tremaining: 8.53s\n",
      "509:\tlearn: 0.3068560\ttotal: 8.86s\tremaining: 8.51s\n",
      "510:\tlearn: 0.3067051\ttotal: 8.87s\tremaining: 8.49s\n",
      "511:\tlearn: 0.3063823\ttotal: 8.9s\tremaining: 8.48s\n",
      "512:\tlearn: 0.3060683\ttotal: 8.92s\tremaining: 8.47s\n",
      "513:\tlearn: 0.3058787\ttotal: 8.94s\tremaining: 8.45s\n",
      "514:\tlearn: 0.3055513\ttotal: 8.95s\tremaining: 8.43s\n",
      "515:\tlearn: 0.3054095\ttotal: 8.97s\tremaining: 8.41s\n",
      "516:\tlearn: 0.3051773\ttotal: 8.99s\tremaining: 8.4s\n",
      "517:\tlearn: 0.3048831\ttotal: 9s\tremaining: 8.38s\n",
      "518:\tlearn: 0.3044983\ttotal: 9.02s\tremaining: 8.36s\n",
      "519:\tlearn: 0.3043443\ttotal: 9.04s\tremaining: 8.34s\n",
      "520:\tlearn: 0.3042276\ttotal: 9.06s\tremaining: 8.33s\n",
      "521:\tlearn: 0.3039324\ttotal: 9.07s\tremaining: 8.31s\n",
      "522:\tlearn: 0.3037401\ttotal: 9.09s\tremaining: 8.29s\n",
      "523:\tlearn: 0.3035358\ttotal: 9.11s\tremaining: 8.28s\n",
      "524:\tlearn: 0.3034282\ttotal: 9.13s\tremaining: 8.27s\n",
      "525:\tlearn: 0.3032070\ttotal: 9.15s\tremaining: 8.25s\n",
      "526:\tlearn: 0.3030208\ttotal: 9.17s\tremaining: 8.23s\n",
      "527:\tlearn: 0.3028062\ttotal: 9.18s\tremaining: 8.21s\n",
      "528:\tlearn: 0.3026242\ttotal: 9.2s\tremaining: 8.19s\n",
      "529:\tlearn: 0.3022589\ttotal: 9.21s\tremaining: 8.17s\n",
      "530:\tlearn: 0.3020914\ttotal: 9.23s\tremaining: 8.15s\n",
      "531:\tlearn: 0.3018818\ttotal: 9.25s\tremaining: 8.14s\n",
      "532:\tlearn: 0.3015308\ttotal: 9.29s\tremaining: 8.14s\n",
      "533:\tlearn: 0.3012978\ttotal: 9.31s\tremaining: 8.12s\n",
      "534:\tlearn: 0.3009721\ttotal: 9.33s\tremaining: 8.11s\n",
      "535:\tlearn: 0.3007290\ttotal: 9.35s\tremaining: 8.09s\n",
      "536:\tlearn: 0.3004625\ttotal: 9.36s\tremaining: 8.07s\n",
      "537:\tlearn: 0.3001790\ttotal: 9.39s\tremaining: 8.06s\n",
      "538:\tlearn: 0.2999108\ttotal: 9.41s\tremaining: 8.05s\n",
      "539:\tlearn: 0.2996798\ttotal: 9.42s\tremaining: 8.03s\n",
      "540:\tlearn: 0.2994811\ttotal: 9.44s\tremaining: 8.01s\n",
      "541:\tlearn: 0.2992258\ttotal: 9.45s\tremaining: 7.99s\n",
      "542:\tlearn: 0.2990384\ttotal: 9.47s\tremaining: 7.97s\n",
      "543:\tlearn: 0.2987700\ttotal: 9.48s\tremaining: 7.95s\n",
      "544:\tlearn: 0.2985199\ttotal: 9.5s\tremaining: 7.93s\n",
      "545:\tlearn: 0.2983534\ttotal: 9.51s\tremaining: 7.91s\n",
      "546:\tlearn: 0.2980019\ttotal: 9.53s\tremaining: 7.89s\n",
      "547:\tlearn: 0.2978707\ttotal: 9.55s\tremaining: 7.88s\n",
      "548:\tlearn: 0.2976935\ttotal: 9.56s\tremaining: 7.86s\n",
      "549:\tlearn: 0.2975250\ttotal: 9.58s\tremaining: 7.84s\n",
      "550:\tlearn: 0.2972861\ttotal: 9.6s\tremaining: 7.82s\n",
      "551:\tlearn: 0.2970113\ttotal: 9.61s\tremaining: 7.8s\n",
      "552:\tlearn: 0.2967838\ttotal: 9.63s\tremaining: 7.78s\n",
      "553:\tlearn: 0.2965272\ttotal: 9.64s\tremaining: 7.76s\n",
      "554:\tlearn: 0.2962345\ttotal: 9.66s\tremaining: 7.74s\n",
      "555:\tlearn: 0.2958117\ttotal: 9.67s\tremaining: 7.72s\n",
      "556:\tlearn: 0.2955735\ttotal: 9.69s\tremaining: 7.71s\n",
      "557:\tlearn: 0.2952845\ttotal: 9.7s\tremaining: 7.68s\n",
      "558:\tlearn: 0.2950946\ttotal: 9.72s\tremaining: 7.67s\n",
      "559:\tlearn: 0.2948783\ttotal: 9.73s\tremaining: 7.65s\n",
      "560:\tlearn: 0.2946463\ttotal: 9.74s\tremaining: 7.63s\n",
      "561:\tlearn: 0.2943407\ttotal: 9.76s\tremaining: 7.61s\n",
      "562:\tlearn: 0.2942296\ttotal: 9.77s\tremaining: 7.59s\n",
      "563:\tlearn: 0.2940497\ttotal: 9.8s\tremaining: 7.58s\n",
      "564:\tlearn: 0.2938726\ttotal: 9.82s\tremaining: 7.56s\n",
      "565:\tlearn: 0.2935451\ttotal: 9.84s\tremaining: 7.54s\n",
      "566:\tlearn: 0.2933346\ttotal: 9.85s\tremaining: 7.52s\n",
      "567:\tlearn: 0.2932186\ttotal: 9.87s\tremaining: 7.5s\n",
      "568:\tlearn: 0.2931096\ttotal: 9.88s\tremaining: 7.49s\n",
      "569:\tlearn: 0.2929754\ttotal: 9.89s\tremaining: 7.46s\n",
      "570:\tlearn: 0.2928637\ttotal: 9.91s\tremaining: 7.45s\n",
      "571:\tlearn: 0.2926855\ttotal: 9.92s\tremaining: 7.42s\n",
      "572:\tlearn: 0.2925061\ttotal: 9.94s\tremaining: 7.41s\n",
      "573:\tlearn: 0.2923153\ttotal: 9.96s\tremaining: 7.39s\n",
      "574:\tlearn: 0.2921649\ttotal: 9.97s\tremaining: 7.37s\n",
      "575:\tlearn: 0.2918867\ttotal: 9.98s\tremaining: 7.35s\n",
      "576:\tlearn: 0.2915200\ttotal: 10s\tremaining: 7.33s\n",
      "577:\tlearn: 0.2913693\ttotal: 10s\tremaining: 7.31s\n",
      "578:\tlearn: 0.2911211\ttotal: 10s\tremaining: 7.3s\n",
      "579:\tlearn: 0.2908798\ttotal: 10.1s\tremaining: 7.29s\n",
      "580:\tlearn: 0.2907148\ttotal: 10.1s\tremaining: 7.26s\n",
      "581:\tlearn: 0.2903690\ttotal: 10.1s\tremaining: 7.25s\n",
      "582:\tlearn: 0.2901310\ttotal: 10.1s\tremaining: 7.23s\n",
      "583:\tlearn: 0.2899319\ttotal: 10.1s\tremaining: 7.21s\n",
      "584:\tlearn: 0.2896578\ttotal: 10.1s\tremaining: 7.19s\n",
      "585:\tlearn: 0.2893085\ttotal: 10.1s\tremaining: 7.17s\n",
      "586:\tlearn: 0.2890400\ttotal: 10.2s\tremaining: 7.15s\n",
      "587:\tlearn: 0.2887479\ttotal: 10.2s\tremaining: 7.13s\n",
      "588:\tlearn: 0.2885332\ttotal: 10.2s\tremaining: 7.11s\n",
      "589:\tlearn: 0.2882287\ttotal: 10.2s\tremaining: 7.09s\n",
      "590:\tlearn: 0.2879778\ttotal: 10.2s\tremaining: 7.08s\n",
      "591:\tlearn: 0.2876695\ttotal: 10.3s\tremaining: 7.07s\n",
      "592:\tlearn: 0.2875048\ttotal: 10.3s\tremaining: 7.07s\n",
      "593:\tlearn: 0.2873285\ttotal: 10.3s\tremaining: 7.05s\n",
      "594:\tlearn: 0.2871565\ttotal: 10.3s\tremaining: 7.03s\n",
      "595:\tlearn: 0.2869863\ttotal: 10.3s\tremaining: 7.01s\n",
      "596:\tlearn: 0.2867512\ttotal: 10.4s\tremaining: 7s\n",
      "597:\tlearn: 0.2865083\ttotal: 10.4s\tremaining: 6.98s\n",
      "598:\tlearn: 0.2863595\ttotal: 10.4s\tremaining: 6.96s\n",
      "599:\tlearn: 0.2861414\ttotal: 10.4s\tremaining: 6.94s\n",
      "600:\tlearn: 0.2859327\ttotal: 10.4s\tremaining: 6.92s\n",
      "601:\tlearn: 0.2856680\ttotal: 10.4s\tremaining: 6.9s\n",
      "602:\tlearn: 0.2855608\ttotal: 10.5s\tremaining: 6.88s\n",
      "603:\tlearn: 0.2853292\ttotal: 10.5s\tremaining: 6.86s\n",
      "604:\tlearn: 0.2850660\ttotal: 10.5s\tremaining: 6.84s\n",
      "605:\tlearn: 0.2848379\ttotal: 10.5s\tremaining: 6.83s\n",
      "606:\tlearn: 0.2845024\ttotal: 10.5s\tremaining: 6.81s\n",
      "607:\tlearn: 0.2842288\ttotal: 10.5s\tremaining: 6.79s\n",
      "608:\tlearn: 0.2838743\ttotal: 10.6s\tremaining: 6.77s\n",
      "609:\tlearn: 0.2836193\ttotal: 10.6s\tremaining: 6.75s\n",
      "610:\tlearn: 0.2833992\ttotal: 10.6s\tremaining: 6.74s\n",
      "611:\tlearn: 0.2831456\ttotal: 10.6s\tremaining: 6.72s\n",
      "612:\tlearn: 0.2829807\ttotal: 10.6s\tremaining: 6.7s\n",
      "613:\tlearn: 0.2828297\ttotal: 10.6s\tremaining: 6.68s\n",
      "614:\tlearn: 0.2826382\ttotal: 10.6s\tremaining: 6.66s\n",
      "615:\tlearn: 0.2823698\ttotal: 10.7s\tremaining: 6.65s\n",
      "616:\tlearn: 0.2821394\ttotal: 10.7s\tremaining: 6.63s\n",
      "617:\tlearn: 0.2819219\ttotal: 10.7s\tremaining: 6.61s\n",
      "618:\tlearn: 0.2816634\ttotal: 10.7s\tremaining: 6.59s\n",
      "619:\tlearn: 0.2813521\ttotal: 10.7s\tremaining: 6.57s\n",
      "620:\tlearn: 0.2811338\ttotal: 10.7s\tremaining: 6.55s\n",
      "621:\tlearn: 0.2809774\ttotal: 10.7s\tremaining: 6.53s\n",
      "622:\tlearn: 0.2808230\ttotal: 10.8s\tremaining: 6.51s\n",
      "623:\tlearn: 0.2806412\ttotal: 10.8s\tremaining: 6.5s\n",
      "624:\tlearn: 0.2804652\ttotal: 10.8s\tremaining: 6.48s\n",
      "625:\tlearn: 0.2803184\ttotal: 10.8s\tremaining: 6.46s\n",
      "626:\tlearn: 0.2800782\ttotal: 10.8s\tremaining: 6.45s\n",
      "627:\tlearn: 0.2798473\ttotal: 10.9s\tremaining: 6.43s\n",
      "628:\tlearn: 0.2796742\ttotal: 10.9s\tremaining: 6.41s\n",
      "629:\tlearn: 0.2794933\ttotal: 10.9s\tremaining: 6.39s\n",
      "630:\tlearn: 0.2793913\ttotal: 10.9s\tremaining: 6.38s\n",
      "631:\tlearn: 0.2790873\ttotal: 10.9s\tremaining: 6.36s\n",
      "632:\tlearn: 0.2787809\ttotal: 10.9s\tremaining: 6.34s\n",
      "633:\tlearn: 0.2784771\ttotal: 11s\tremaining: 6.32s\n",
      "634:\tlearn: 0.2782116\ttotal: 11s\tremaining: 6.31s\n",
      "635:\tlearn: 0.2780952\ttotal: 11s\tremaining: 6.29s\n",
      "636:\tlearn: 0.2778428\ttotal: 11s\tremaining: 6.27s\n",
      "637:\tlearn: 0.2777122\ttotal: 11s\tremaining: 6.26s\n",
      "638:\tlearn: 0.2773907\ttotal: 11s\tremaining: 6.24s\n",
      "639:\tlearn: 0.2771670\ttotal: 11.1s\tremaining: 6.22s\n",
      "640:\tlearn: 0.2770207\ttotal: 11.1s\tremaining: 6.2s\n",
      "641:\tlearn: 0.2766781\ttotal: 11.1s\tremaining: 6.18s\n",
      "642:\tlearn: 0.2764669\ttotal: 11.1s\tremaining: 6.17s\n",
      "643:\tlearn: 0.2762176\ttotal: 11.1s\tremaining: 6.15s\n",
      "644:\tlearn: 0.2760279\ttotal: 11.1s\tremaining: 6.13s\n",
      "645:\tlearn: 0.2757754\ttotal: 11.1s\tremaining: 6.11s\n",
      "646:\tlearn: 0.2756408\ttotal: 11.2s\tremaining: 6.09s\n",
      "647:\tlearn: 0.2753836\ttotal: 11.2s\tremaining: 6.07s\n",
      "648:\tlearn: 0.2751918\ttotal: 11.2s\tremaining: 6.05s\n",
      "649:\tlearn: 0.2749605\ttotal: 11.2s\tremaining: 6.04s\n",
      "650:\tlearn: 0.2747998\ttotal: 11.2s\tremaining: 6.02s\n",
      "651:\tlearn: 0.2745697\ttotal: 11.2s\tremaining: 6s\n",
      "652:\tlearn: 0.2743184\ttotal: 11.3s\tremaining: 5.99s\n",
      "653:\tlearn: 0.2739973\ttotal: 11.3s\tremaining: 5.97s\n",
      "654:\tlearn: 0.2739083\ttotal: 11.3s\tremaining: 5.96s\n",
      "655:\tlearn: 0.2736983\ttotal: 11.3s\tremaining: 5.95s\n",
      "656:\tlearn: 0.2733289\ttotal: 11.4s\tremaining: 5.93s\n",
      "657:\tlearn: 0.2730439\ttotal: 11.4s\tremaining: 5.91s\n",
      "658:\tlearn: 0.2728013\ttotal: 11.4s\tremaining: 5.89s\n",
      "659:\tlearn: 0.2726738\ttotal: 11.4s\tremaining: 5.87s\n",
      "660:\tlearn: 0.2725312\ttotal: 11.5s\tremaining: 5.89s\n",
      "661:\tlearn: 0.2723440\ttotal: 11.5s\tremaining: 5.88s\n",
      "662:\tlearn: 0.2720595\ttotal: 11.5s\tremaining: 5.87s\n",
      "663:\tlearn: 0.2718452\ttotal: 11.6s\tremaining: 5.85s\n",
      "664:\tlearn: 0.2715952\ttotal: 11.6s\tremaining: 5.83s\n",
      "665:\tlearn: 0.2714242\ttotal: 11.6s\tremaining: 5.81s\n",
      "666:\tlearn: 0.2712612\ttotal: 11.6s\tremaining: 5.79s\n",
      "667:\tlearn: 0.2711765\ttotal: 11.7s\tremaining: 5.8s\n",
      "668:\tlearn: 0.2709824\ttotal: 11.7s\tremaining: 5.79s\n",
      "669:\tlearn: 0.2707670\ttotal: 11.7s\tremaining: 5.77s\n",
      "670:\tlearn: 0.2705744\ttotal: 11.7s\tremaining: 5.75s\n",
      "671:\tlearn: 0.2703700\ttotal: 11.7s\tremaining: 5.74s\n",
      "672:\tlearn: 0.2701710\ttotal: 11.8s\tremaining: 5.72s\n",
      "673:\tlearn: 0.2699754\ttotal: 11.8s\tremaining: 5.7s\n",
      "674:\tlearn: 0.2698939\ttotal: 11.8s\tremaining: 5.69s\n",
      "675:\tlearn: 0.2697933\ttotal: 11.8s\tremaining: 5.67s\n",
      "676:\tlearn: 0.2696475\ttotal: 11.8s\tremaining: 5.65s\n",
      "677:\tlearn: 0.2694823\ttotal: 11.9s\tremaining: 5.63s\n",
      "678:\tlearn: 0.2693262\ttotal: 11.9s\tremaining: 5.61s\n",
      "679:\tlearn: 0.2691113\ttotal: 11.9s\tremaining: 5.59s\n",
      "680:\tlearn: 0.2688694\ttotal: 11.9s\tremaining: 5.57s\n",
      "681:\tlearn: 0.2687039\ttotal: 11.9s\tremaining: 5.55s\n",
      "682:\tlearn: 0.2684966\ttotal: 11.9s\tremaining: 5.54s\n",
      "683:\tlearn: 0.2683552\ttotal: 11.9s\tremaining: 5.52s\n",
      "684:\tlearn: 0.2681593\ttotal: 12s\tremaining: 5.5s\n",
      "685:\tlearn: 0.2679490\ttotal: 12s\tremaining: 5.48s\n",
      "686:\tlearn: 0.2676438\ttotal: 12s\tremaining: 5.46s\n",
      "687:\tlearn: 0.2675266\ttotal: 12s\tremaining: 5.45s\n",
      "688:\tlearn: 0.2673592\ttotal: 12s\tremaining: 5.43s\n",
      "689:\tlearn: 0.2671000\ttotal: 12s\tremaining: 5.41s\n",
      "690:\tlearn: 0.2669275\ttotal: 12.1s\tremaining: 5.39s\n",
      "691:\tlearn: 0.2667408\ttotal: 12.1s\tremaining: 5.38s\n",
      "692:\tlearn: 0.2666009\ttotal: 12.1s\tremaining: 5.36s\n",
      "693:\tlearn: 0.2664670\ttotal: 12.1s\tremaining: 5.34s\n",
      "694:\tlearn: 0.2662585\ttotal: 12.1s\tremaining: 5.32s\n",
      "695:\tlearn: 0.2660370\ttotal: 12.1s\tremaining: 5.3s\n",
      "696:\tlearn: 0.2658998\ttotal: 12.2s\tremaining: 5.28s\n",
      "697:\tlearn: 0.2656725\ttotal: 12.2s\tremaining: 5.26s\n",
      "698:\tlearn: 0.2654889\ttotal: 12.2s\tremaining: 5.25s\n",
      "699:\tlearn: 0.2653863\ttotal: 12.2s\tremaining: 5.23s\n",
      "700:\tlearn: 0.2652492\ttotal: 12.2s\tremaining: 5.21s\n",
      "701:\tlearn: 0.2650549\ttotal: 12.2s\tremaining: 5.19s\n",
      "702:\tlearn: 0.2648998\ttotal: 12.2s\tremaining: 5.17s\n",
      "703:\tlearn: 0.2647915\ttotal: 12.3s\tremaining: 5.16s\n",
      "704:\tlearn: 0.2645856\ttotal: 12.3s\tremaining: 5.14s\n",
      "705:\tlearn: 0.2643480\ttotal: 12.3s\tremaining: 5.12s\n",
      "706:\tlearn: 0.2641439\ttotal: 12.3s\tremaining: 5.1s\n",
      "707:\tlearn: 0.2638740\ttotal: 12.3s\tremaining: 5.09s\n",
      "708:\tlearn: 0.2636709\ttotal: 12.4s\tremaining: 5.07s\n",
      "709:\tlearn: 0.2634987\ttotal: 12.4s\tremaining: 5.06s\n",
      "710:\tlearn: 0.2633436\ttotal: 12.4s\tremaining: 5.04s\n",
      "711:\tlearn: 0.2631246\ttotal: 12.4s\tremaining: 5.02s\n",
      "712:\tlearn: 0.2627919\ttotal: 12.4s\tremaining: 5.01s\n",
      "713:\tlearn: 0.2626088\ttotal: 12.5s\tremaining: 4.99s\n",
      "714:\tlearn: 0.2623912\ttotal: 12.5s\tremaining: 4.97s\n",
      "715:\tlearn: 0.2622145\ttotal: 12.5s\tremaining: 4.95s\n",
      "716:\tlearn: 0.2619990\ttotal: 12.5s\tremaining: 4.94s\n",
      "717:\tlearn: 0.2616269\ttotal: 12.5s\tremaining: 4.92s\n",
      "718:\tlearn: 0.2613329\ttotal: 12.5s\tremaining: 4.9s\n",
      "719:\tlearn: 0.2611496\ttotal: 12.6s\tremaining: 4.88s\n",
      "720:\tlearn: 0.2610144\ttotal: 12.6s\tremaining: 4.87s\n",
      "721:\tlearn: 0.2608291\ttotal: 12.6s\tremaining: 4.85s\n",
      "722:\tlearn: 0.2606438\ttotal: 12.6s\tremaining: 4.83s\n",
      "723:\tlearn: 0.2604698\ttotal: 12.6s\tremaining: 4.81s\n",
      "724:\tlearn: 0.2602128\ttotal: 12.6s\tremaining: 4.79s\n",
      "725:\tlearn: 0.2599375\ttotal: 12.7s\tremaining: 4.78s\n",
      "726:\tlearn: 0.2596954\ttotal: 12.7s\tremaining: 4.76s\n",
      "727:\tlearn: 0.2596067\ttotal: 12.7s\tremaining: 4.74s\n",
      "728:\tlearn: 0.2593574\ttotal: 12.7s\tremaining: 4.72s\n",
      "729:\tlearn: 0.2591813\ttotal: 12.7s\tremaining: 4.71s\n",
      "730:\tlearn: 0.2590046\ttotal: 12.7s\tremaining: 4.69s\n",
      "731:\tlearn: 0.2588359\ttotal: 12.8s\tremaining: 4.67s\n",
      "732:\tlearn: 0.2585743\ttotal: 12.8s\tremaining: 4.66s\n",
      "733:\tlearn: 0.2583285\ttotal: 12.8s\tremaining: 4.64s\n",
      "734:\tlearn: 0.2580382\ttotal: 12.8s\tremaining: 4.62s\n",
      "735:\tlearn: 0.2579179\ttotal: 12.8s\tremaining: 4.6s\n",
      "736:\tlearn: 0.2578576\ttotal: 12.8s\tremaining: 4.58s\n",
      "737:\tlearn: 0.2577006\ttotal: 12.9s\tremaining: 4.57s\n",
      "738:\tlearn: 0.2574118\ttotal: 12.9s\tremaining: 4.55s\n",
      "739:\tlearn: 0.2572418\ttotal: 12.9s\tremaining: 4.53s\n",
      "740:\tlearn: 0.2570385\ttotal: 12.9s\tremaining: 4.51s\n",
      "741:\tlearn: 0.2568663\ttotal: 12.9s\tremaining: 4.5s\n",
      "742:\tlearn: 0.2566397\ttotal: 13s\tremaining: 4.48s\n",
      "743:\tlearn: 0.2565144\ttotal: 13s\tremaining: 4.46s\n",
      "744:\tlearn: 0.2563916\ttotal: 13s\tremaining: 4.45s\n",
      "745:\tlearn: 0.2561622\ttotal: 13s\tremaining: 4.43s\n",
      "746:\tlearn: 0.2560424\ttotal: 13s\tremaining: 4.42s\n",
      "747:\tlearn: 0.2559137\ttotal: 13.1s\tremaining: 4.4s\n",
      "748:\tlearn: 0.2556867\ttotal: 13.1s\tremaining: 4.38s\n",
      "749:\tlearn: 0.2555796\ttotal: 13.1s\tremaining: 4.36s\n",
      "750:\tlearn: 0.2552717\ttotal: 13.1s\tremaining: 4.34s\n",
      "751:\tlearn: 0.2551347\ttotal: 13.1s\tremaining: 4.33s\n",
      "752:\tlearn: 0.2548480\ttotal: 13.1s\tremaining: 4.31s\n",
      "753:\tlearn: 0.2545245\ttotal: 13.2s\tremaining: 4.29s\n",
      "754:\tlearn: 0.2543860\ttotal: 13.2s\tremaining: 4.27s\n",
      "755:\tlearn: 0.2541050\ttotal: 13.2s\tremaining: 4.25s\n",
      "756:\tlearn: 0.2539209\ttotal: 13.2s\tremaining: 4.24s\n",
      "757:\tlearn: 0.2538043\ttotal: 13.2s\tremaining: 4.22s\n",
      "758:\tlearn: 0.2534529\ttotal: 13.3s\tremaining: 4.21s\n",
      "759:\tlearn: 0.2532509\ttotal: 13.3s\tremaining: 4.19s\n",
      "760:\tlearn: 0.2530688\ttotal: 13.3s\tremaining: 4.17s\n",
      "761:\tlearn: 0.2529197\ttotal: 13.3s\tremaining: 4.15s\n",
      "762:\tlearn: 0.2527741\ttotal: 13.3s\tremaining: 4.14s\n",
      "763:\tlearn: 0.2525311\ttotal: 13.3s\tremaining: 4.12s\n",
      "764:\tlearn: 0.2522786\ttotal: 13.3s\tremaining: 4.1s\n",
      "765:\tlearn: 0.2519941\ttotal: 13.4s\tremaining: 4.08s\n",
      "766:\tlearn: 0.2517426\ttotal: 13.4s\tremaining: 4.08s\n",
      "767:\tlearn: 0.2515837\ttotal: 13.6s\tremaining: 4.11s\n",
      "768:\tlearn: 0.2514565\ttotal: 13.7s\tremaining: 4.11s\n",
      "769:\tlearn: 0.2512590\ttotal: 13.7s\tremaining: 4.09s\n",
      "770:\tlearn: 0.2509201\ttotal: 13.7s\tremaining: 4.08s\n",
      "771:\tlearn: 0.2507875\ttotal: 13.9s\tremaining: 4.09s\n",
      "772:\tlearn: 0.2505182\ttotal: 13.9s\tremaining: 4.09s\n",
      "773:\tlearn: 0.2503171\ttotal: 14s\tremaining: 4.08s\n",
      "774:\tlearn: 0.2501721\ttotal: 14s\tremaining: 4.07s\n",
      "775:\tlearn: 0.2499350\ttotal: 14s\tremaining: 4.05s\n",
      "776:\tlearn: 0.2496580\ttotal: 14.1s\tremaining: 4.04s\n",
      "777:\tlearn: 0.2493949\ttotal: 14.1s\tremaining: 4.04s\n",
      "778:\tlearn: 0.2491860\ttotal: 14.2s\tremaining: 4.02s\n",
      "779:\tlearn: 0.2490078\ttotal: 14.2s\tremaining: 4.01s\n",
      "780:\tlearn: 0.2488971\ttotal: 14.3s\tremaining: 4.01s\n",
      "781:\tlearn: 0.2487000\ttotal: 14.4s\tremaining: 4.01s\n",
      "782:\tlearn: 0.2485636\ttotal: 14.4s\tremaining: 4s\n",
      "783:\tlearn: 0.2484664\ttotal: 14.5s\tremaining: 3.99s\n",
      "784:\tlearn: 0.2482553\ttotal: 14.5s\tremaining: 3.98s\n",
      "785:\tlearn: 0.2480727\ttotal: 14.6s\tremaining: 3.97s\n",
      "786:\tlearn: 0.2478911\ttotal: 14.7s\tremaining: 3.97s\n",
      "787:\tlearn: 0.2477972\ttotal: 14.8s\tremaining: 3.97s\n",
      "788:\tlearn: 0.2475904\ttotal: 14.8s\tremaining: 3.96s\n",
      "789:\tlearn: 0.2474424\ttotal: 14.9s\tremaining: 3.95s\n",
      "790:\tlearn: 0.2471820\ttotal: 14.9s\tremaining: 3.94s\n",
      "791:\tlearn: 0.2469352\ttotal: 15s\tremaining: 3.94s\n",
      "792:\tlearn: 0.2467102\ttotal: 15.1s\tremaining: 3.94s\n",
      "793:\tlearn: 0.2464495\ttotal: 15.2s\tremaining: 3.93s\n",
      "794:\tlearn: 0.2463291\ttotal: 15.2s\tremaining: 3.93s\n",
      "795:\tlearn: 0.2460547\ttotal: 15.3s\tremaining: 3.92s\n",
      "796:\tlearn: 0.2458805\ttotal: 15.3s\tremaining: 3.91s\n",
      "797:\tlearn: 0.2457026\ttotal: 15.4s\tremaining: 3.89s\n",
      "798:\tlearn: 0.2455458\ttotal: 15.4s\tremaining: 3.88s\n",
      "799:\tlearn: 0.2452250\ttotal: 15.6s\tremaining: 3.91s\n",
      "800:\tlearn: 0.2449914\ttotal: 15.7s\tremaining: 3.9s\n",
      "801:\tlearn: 0.2448482\ttotal: 15.9s\tremaining: 3.91s\n",
      "802:\tlearn: 0.2445929\ttotal: 15.9s\tremaining: 3.91s\n",
      "803:\tlearn: 0.2443147\ttotal: 16s\tremaining: 3.89s\n",
      "804:\tlearn: 0.2442600\ttotal: 16s\tremaining: 3.88s\n",
      "805:\tlearn: 0.2439939\ttotal: 16s\tremaining: 3.85s\n",
      "806:\tlearn: 0.2437318\ttotal: 16s\tremaining: 3.83s\n",
      "807:\tlearn: 0.2435515\ttotal: 16.1s\tremaining: 3.81s\n",
      "808:\tlearn: 0.2433373\ttotal: 16.1s\tremaining: 3.8s\n",
      "809:\tlearn: 0.2431092\ttotal: 16.1s\tremaining: 3.78s\n",
      "810:\tlearn: 0.2429837\ttotal: 16.2s\tremaining: 3.77s\n",
      "811:\tlearn: 0.2428768\ttotal: 16.2s\tremaining: 3.75s\n",
      "812:\tlearn: 0.2426614\ttotal: 16.2s\tremaining: 3.73s\n",
      "813:\tlearn: 0.2425096\ttotal: 16.2s\tremaining: 3.71s\n",
      "814:\tlearn: 0.2420605\ttotal: 16.2s\tremaining: 3.69s\n",
      "815:\tlearn: 0.2416188\ttotal: 16.3s\tremaining: 3.67s\n",
      "816:\tlearn: 0.2413961\ttotal: 16.3s\tremaining: 3.65s\n",
      "817:\tlearn: 0.2412135\ttotal: 16.3s\tremaining: 3.63s\n",
      "818:\tlearn: 0.2408659\ttotal: 16.3s\tremaining: 3.61s\n",
      "819:\tlearn: 0.2407091\ttotal: 16.4s\tremaining: 3.59s\n",
      "820:\tlearn: 0.2404354\ttotal: 16.4s\tremaining: 3.57s\n",
      "821:\tlearn: 0.2401577\ttotal: 16.4s\tremaining: 3.55s\n",
      "822:\tlearn: 0.2400014\ttotal: 16.4s\tremaining: 3.53s\n",
      "823:\tlearn: 0.2396231\ttotal: 16.4s\tremaining: 3.51s\n",
      "824:\tlearn: 0.2393530\ttotal: 16.5s\tremaining: 3.49s\n",
      "825:\tlearn: 0.2391757\ttotal: 16.5s\tremaining: 3.47s\n",
      "826:\tlearn: 0.2389752\ttotal: 16.5s\tremaining: 3.46s\n",
      "827:\tlearn: 0.2388402\ttotal: 16.5s\tremaining: 3.44s\n",
      "828:\tlearn: 0.2386147\ttotal: 16.6s\tremaining: 3.42s\n",
      "829:\tlearn: 0.2384385\ttotal: 16.6s\tremaining: 3.4s\n",
      "830:\tlearn: 0.2382875\ttotal: 16.6s\tremaining: 3.38s\n",
      "831:\tlearn: 0.2380710\ttotal: 16.6s\tremaining: 3.36s\n",
      "832:\tlearn: 0.2378862\ttotal: 16.6s\tremaining: 3.34s\n",
      "833:\tlearn: 0.2374371\ttotal: 16.7s\tremaining: 3.32s\n",
      "834:\tlearn: 0.2372319\ttotal: 16.7s\tremaining: 3.3s\n",
      "835:\tlearn: 0.2369184\ttotal: 16.7s\tremaining: 3.28s\n",
      "836:\tlearn: 0.2366715\ttotal: 16.8s\tremaining: 3.26s\n",
      "837:\tlearn: 0.2365504\ttotal: 16.8s\tremaining: 3.24s\n",
      "838:\tlearn: 0.2363831\ttotal: 16.8s\tremaining: 3.22s\n",
      "839:\tlearn: 0.2361972\ttotal: 16.8s\tremaining: 3.2s\n",
      "840:\tlearn: 0.2360381\ttotal: 16.8s\tremaining: 3.18s\n",
      "841:\tlearn: 0.2357994\ttotal: 16.9s\tremaining: 3.16s\n",
      "842:\tlearn: 0.2356245\ttotal: 16.9s\tremaining: 3.14s\n",
      "843:\tlearn: 0.2354067\ttotal: 16.9s\tremaining: 3.12s\n",
      "844:\tlearn: 0.2351639\ttotal: 16.9s\tremaining: 3.1s\n",
      "845:\tlearn: 0.2349235\ttotal: 17s\tremaining: 3.09s\n",
      "846:\tlearn: 0.2347952\ttotal: 17s\tremaining: 3.07s\n",
      "847:\tlearn: 0.2346379\ttotal: 17s\tremaining: 3.05s\n",
      "848:\tlearn: 0.2345570\ttotal: 17s\tremaining: 3.03s\n",
      "849:\tlearn: 0.2343529\ttotal: 17.1s\tremaining: 3.01s\n",
      "850:\tlearn: 0.2342068\ttotal: 17.1s\tremaining: 2.99s\n",
      "851:\tlearn: 0.2340009\ttotal: 17.1s\tremaining: 2.97s\n",
      "852:\tlearn: 0.2338189\ttotal: 17.1s\tremaining: 2.95s\n",
      "853:\tlearn: 0.2334831\ttotal: 17.2s\tremaining: 2.94s\n",
      "854:\tlearn: 0.2332059\ttotal: 17.2s\tremaining: 2.92s\n",
      "855:\tlearn: 0.2327199\ttotal: 17.2s\tremaining: 2.9s\n",
      "856:\tlearn: 0.2325617\ttotal: 17.2s\tremaining: 2.88s\n",
      "857:\tlearn: 0.2322318\ttotal: 17.3s\tremaining: 2.85s\n",
      "858:\tlearn: 0.2320362\ttotal: 17.3s\tremaining: 2.83s\n",
      "859:\tlearn: 0.2318858\ttotal: 17.3s\tremaining: 2.81s\n",
      "860:\tlearn: 0.2316677\ttotal: 17.3s\tremaining: 2.8s\n",
      "861:\tlearn: 0.2313374\ttotal: 17.3s\tremaining: 2.78s\n",
      "862:\tlearn: 0.2311570\ttotal: 17.4s\tremaining: 2.76s\n",
      "863:\tlearn: 0.2309092\ttotal: 17.4s\tremaining: 2.74s\n",
      "864:\tlearn: 0.2307427\ttotal: 17.4s\tremaining: 2.72s\n",
      "865:\tlearn: 0.2305595\ttotal: 17.5s\tremaining: 2.7s\n",
      "866:\tlearn: 0.2304045\ttotal: 17.5s\tremaining: 2.68s\n",
      "867:\tlearn: 0.2302233\ttotal: 17.5s\tremaining: 2.66s\n",
      "868:\tlearn: 0.2300640\ttotal: 17.5s\tremaining: 2.64s\n",
      "869:\tlearn: 0.2298493\ttotal: 17.5s\tremaining: 2.62s\n",
      "870:\tlearn: 0.2296947\ttotal: 17.6s\tremaining: 2.6s\n",
      "871:\tlearn: 0.2295409\ttotal: 17.6s\tremaining: 2.58s\n",
      "872:\tlearn: 0.2293865\ttotal: 17.6s\tremaining: 2.56s\n",
      "873:\tlearn: 0.2291087\ttotal: 17.6s\tremaining: 2.54s\n",
      "874:\tlearn: 0.2289165\ttotal: 17.7s\tremaining: 2.53s\n",
      "875:\tlearn: 0.2287273\ttotal: 17.7s\tremaining: 2.51s\n",
      "876:\tlearn: 0.2285478\ttotal: 17.8s\tremaining: 2.5s\n",
      "877:\tlearn: 0.2283893\ttotal: 17.8s\tremaining: 2.48s\n",
      "878:\tlearn: 0.2281672\ttotal: 17.9s\tremaining: 2.46s\n",
      "879:\tlearn: 0.2280382\ttotal: 17.9s\tremaining: 2.44s\n",
      "880:\tlearn: 0.2278460\ttotal: 17.9s\tremaining: 2.42s\n",
      "881:\tlearn: 0.2276605\ttotal: 18s\tremaining: 2.4s\n",
      "882:\tlearn: 0.2275020\ttotal: 18s\tremaining: 2.39s\n",
      "883:\tlearn: 0.2273175\ttotal: 18.1s\tremaining: 2.37s\n",
      "884:\tlearn: 0.2271601\ttotal: 18.1s\tremaining: 2.35s\n",
      "885:\tlearn: 0.2270233\ttotal: 18.1s\tremaining: 2.33s\n",
      "886:\tlearn: 0.2266134\ttotal: 18.2s\tremaining: 2.32s\n",
      "887:\tlearn: 0.2264233\ttotal: 18.2s\tremaining: 2.29s\n",
      "888:\tlearn: 0.2261968\ttotal: 18.2s\tremaining: 2.27s\n",
      "889:\tlearn: 0.2260834\ttotal: 18.2s\tremaining: 2.25s\n",
      "890:\tlearn: 0.2259372\ttotal: 18.3s\tremaining: 2.23s\n",
      "891:\tlearn: 0.2257129\ttotal: 18.3s\tremaining: 2.21s\n",
      "892:\tlearn: 0.2255865\ttotal: 18.3s\tremaining: 2.19s\n",
      "893:\tlearn: 0.2253934\ttotal: 18.3s\tremaining: 2.17s\n",
      "894:\tlearn: 0.2249978\ttotal: 18.4s\tremaining: 2.15s\n",
      "895:\tlearn: 0.2247813\ttotal: 18.4s\tremaining: 2.14s\n",
      "896:\tlearn: 0.2245002\ttotal: 18.4s\tremaining: 2.12s\n",
      "897:\tlearn: 0.2243440\ttotal: 18.4s\tremaining: 2.1s\n",
      "898:\tlearn: 0.2241541\ttotal: 18.5s\tremaining: 2.07s\n",
      "899:\tlearn: 0.2239474\ttotal: 18.5s\tremaining: 2.05s\n",
      "900:\tlearn: 0.2237802\ttotal: 18.5s\tremaining: 2.03s\n",
      "901:\tlearn: 0.2236447\ttotal: 18.5s\tremaining: 2.01s\n",
      "902:\tlearn: 0.2233218\ttotal: 18.6s\tremaining: 1.99s\n",
      "903:\tlearn: 0.2230797\ttotal: 18.7s\tremaining: 1.98s\n",
      "904:\tlearn: 0.2228526\ttotal: 18.7s\tremaining: 1.97s\n",
      "905:\tlearn: 0.2227471\ttotal: 18.8s\tremaining: 1.95s\n",
      "906:\tlearn: 0.2225394\ttotal: 18.8s\tremaining: 1.93s\n",
      "907:\tlearn: 0.2223190\ttotal: 18.8s\tremaining: 1.91s\n",
      "908:\tlearn: 0.2221451\ttotal: 18.8s\tremaining: 1.89s\n",
      "909:\tlearn: 0.2218390\ttotal: 18.9s\tremaining: 1.86s\n",
      "910:\tlearn: 0.2217524\ttotal: 18.9s\tremaining: 1.84s\n",
      "911:\tlearn: 0.2215836\ttotal: 18.9s\tremaining: 1.82s\n",
      "912:\tlearn: 0.2214254\ttotal: 18.9s\tremaining: 1.8s\n",
      "913:\tlearn: 0.2213262\ttotal: 18.9s\tremaining: 1.78s\n",
      "914:\tlearn: 0.2211085\ttotal: 19s\tremaining: 1.76s\n",
      "915:\tlearn: 0.2209424\ttotal: 19s\tremaining: 1.74s\n",
      "916:\tlearn: 0.2206685\ttotal: 19s\tremaining: 1.72s\n",
      "917:\tlearn: 0.2205363\ttotal: 19s\tremaining: 1.7s\n",
      "918:\tlearn: 0.2204101\ttotal: 19.1s\tremaining: 1.68s\n",
      "919:\tlearn: 0.2200412\ttotal: 19.1s\tremaining: 1.67s\n",
      "920:\tlearn: 0.2199064\ttotal: 19.2s\tremaining: 1.64s\n",
      "921:\tlearn: 0.2197222\ttotal: 19.2s\tremaining: 1.62s\n",
      "922:\tlearn: 0.2194492\ttotal: 19.2s\tremaining: 1.6s\n",
      "923:\tlearn: 0.2193086\ttotal: 19.2s\tremaining: 1.58s\n",
      "924:\tlearn: 0.2191796\ttotal: 19.3s\tremaining: 1.56s\n",
      "925:\tlearn: 0.2190158\ttotal: 19.3s\tremaining: 1.54s\n",
      "926:\tlearn: 0.2188737\ttotal: 19.3s\tremaining: 1.52s\n",
      "927:\tlearn: 0.2187168\ttotal: 19.3s\tremaining: 1.5s\n",
      "928:\tlearn: 0.2186251\ttotal: 19.4s\tremaining: 1.48s\n",
      "929:\tlearn: 0.2184721\ttotal: 19.4s\tremaining: 1.46s\n",
      "930:\tlearn: 0.2182508\ttotal: 19.4s\tremaining: 1.44s\n",
      "931:\tlearn: 0.2181065\ttotal: 19.5s\tremaining: 1.42s\n",
      "932:\tlearn: 0.2179998\ttotal: 19.6s\tremaining: 1.4s\n",
      "933:\tlearn: 0.2178139\ttotal: 19.6s\tremaining: 1.38s\n",
      "934:\tlearn: 0.2177037\ttotal: 19.6s\tremaining: 1.36s\n",
      "935:\tlearn: 0.2175774\ttotal: 19.7s\tremaining: 1.34s\n",
      "936:\tlearn: 0.2173594\ttotal: 19.7s\tremaining: 1.32s\n",
      "937:\tlearn: 0.2170698\ttotal: 19.7s\tremaining: 1.3s\n",
      "938:\tlearn: 0.2169309\ttotal: 19.7s\tremaining: 1.28s\n",
      "939:\tlearn: 0.2168337\ttotal: 19.7s\tremaining: 1.26s\n",
      "940:\tlearn: 0.2166908\ttotal: 19.8s\tremaining: 1.24s\n",
      "941:\tlearn: 0.2166349\ttotal: 19.8s\tremaining: 1.22s\n",
      "942:\tlearn: 0.2164386\ttotal: 19.8s\tremaining: 1.2s\n",
      "943:\tlearn: 0.2161560\ttotal: 19.8s\tremaining: 1.18s\n",
      "944:\tlearn: 0.2158354\ttotal: 19.9s\tremaining: 1.16s\n",
      "945:\tlearn: 0.2156986\ttotal: 19.9s\tremaining: 1.14s\n",
      "946:\tlearn: 0.2155712\ttotal: 19.9s\tremaining: 1.11s\n",
      "947:\tlearn: 0.2153559\ttotal: 19.9s\tremaining: 1.09s\n",
      "948:\tlearn: 0.2151499\ttotal: 19.9s\tremaining: 1.07s\n",
      "949:\tlearn: 0.2148496\ttotal: 20s\tremaining: 1.05s\n",
      "950:\tlearn: 0.2146522\ttotal: 20s\tremaining: 1.03s\n",
      "951:\tlearn: 0.2144067\ttotal: 20s\tremaining: 1.01s\n",
      "952:\tlearn: 0.2143062\ttotal: 20s\tremaining: 989ms\n",
      "953:\tlearn: 0.2140857\ttotal: 20.1s\tremaining: 968ms\n",
      "954:\tlearn: 0.2138819\ttotal: 20.1s\tremaining: 946ms\n",
      "955:\tlearn: 0.2136740\ttotal: 20.1s\tremaining: 926ms\n",
      "956:\tlearn: 0.2135464\ttotal: 20.2s\tremaining: 906ms\n",
      "957:\tlearn: 0.2133223\ttotal: 20.2s\tremaining: 885ms\n",
      "958:\tlearn: 0.2131819\ttotal: 20.2s\tremaining: 865ms\n",
      "959:\tlearn: 0.2130962\ttotal: 20.2s\tremaining: 843ms\n",
      "960:\tlearn: 0.2129411\ttotal: 20.3s\tremaining: 822ms\n",
      "961:\tlearn: 0.2128119\ttotal: 20.3s\tremaining: 801ms\n",
      "962:\tlearn: 0.2126813\ttotal: 20.3s\tremaining: 780ms\n",
      "963:\tlearn: 0.2125553\ttotal: 20.3s\tremaining: 758ms\n",
      "964:\tlearn: 0.2124481\ttotal: 20.3s\tremaining: 737ms\n",
      "965:\tlearn: 0.2122845\ttotal: 20.3s\tremaining: 716ms\n",
      "966:\tlearn: 0.2121282\ttotal: 20.4s\tremaining: 695ms\n",
      "967:\tlearn: 0.2120238\ttotal: 20.4s\tremaining: 674ms\n",
      "968:\tlearn: 0.2117431\ttotal: 20.4s\tremaining: 653ms\n",
      "969:\tlearn: 0.2114842\ttotal: 20.4s\tremaining: 632ms\n",
      "970:\tlearn: 0.2111128\ttotal: 20.5s\tremaining: 611ms\n",
      "971:\tlearn: 0.2109408\ttotal: 20.5s\tremaining: 590ms\n",
      "972:\tlearn: 0.2107249\ttotal: 20.5s\tremaining: 569ms\n",
      "973:\tlearn: 0.2104167\ttotal: 20.5s\tremaining: 548ms\n",
      "974:\tlearn: 0.2103225\ttotal: 20.5s\tremaining: 527ms\n",
      "975:\tlearn: 0.2102243\ttotal: 20.6s\tremaining: 505ms\n",
      "976:\tlearn: 0.2101321\ttotal: 20.6s\tremaining: 484ms\n",
      "977:\tlearn: 0.2098318\ttotal: 20.6s\tremaining: 464ms\n",
      "978:\tlearn: 0.2095065\ttotal: 20.6s\tremaining: 443ms\n",
      "979:\tlearn: 0.2093725\ttotal: 20.7s\tremaining: 422ms\n",
      "980:\tlearn: 0.2091530\ttotal: 20.7s\tremaining: 401ms\n",
      "981:\tlearn: 0.2090783\ttotal: 20.7s\tremaining: 379ms\n",
      "982:\tlearn: 0.2088439\ttotal: 20.7s\tremaining: 358ms\n",
      "983:\tlearn: 0.2087259\ttotal: 20.7s\tremaining: 337ms\n",
      "984:\tlearn: 0.2085302\ttotal: 20.8s\tremaining: 316ms\n",
      "985:\tlearn: 0.2082627\ttotal: 20.8s\tremaining: 295ms\n",
      "986:\tlearn: 0.2080301\ttotal: 20.8s\tremaining: 274ms\n",
      "987:\tlearn: 0.2077183\ttotal: 20.8s\tremaining: 253ms\n",
      "988:\tlearn: 0.2074577\ttotal: 20.8s\tremaining: 232ms\n",
      "989:\tlearn: 0.2073807\ttotal: 20.9s\tremaining: 211ms\n",
      "990:\tlearn: 0.2072274\ttotal: 20.9s\tremaining: 190ms\n",
      "991:\tlearn: 0.2070296\ttotal: 20.9s\tremaining: 169ms\n",
      "992:\tlearn: 0.2069069\ttotal: 20.9s\tremaining: 148ms\n",
      "993:\tlearn: 0.2067251\ttotal: 20.9s\tremaining: 126ms\n",
      "994:\tlearn: 0.2064797\ttotal: 21s\tremaining: 105ms\n",
      "995:\tlearn: 0.2063826\ttotal: 21.1s\tremaining: 84.7ms\n",
      "996:\tlearn: 0.2062505\ttotal: 21.1s\tremaining: 63.6ms\n",
      "997:\tlearn: 0.2060654\ttotal: 21.1s\tremaining: 42.4ms\n",
      "998:\tlearn: 0.2058327\ttotal: 21.2s\tremaining: 21.2ms\n",
      "999:\tlearn: 0.2056838\ttotal: 21.2s\tremaining: 0us\n",
      "Accuracy, fold_5: 0.819672131147541\n",
      "0.8143409302945489\n"
     ]
    }
   ],
   "source": [
    "fold=StratifiedKFold(n_splits=5)\n",
    "\n",
    "F1,i=[],1\n",
    "for train, test in fold.split(X,y):\n",
    "\n",
    "  X_train, X_test = X.iloc[train],X.iloc[test]\n",
    "  y_train, y_test = y.iloc[train],y.iloc[test]\n",
    "\n",
    "  model=CatBoostClassifier(verbose=False)\n",
    "\n",
    "  model.fit(X_train,y_train)\n",
    "\n",
    "  preds=model.predict(X_test)\n",
    "\n",
    "  print(f'Accuracy, fold_{i}: {accuracy_score(y_test,preds)}')\n",
    "  i+=1\n",
    "  F1.append(accuracy_score(y_test,preds))\n",
    "print(np.mean(F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, fold_1: 0.7886178861788617\n",
      "Accuracy, fold_2: 0.7967479674796748\n",
      "Accuracy, fold_3: 0.7804878048780488\n",
      "Accuracy, fold_4: 0.8455284552845529\n",
      "Accuracy, fold_5: 0.7459016393442623\n",
      "0.7914567506330802\n"
     ]
    }
   ],
   "source": [
    "fold=StratifiedKFold(n_splits=5)\n",
    "\n",
    "F1,i=[],1\n",
    "for train, test in fold.split(X,y):\n",
    "\n",
    "  X_train, X_test = X.iloc[train],X.iloc[test]\n",
    "  y_train, y_test = y.iloc[train],y.iloc[test]\n",
    "\n",
    "  model=LGBMClassifier()\n",
    "\n",
    "  model.fit(X_train,y_train)\n",
    "\n",
    "  preds=model.predict(X_test)\n",
    "\n",
    "  print(f'Accuracy, fold_{i}: {accuracy_score(y_test,preds)}')\n",
    "  i+=1\n",
    "  F1.append(accuracy_score(y_test,preds))\n",
    "print(np.mean(F1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-OFZoqosRXe"
   },
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "id": "vvY87WQRZVzN",
    "outputId": "ceba7b85-86f2-4a58-e421-5af0db51ad2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Model features importance:')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0.7831404345536787\n",
    "feature_importance_df = pd.DataFrame(model.feature_importances_, columns=['importance'])\n",
    "feature_importance_df['feature'] = new_data.drop(['Loan_ID','Loan_Status'],axis=1).columns\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "sns.barplot(x=\"importance\", y=\"feature\", data=feature_importance_df.sort_values(by = ['importance'], ascending = False).head(60))\n",
    "plt.title('Model features importance:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "WdbweSh_baap"
   },
   "outputs": [],
   "source": [
    "new_feat = feature_importance_df.sort_values(by = ['importance'], ascending = False).head(30)['feature'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "M8PvUf_dbjfm"
   },
   "outputs": [],
   "source": [
    "X= new_data[new_feat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPyxYtXtsayb"
   },
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D7pbvYB2_EU9",
    "outputId": "8bd42338-cf34-4b26-83c4-a79c22c5c941"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Wonder\\anaconda3\\envs\\venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "m6efM2ha82s0"
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    oof_f1=[]\n",
    "    oof_predictions=[]\n",
    "\n",
    "\n",
    "    param = {}\n",
    "#     param['objective'] = \"Logloss\"\n",
    "    param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.001, 0.1, 0.001)\n",
    "    param['depth'] = trial.suggest_int('depth', 3, 15)\n",
    "    param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
    "    param['min_child_samples'] = trial.suggest_categorical('min_child_samples', [1, 4, 8, 16, 32])\n",
    "    param['iterations'] = trial.suggest_discrete_uniform(\"iterations\", 200, 4000, 50)\n",
    "    param['use_best_model'] = True\n",
    "    param[\"colsample_bylevel\"] =  trial.suggest_float(\"colsample_bylevel\", 0.01, 0.1)\n",
    "    param['random_state'] = 0\n",
    "    param['scale_pos_weight'] = trial.suggest_int('scale_pos_weight', 1, 10)\n",
    "    param['bootstrap_type'] = trial.suggest_categorical(\"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"])\n",
    "    param['logging_level'] = 'Silent'\n",
    "\n",
    "\n",
    "\n",
    "    fold=StratifiedKFold(n_splits=5)#15#5#10\n",
    "    i=1\n",
    "    for train_index, test_index in fold.split(X,y):\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        #model = CatBoostClassifier(**param)\n",
    "        model = XGBClassifier(**param)\n",
    "    \n",
    "\n",
    "        model.fit(X_train,y_train,eval_set=[(X_train,y_train),(X_test, y_test)], verbose = False)#erly100\n",
    "        preds=model.predict(X_test)\n",
    "\n",
    "        oof_f1.append(accuracy_score(y_test,preds))\n",
    "\n",
    "    return np.mean(oof_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "I2E9OJ3T_Ck_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:49:25] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:26] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:26] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:26] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:27] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:27] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:28] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:28] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:28] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:29] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:29] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:29] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:30] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:30] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:31] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:31] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:31] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:32] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:32] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:32] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:33] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:33] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:34] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:34] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:34] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:34] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:35] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:35] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:36] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:36] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:36] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:37] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:37] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:37] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:38] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:38] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:38] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:39] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:39] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:39] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:40] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:40] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:40] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:41] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:41] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:41] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:42] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:42] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:43] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:43] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:43] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:44] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:44] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:44] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:44] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:45] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:45] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:45] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:46] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:46] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:46] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:47] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:47] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:47] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:48] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:48] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:48] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:49] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:49] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:50] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:50] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:51] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:51] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:51] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:52] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:52] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:52] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:53] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:53] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:53] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:54] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:54] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:55] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:55] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:55] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:56] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:56] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:56] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:57] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:57] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:57] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:58] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:58] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:58] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:59] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:49:59] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:00] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:00] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:00] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:01] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:01] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:01] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:02] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:02] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:02] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:03] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:03] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:03] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:04] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:04] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:04] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:05] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:05] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:05] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:05] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:06] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:06] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:06] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:07] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:07] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:07] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:08] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:08] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:08] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:09] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:09] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:09] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:09] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:10] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:10] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:11] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:11] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:11] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:12] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:12] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:13] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:13] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:14] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:14] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:14] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:15] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:15] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:16] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:16] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:16] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:17] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:17] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:17] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:18] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:18] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:18] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:19] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:19] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:19] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:20] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:20] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:20] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:21] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:21] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:21] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:22] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:22] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:23] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:23] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:23] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:24] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:24] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:24] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:24] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:25] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:25] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:25] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:26] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:26] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:26] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:27] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:27] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:27] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:28] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:28] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:28] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:29] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:29] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:29] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:29] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:30] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:30] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:30] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:31] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:31] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:31] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:32] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:32] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:32] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:33] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:33] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:33] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:34] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:34] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:34] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:35] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:35] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:35] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:35] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:36] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:36] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:37] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:37] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:37] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:37] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:38] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:38] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:39] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:39] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:39] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:40] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:40] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:40] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:40] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:41] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:41] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:41] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:42] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:42] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:42] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:43] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:43] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:43] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:44] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:44] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:44] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:45] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:45] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:45] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:46] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:46] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:46] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:47] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:47] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:47] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:48] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:48] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:48] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:49] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:49] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:49] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:50] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:50] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:50] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:50] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:51] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:51] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:51] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:52] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:52] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:52] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:53] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:53] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:53] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:54] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:54] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:55] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:55] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:55] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:56] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:56] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:56] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:57] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:57] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:57] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:58] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:58] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:59] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:59] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:50:59] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:00] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:00] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:00] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:00] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:01] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:01] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:01] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:02] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:02] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:02] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:03] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:03] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:03] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:04] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:04] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:04] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:05] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:05] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:05] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:06] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:06] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:06] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:07] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:07] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:07] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:08] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:08] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:09] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:09] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:09] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:10] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:10] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:10] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:10] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:11] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:11] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:11] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:12] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:12] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:12] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:13] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:13] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:13] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:13] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:14] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:14] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:14] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:15] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:15] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:15] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:16] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:16] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:16] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:17] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:17] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:17] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:17] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:18] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:18] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:18] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:19] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:19] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:19] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:20] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:20] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:20] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:20] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:21] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:21] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:21] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:22] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:22] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:22] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:23] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:23] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:23] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:24] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:24] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:24] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:24] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:25] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:25] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:25] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:26] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:26] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:26] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:27] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:27] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:27] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:28] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:28] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:28] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:28] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:29] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:29] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:29] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:30] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:30] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:30] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:31] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:31] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:31] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:32] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:32] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:32] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:32] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:33] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:33] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:33] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:34] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:34] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:34] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:35] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:35] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:35] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:36] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:36] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:36] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:36] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:37] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:37] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:37] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:38] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:38] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:38] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:39] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:39] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:39] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:39] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:40] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:40] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:40] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:41] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:41] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:41] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:42] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:42] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:42] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:42] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:43] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:43] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:43] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:44] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:44] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:44] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:45] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:45] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:45] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:46] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:46] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:46] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:47] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:47] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:47] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:47] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:48] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:48] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:48] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:49] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:49] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:49] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:50] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:50] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:50] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:51] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:51] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:51] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:52] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:52] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:52] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:53] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:53] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:53] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:54] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:54] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:54] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:55] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:55] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:55] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:56] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:56] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:56] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:57] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:57] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:57] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:58] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:58] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:58] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:59] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:59] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:59] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:00] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:00] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:00] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:01] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:01] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:01] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:02] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:02] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:02] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:03] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:03] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:03] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:04] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:04] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:04] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:05] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:05] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:05] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:06] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:06] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:06] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:07] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:07] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:07] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:08] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:08] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:08] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:09] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:09] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:09] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:10] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:10] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:10] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:11] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"logging_level\", \"min_child_samples\", \"use_best_model\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "APOpYcgCVyju",
    "outputId": "10f97546-f68d-4c1f-a13c-225c7f132c47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 100\n",
      "Best trial:\n",
      "  Value: 0.8126482740237237\n",
      "  Params: \n",
      "    learning_rate: 0.068\n",
      "    depth: 4\n",
      "    l2_leaf_reg: 4.0\n",
      "    min_child_samples: 4\n",
      "    iterations: 3500.0\n",
      "    colsample_bylevel: 0.08466761002134586\n",
      "    scale_pos_weight: 1\n",
      "    bootstrap_type: Bernoulli\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LE4AVrkxVQkd",
    "outputId": "770b6b78-6a5d-4a12-e834-40b4ac9d3808"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Wonder\\anaconda3\\envs\\venv\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:53:26] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"min_child_samples\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "err:  0.8130081300813008\n",
      "[20:53:27] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"min_child_samples\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Wonder\\anaconda3\\envs\\venv\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err:  0.8130081300813008\n",
      "[20:53:29] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"min_child_samples\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Wonder\\anaconda3\\envs\\venv\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err:  0.8373983739837398\n",
      "[20:53:31] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"min_child_samples\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Wonder\\anaconda3\\envs\\venv\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err:  0.8455284552845529\n",
      "[20:53:33] WARNING: D:\\bld\\xgboost-split_1660208973102\\work\\src\\learner.cc:627: \n",
      "Parameters: { \"bootstrap_type\", \"depth\", \"iterations\", \"l2_leaf_reg\", \"min_child_samples\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Wonder\\anaconda3\\envs\\venv\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err:  0.7786885245901639\n",
      "0.8175263228042116\n"
     ]
    }
   ],
   "source": [
    "oof_f1=[]\n",
    "lgb_oof_predictions=[]\n",
    "\n",
    "\n",
    "param = trial.params\n",
    "\n",
    "\n",
    "\n",
    "fold=StratifiedKFold(n_splits=5)#15#5#10\n",
    "i=1\n",
    "\n",
    "for train_index, test_index in fold.split(X,y):\n",
    "        \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    model = XGBClassifier(**param ,n_estimators=1000)\n",
    "\n",
    "    model.fit(X_train,y_train,eval_set=[(X_train,y_train),(X_test, y_test)], early_stopping_rounds=500, verbose = False)#erly100\n",
    "    preds=model.predict(X_test)\n",
    "    print(\"err: \",accuracy_score(y_test,preds))\n",
    "    oof_f1.append(accuracy_score(y_test,preds))\n",
    "    lgb_oof_predictions.append(model.predict_proba(X_test)[:,-1])\n",
    "    \n",
    "print(np.mean(oof_f1))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNSjKaCas2++a+HRY2aotvu",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1ee8_pOLtSlZ9zgvAS5FeFAxiuGkjEQBE",
   "name": "Model_Improvement.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "34024564ae41f543771def55e1cc8f8e6526295bc4872b924a19ccccfa692b05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
